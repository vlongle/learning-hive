{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.fleet.utils.fleet_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shell.fleet.fleet import Agent, Fleet\n",
    "from shell.fleet.data.data_utilize import *\n",
    "from shell.fleet.data.recv import *\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.utils import make_grid\n",
    "from shell.fleet.data.data_utilize import *\n",
    "import logging\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from shell.fleet.data.recv_utils import *\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from functools import partial\n",
    "from torchvision.utils import make_grid\n",
    "from shell.utils.oodloss import OODSeparationLoss\n",
    "from pythresh.thresholds.dsn import DSN\n",
    "from pythresh.thresholds.aucp import AUCP\n",
    "from pythresh.thresholds.boot import BOOT\n",
    "from pythresh.thresholds.zscore import ZSCORE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "from experiments.run import handle_combine_modes\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \".\"\n",
    "experiment_name = \"combine_modes_results/recv_data_no_sparse_False_recv_mod_add_data_backward_True_make_new_opt_True\"\n",
    "experiment_name = \"combine_modes_results/gt_recv_data_no_sparse_False_recv_mod_add_data_backward_True_make_new_opt_True\"\n",
    "dataset = \"kmnist\"\n",
    "algo = \"modular\"\n",
    "\n",
    "use_contrastive = False\n",
    "num_trains_per_class = 64 if dataset != \"cifar100\" else 256\n",
    "seed = 0\n",
    "parallel = False\n",
    "task_id = 3\n",
    "\n",
    "\n",
    "agent_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_cfg(net_cfg, agent_cfg, train_cfg, fleet_additional_cfg, cfg):\n",
    "    cfg = handle_combine_modes(cfg)\n",
    "    return  net_cfg, agent_cfg, train_cfg, fleet_additional_cfg, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = get_save_dir(experiment_folder, experiment_name,\n",
    "                        dataset, algo, num_trains_per_class, use_contrastive, seed)\n",
    "\n",
    "fleet = setup_fleet(save_dir, task_id=task_id, parallel=False, modify_cfg=modify_cfg)\n",
    "# fleet = setup_fleet(save_dir, task_id=task_id, parallel=False, modify_cfg=modify_cfg)\n",
    "fleet.change_save_dir('debug_combine_modes_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = fleet.agents[agent_id]\n",
    "if 'gt' not in experiment_name:\n",
    "    comm = agent.communicator['recv_data']\n",
    "    print(comm.neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gt' not in experiment_name:\n",
    "    fleet.communicate(task_id, end_epoch=None, comm_freq=None, num_epochs=None, strategy='recv_data')\n",
    "else:\n",
    "    fleet.communicate(task_id, end_epoch=None, comm_freq=None, num_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gt' not in experiment_name:\n",
    "    print(comm.incoming_data)\n",
    "else:\n",
    "    print(agent.incoming_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.eval_test(task_id=task_id, include_avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.incoming_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
