{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.fleet.utils.fleet_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shell.fleet.fleet import Agent, Fleet\n",
    "from shell.fleet.data.data_utilize import *\n",
    "from shell.fleet.data.recv import *\n",
    "from shell.utils.record import Record\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.utils import make_grid\n",
    "from shell.fleet.data.data_utilize import *\n",
    "import logging\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from shell.fleet.data.recv_utils import *\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from functools import partial\n",
    "from torchvision.utils import make_grid\n",
    "from shell.utils.oodloss import OODSeparationLoss\n",
    "from pythresh.thresholds.dsn import DSN\n",
    "from pythresh.thresholds.aucp import AUCP\n",
    "from pythresh.thresholds.boot import BOOT\n",
    "from pythresh.thresholds.zscore import ZSCORE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "from shell.fleet.utils.model_sharing_utils import *\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_cfg(net_cfg, agent_cfg, train_cfg, fleet_additional_cfg, cfg):\n",
    "    cfg.sharing_strategy['sync_base'] = False\n",
    "    return net_cfg, agent_cfg, train_cfg, fleet_additional_cfg, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mnist\"\n",
    "# datasets = [\"mnist\", \"kmnist\", \"fashionmnist\"]\n",
    "experiment_folder = \"experiment_results\"\n",
    "\n",
    "# use_contrastive = True\n",
    "use_contrastive = False\n",
    "num_trains_per_class = 64\n",
    "seed = 0\n",
    "# seed = 7\n",
    "algo = \"modular\"\n",
    "\n",
    "\n",
    "sync_base = True\n",
    "opt_with_random = False\n",
    "\n",
    "# experiment_name = f\"modmod_test_sync_base_{sync_base}_opt_with_random_{opt_with_random}\"\n",
    "experiment_name = f\"lowest_task_id_wins_modmod_test_sync_base_{sync_base}_opt_with_random_{opt_with_random}_frozen_False\"\n",
    "# base_experiment_name = \"vanilla_modular_save_freq_10\"\n",
    "# base_experiment_name = \"vanilla_fix_bug_compute_loss_encodev2\"\n",
    "base_experiment_name = \"vanilla_jorge_setting\"\n",
    "# seeds = [1]\n",
    "# tasks = [4]\n",
    "# agent_ids = None\n",
    "# ax=None\n",
    "# sync_bases = [True]\n",
    "# opt_with_randoms = [False]\n",
    "\n",
    "\n",
    "\n",
    "def modify_cfg(net_cfg, agent_cfg, train_cfg, fleet_additional_cfg, cfg):\n",
    "    if \"sync_base\" not in cfg.sharing_strategy:\n",
    "        cfg.sharing_strategy['sync_base'] = False\n",
    "    return net_cfg, agent_cfg, train_cfg, fleet_additional_cfg, cfg\n",
    "\n",
    "save_dirs = {}\n",
    "save_dirs['modmod'] = get_save_dir(experiment_folder, experiment_name,\n",
    "                        dataset, algo, num_trains_per_class, use_contrastive, seed)\n",
    "save_dirs['base_mod']  = get_save_dir(experiment_folder, base_experiment_name,  \n",
    "                        dataset, algo, num_trains_per_class, use_contrastive, seed)\n",
    "save_dirs['base_mono']  = get_save_dir(experiment_folder, base_experiment_name,  \n",
    "                        dataset, 'monolithic', num_trains_per_class, use_contrastive, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_divergence(save_dir, task_id):\n",
    "    fleet = setup_fleet(save_dir, modify_cfg=modify_cfg, parallel=False)\n",
    "    fleet.load_model_from_ckpoint(task_ids=task_id)\n",
    "    basis = [f'components.{i}.weight' for i in range(fleet.num_init_tasks)]\n",
    "    basis += [f'components.{i}.bias' for i in range(fleet.num_init_tasks)]\n",
    "    div = Record(\"debug_modmod_result_div\")\n",
    "    for agent in fleet.agents:\n",
    "        for agent2 in fleet.agents:\n",
    "            if agent.node_id == agent2.node_id:\n",
    "                continue\n",
    "            agent_div = diff_models(agent.net.state_dict(), agent2.net.state_dict(), basis)\n",
    "            agent_div['avg'] = sum(agent_div.values()) / len(agent_div)\n",
    "            div.write(\n",
    "               {'agent_1': agent.node_id, 'agent_2': agent2.node_id} | \n",
    "                agent_div)\n",
    "    return div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_tasks = 4\n",
    "num_tasks = 10\n",
    "exp_divs = {}\n",
    "for exp_name, save_dir in save_dirs.items():\n",
    "    divs = {}\n",
    "    for task_id in range(num_init_tasks, num_tasks):\n",
    "        task_div = compute_divergence(save_dir, task_id).df\n",
    "        div_m, div_std = task_div['avg'].mean(), task_div['avg'].std()\n",
    "        divs[task_id] = (div_m, div_std)\n",
    "    exp_divs[exp_name] = divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_div(exp_divs):\n",
    "    num_exp = len(exp_divs)\n",
    "    exp_names = list(exp_divs.keys())\n",
    "    task_ids = list(next(iter(exp_divs.values())).keys())\n",
    "    num_tasks = len(task_ids)\n",
    "\n",
    "    # Width of a bar\n",
    "    bar_width = 0.8 / num_exp  # Adjust this as needed\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Generate a colormap\n",
    "    cmap = get_cmap('tab20', num_exp)  # You can change 'viridis' to any other colormap\n",
    "    colors = {exp_name: cmap(i) for i, exp_name in enumerate(exp_names)}\n",
    "    print(colors)\n",
    "\n",
    "    # Loop over experiments and tasks to plot\n",
    "    for exp_index, (exp_name, divs) in enumerate(exp_divs.items()):\n",
    "        offsets = np.arange(len(task_ids))  # Base x positions for each task_id\n",
    "        for task_index, (task_id, (div_m, div_std)) in enumerate(divs.items()):\n",
    "            # Calculate offset for this experiment\n",
    "            offset = (exp_index - num_exp / 2) * bar_width + bar_width / 2\n",
    "            pos = offsets[task_index] + offset\n",
    "            \n",
    "            # Plotting\n",
    "            plt.bar(pos, div_m, yerr=div_std, width=bar_width, color=colors[exp_name],\n",
    "                    label=f'{exp_name}' if task_index == 0 else \"\", align='center')\n",
    "\n",
    "    # Improving the plot\n",
    "    ax.set_xticks(np.arange(len(task_ids)))\n",
    "    ax.set_xticklabels(task_ids)\n",
    "    ax.set_ylim(0.001, 0.01)\n",
    "\n",
    "    # Create a legend for the experiments\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))  # Removing duplicates in legend\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "    plt.xlabel('Task ID')\n",
    "    plt.ylabel('Divergence Measure')\n",
    "    plt.title('Divergence Measures by Task and Experiment')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_div(exp_divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Module Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_no_dependent_modules(save_dir, task_id):\n",
    "    fleet = setup_fleet(save_dir, modify_cfg=modify_cfg, parallel=False)\n",
    "    fleet.load_records()\n",
    "    fleet.load_model_from_ckpoint(task_ids=task_id-1)\n",
    "    fleet.communicate(task_id=task_id, end_epoch=None, comm_freq=None, num_epochs=None)\n",
    "    record = Record('debug_modmod_result_depedent_modules')\n",
    "    for agent in fleet.agents:\n",
    "        module_list = agent.get_module_list()\n",
    "        if len(module_list) == 0:\n",
    "            continue\n",
    "        chosen_id = agent.choose_best_module_from_neighbors(module_list)\n",
    "        chosen = module_list[chosen_id]\n",
    "        record.write(\n",
    "            {\n",
    "            'agent': agent.node_id,\n",
    "            'chosen_module_id': chosen['module_id'],\n",
    "            'task_id': task_id,\n",
    "            'task_sim': chosen['task_sim'],\n",
    "            })\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1, 2, 3, 4, 5, 6, 7]\n",
    "seed_chosen_module_id = []\n",
    "for seed_id in seeds:\n",
    "    save_dirs = {}\n",
    "    save_dirs['modmod'] = get_save_dir(experiment_folder, experiment_name,\n",
    "                        dataset, algo, num_trains_per_class, use_contrastive, seed_id)\n",
    "\n",
    "    dfs = []\n",
    "    for i in range(5, 10):\n",
    "        dfs.append(compute_no_dependent_modules(save_dirs['modmod'], i).df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    mean_chosen_module_id = df.groupby('task_id').mean().reset_index()\n",
    "    seed_chosen_module_id.append(mean_chosen_module_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for seed, df in enumerate(seed_chosen_module_id):\n",
    "    df[\"seed\"] = seed\n",
    "    dfs.append(df)\n",
    "\n",
    "concat_df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "# Aggregating results\n",
    "agg_df = concat_df.groupby(\"task_id\").agg({\"chosen_module_id\": \"mean\", \"task_sim\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "# Bar plot of chosen_module_id with respect to task_id\n",
    "axs[0].bar(agg_df[\"task_id\"], agg_df[\"chosen_module_id\"], color='skyblue')\n",
    "axs[0].set_title('Average Chosen Module ID by Task ID')\n",
    "axs[0].set_xlabel('Task ID')\n",
    "axs[0].set_ylabel('Chosen Module ID')\n",
    "\n",
    "# Bar plot of task_sim\n",
    "axs[1].bar(agg_df[\"task_id\"], agg_df[\"task_sim\"], color='lightgreen')\n",
    "axs[1].set_title('Average Task Similarity by Task ID')\n",
    "axs[1].set_xlabel('Task ID')\n",
    "axs[1].set_ylabel('Task Similarity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = save_dirs['modmod']\n",
    "# fleet = setup_fleet(save_dir, modify_cfg=modify_cfg, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'component_update_freq': 100, 'num_epochs': 100, 'init_component_update_freq': 100, 'init_num_epochs': 100, 'save_freq': 10}, 'dataset': {'dataset_name': 'mnist', 'num_tasks': 10, 'num_classes_per_task': 2, 'with_replacement': True, 'num_trains_per_class': 64, 'num_vals_per_class': 50, 'remap_labels': True}, 'net': {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.5}, 'sharing_strategy': {'name': 'no_sharing', 'num_coms_per_round': 0, 'sync_base': False, 'pre_or_post_comm': 'post'}, 'seed': 0, 'algo': 'modular', 'job_name': 'mnist_modular_numtrain_64', 'num_agents': 8, 'root_save_dir': 'experiment_results/vanilla_jorge_setting', 'parallel': True, 'num_init_tasks': 4, 'overwrite': False, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': False, 'use_ood_separation_loss': False, 'lambda_ood': 2.0, 'delta_ood': 1.0}}\n",
      "i_size 28\n",
      "num_classes 2\n",
      "net_cfg {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.5, 'i_size': 28, 'num_classes': 2, 'num_tasks': 10, 'num_init_tasks': 4, 'use_contrastive': False}\n",
      "<class 'shell.learners.er_dynamic.CompositionalDynamicER'>\n"
     ]
    }
   ],
   "source": [
    "save_dir = save_dirs['base_mod']\n",
    "fleet = setup_fleet(save_dir, modify_cfg=modify_cfg, parallel=False)\n",
    "\n",
    "task_id = 6\n",
    "fleet.load_records()\n",
    "fleet.load_model_from_ckpoint(task_ids=task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1168419 , 0.12826174, 0.12350338, 0.14712647],\n",
       "       [0.20251852, 0.14913394, 0.29645446, 0.13973507],\n",
       "       [0.12060184, 0.12252009, 0.12759334, 0.21331032],\n",
       "       [0.27101514, 0.38600186, 0.29581982, 0.32900655],\n",
       "       [0.28902262, 0.21408239, 0.15662901, 0.17082164]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent =  fleet.agents[0]\n",
    "net = agent.net\n",
    "s = net.softmax(net.structure[task_id][:net.num_components, :]).cpu().detach().numpy()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>best_candidate_idx</th>\n",
       "      <th>num_candidates</th>\n",
       "      <th>best_improvement</th>\n",
       "      <th>num_components</th>\n",
       "      <th>add_new_module</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id  best_candidate_idx  num_candidates  best_improvement  \\\n",
       "0        4                   4               1          0.000000   \n",
       "1        5                   4               1          0.010101   \n",
       "2        6                   4               1          0.291667   \n",
       "3        7                   5               1          0.032967   \n",
       "4        8                   5               1          0.010204   \n",
       "5        9                   5               1          0.021277   \n",
       "\n",
       "   num_components  add_new_module  \n",
       "0               4           False  \n",
       "1               4           False  \n",
       "2               5            True  \n",
       "3               5           False  \n",
       "4               5           False  \n",
       "5               5           False  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.dynamic_record.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f41f80f7310>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(s, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should add to 1.0 due to softmax\n",
    "s.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sum(axis=0), s.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "At the beginning of each task, compute\n",
    "- Basis module divergence.\n",
    "- External module dependency on the shared module:\n",
    "    - No. of sender's modules at the source task time.\n",
    "    - Actual avg linear weight on non-basis modules at source task time.\n",
    "\n",
    "- Plot the no. of modules over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
