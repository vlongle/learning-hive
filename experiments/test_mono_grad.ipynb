{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from shell.fleet.helper import get_fleet, get_agent_cls\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "from shell.utils.experiment_utils import setup_experiment, process_dataset_cfg, eval_net\n",
    "from shell.datasets.datasets import get_dataset\n",
    "from pprint import pprint\n",
    "import ray\n",
    "import os\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from shell.utils.utils import seed_everything\n",
    "from shell.fleet.model_sharing_utils import is_in\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1902582/4114385434.py:4: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\"conf\", job_name=\"tmp_job\")\n",
      "/home/vlongle/miniconda3/envs/shell/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'grad': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# config_path = os.path.join(\"conf\", \"grad.yaml\")\n",
    "# # read the config file\n",
    "# cfg = omegaconf.OmegaConf.load(config_path)\n",
    "initialize(config_path=\"conf\", job_name=\"tmp_job\")\n",
    "cfg = compose(config_name=\"grad\")\n",
    "seed_everything(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override\n",
    "cfg.parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train.num_epochs = 50\n",
    "cfg.train.component_update_freq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [4 7 0 8 4 6 4 3 8 0 1 0 5 9 6 4 9 0 3 0]\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'component_update_freq': 50, 'num_epochs': 50, 'save_freq': 1}, 'dataset': {'dataset_name': 'mnist', 'num_tasks': 10, 'num_classes_per_task': 2, 'with_replacement': True, 'num_trains_per_class': 64, 'num_vals_per_class': 50, 'remap_labels': True}, 'net': {'name': 'mlp', 'depth': 2, 'layer_size': 64, 'dropout': 0.0}, 'sharing_strategy': {'name': 'gradient', 'num_coms_per_round': 5, 'retrain': {'num_epochs': 10}}, 'seed': 0, 'algo': 'modular', 'job_name': 'fun', 'num_agents': 4, 'root_save_dir': 'results', 'parallel': True, 'num_init_tasks': 2, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 64, 'improvement_threshold': 0.05, 'use_contrastive': True}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [2 1 3 8 6 0 3 0 5 0 3 6 2 7 6 7 6 1 0 5]\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [0 9 7 2 1 8 6 1 6 4 5 7 8 0 2 3 0 3 9 6]\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [0 5 3 4 4 5 9 3 0 6 9 1 3 1 7 9 5 2 3 2]\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_size 28\n",
      "num_classes 2\n",
      "net_cfg {'name': 'mlp', 'depth': 2, 'layer_size': 64, 'dropout': 0.0, 'i_size': 28, 'num_classes': 2, 'num_tasks': 10, 'num_init_tasks': 2}\n",
      "<class 'shell.learners.er_dynamic.CompositionalDynamicER'>\n"
     ]
    }
   ],
   "source": [
    "AgentCls = get_agent_cls(cfg.sharing_strategy, cfg.algo, cfg.parallel)\n",
    "\n",
    "graph, datasets, NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg = setup_experiment(\n",
    "        cfg)\n",
    "FleetCls = get_fleet(cfg.sharing_strategy, cfg.parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [3 9 2 4 9 2 5 4 8 9 9 4 1 6 9 6 8 0 5 1]\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "INFO:root:(128, 1, 28, 28)\n",
      "2023-03-27 22:16:19,007\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:Agent: node_id: 69420, seed: 69420000\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 0, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.208\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.208\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 0, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.201\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.201\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:final components: 2\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 0, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.201\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.210\tacc: 0.577\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.206\tacc: 0.538\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 1, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.190\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.163\tacc: 0.537\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.177\tacc: 0.518\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 2, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.167\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.127\tacc: 0.538\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.147\tacc: 0.519\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 3, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.158\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.103\tacc: 0.577\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.130\tacc: 0.539\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 4, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.134\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.098\tacc: 0.646\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.116\tacc: 0.573\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 5, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.146\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.061\tacc: 0.747\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.104\tacc: 0.623\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 6, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.089\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.058\tacc: 0.833\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.074\tacc: 0.666\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 7, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.094\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.021\tacc: 0.863\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.057\tacc: 0.682\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 8, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.119\tacc: 0.502\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.993\tacc: 0.883\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.056\tacc: 0.693\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 9, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.089\tacc: 0.518\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.986\tacc: 0.911\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.038\tacc: 0.714\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 10, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.126\tacc: 0.531\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.997\tacc: 0.927\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.062\tacc: 0.729\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 11, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.083\tacc: 0.530\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.985\tacc: 0.936\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.034\tacc: 0.733\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 12, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.029\tacc: 0.537\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 6.003\tacc: 0.943\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.016\tacc: 0.740\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 13, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.020\tacc: 0.574\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.924\tacc: 0.949\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.972\tacc: 0.761\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 14, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.025\tacc: 0.643\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.966\tacc: 0.955\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.996\tacc: 0.799\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 15, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.056\tacc: 0.702\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.976\tacc: 0.954\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 6.016\tacc: 0.828\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 16, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.007\tacc: 0.746\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.908\tacc: 0.943\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.957\tacc: 0.845\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 17, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.017\tacc: 0.770\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.970\tacc: 0.925\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.994\tacc: 0.847\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 18, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.002\tacc: 0.807\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.918\tacc: 0.928\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.960\tacc: 0.867\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 19, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.970\tacc: 0.853\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.888\tacc: 0.954\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.929\tacc: 0.904\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 20, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.012\tacc: 0.881\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.926\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.969\tacc: 0.921\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 21, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.987\tacc: 0.903\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.902\tacc: 0.957\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.944\tacc: 0.930\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 22, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.935\tacc: 0.921\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.887\tacc: 0.949\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.911\tacc: 0.935\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 23, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.998\tacc: 0.921\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.925\tacc: 0.940\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.961\tacc: 0.931\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 24, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.953\tacc: 0.940\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.839\tacc: 0.945\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.896\tacc: 0.943\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 25, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.999\tacc: 0.951\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.870\tacc: 0.960\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.935\tacc: 0.956\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 26, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.920\tacc: 0.951\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.890\tacc: 0.970\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.905\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 27, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.946\tacc: 0.949\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.863\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.905\tacc: 0.955\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 28, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.950\tacc: 0.945\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.856\tacc: 0.941\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.903\tacc: 0.943\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 29, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.939\tacc: 0.958\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.920\tacc: 0.940\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.929\tacc: 0.949\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 30, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.939\tacc: 0.960\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.852\tacc: 0.954\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.896\tacc: 0.957\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 31, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.002\tacc: 0.960\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.784\tacc: 0.970\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.893\tacc: 0.965\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 32, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.922\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.835\tacc: 0.972\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.878\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 33, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 6.004\tacc: 0.965\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.844\tacc: 0.972\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.924\tacc: 0.969\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 34, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.892\tacc: 0.965\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.808\tacc: 0.964\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.850\tacc: 0.965\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 35, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.926\tacc: 0.965\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.809\tacc: 0.960\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.868\tacc: 0.963\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 36, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.880\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.853\tacc: 0.963\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.867\tacc: 0.966\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 37, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.825\tacc: 0.963\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.864\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.845\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 38, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.946\tacc: 0.962\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.814\tacc: 0.973\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.880\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 39, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.919\tacc: 0.964\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.798\tacc: 0.972\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.858\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 40, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.883\tacc: 0.965\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.785\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.834\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 41, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.880\tacc: 0.966\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.809\tacc: 0.958\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.845\tacc: 0.962\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 42, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.832\tacc: 0.965\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.812\tacc: 0.949\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.822\tacc: 0.957\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 43, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.801\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.790\tacc: 0.950\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.795\tacc: 0.959\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 44, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.896\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.780\tacc: 0.956\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.838\tacc: 0.963\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 45, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.811\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.774\tacc: 0.969\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.793\tacc: 0.970\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 46, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.874\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.805\tacc: 0.972\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.840\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 47, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.859\tacc: 0.973\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.789\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.824\tacc: 0.970\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 48, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.843\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.742\tacc: 0.962\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.792\tacc: 0.962\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 49, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.834\tacc: 0.965\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.748\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.791\tacc: 0.963\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 50, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.839\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.764\tacc: 0.956\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.801\tacc: 0.962\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:epochs: 51, training task: 1\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 0\tloss: 5.814\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: 1\tloss: 5.778\tacc: 0.956\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:\ttask: avg\tloss: 5.796\tacc: 0.962\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1910811)\u001b[0m INFO:root:final components: 2\n",
      "INFO:root:No. gpus per agent: 0.5\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:Agent: node_id: 1, seed: 1000\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:Agent: node_id: 0, seed: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:Agent: node_id: 2, seed: 2000\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:Agent: node_id: 3, seed: 3000\n",
      "INFO:root:Created fleet with 4 agents\n",
      "INFO:root:Adding neighbors...\n",
      "INFO:root:Fleet initialized\n"
     ]
    }
   ],
   "source": [
    "fake_dataset = get_dataset(**process_dataset_cfg(cfg))\n",
    "fleet = FleetCls(graph, cfg.seed, datasets, cfg.sharing_strategy, AgentCls, NetCls=NetCls,\n",
    "                     LearnerCls=LearnerCls, net_kwargs=net_cfg, agent_kwargs=agent_cfg,\n",
    "                     train_kwargs=train_cfg, fake_dataset=fake_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_models(modelA_statedict, modelB_statedict, keys=None):\n",
    "    diffs = {}\n",
    "    # compute the average difference between two models\n",
    "    for key in modelA_statedict.keys():\n",
    "        if keys is not None and not is_in(key, keys):\n",
    "            continue\n",
    "        if key in modelB_statedict.keys():\n",
    "            diffs[key] = torch.mean(torch.abs(modelA_statedict[key] - modelB_statedict[key])).item()\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m replacing model with strict: False\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m replacing model with strict: False\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m replacing model with strict: False\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m replacing model with strict: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'components.0.weight': 0.0,\n",
       " 'components.0.bias': 0.0,\n",
       " 'components.1.weight': 0.0,\n",
       " 'components.1.bias': 0.0,\n",
       " 'random_linear_projection.weight': 0.0,\n",
       " 'random_linear_projection.bias': 0.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diff_models(fleet.agents[0].get_net().state_dict(), fleet.agents[1].get_net().state_dict(),\n",
    "#             keys=[\"random_linear_projection\", \"components\"])\n",
    "\n",
    "diff_models(ray.get(fleet.agents[0].get_net.remote()).state_dict(), \n",
    "            ray.get(fleet.agents[1].get_net.remote()).state_dict(),\n",
    "            keys=[\"random_linear_projection\", \"components\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.4900497512437811}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(fleet.agents[0].eval.remote(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0: tensor([ 0.0232, -0.0111,  0.0021, -0.0189, -0.0179, -0.0112, -0.0022,  0.0112,\n",
      "        -0.0076,  0.0167], device='cuda:0')\n",
      "agent 1: tensor([ 0.0232, -0.0111,  0.0021, -0.0189, -0.0179, -0.0112, -0.0022,  0.0112,\n",
      "        -0.0076,  0.0167], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# check the linear projection\n",
    "print(\"agent 0:\", ray.get(fleet.agents[0].get_net.remote()).state_dict()[\"random_linear_projection.weight\"][0, :10])\n",
    "print(\"agent 1:\", ray.get(fleet.agents[1].get_net.remote()).state_dict()[\"random_linear_projection.weight\"][0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0: False\n"
     ]
    }
   ],
   "source": [
    "print(\"agent 0:\", ray.get(fleet.agents[0].get_net.remote()).state_dict()[\"random_linear_projection.weight\"].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 0, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.188\tacc: 0.490\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.188\tacc: 0.490\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 0, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.229\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.229\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 0, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.142\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.142\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 0, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.345\tacc: 0.475\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.345\tacc: 0.475\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 1, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.211\tacc: 0.520\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.211\tacc: 0.520\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 1, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.193\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.193\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 1, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.209\tacc: 0.607\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.209\tacc: 0.607\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 1, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.215\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.215\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 2, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.210\tacc: 0.679\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.210\tacc: 0.679\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 2, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.212\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.212\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 2, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.190\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.190\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 2, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.209\tacc: 0.527\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.209\tacc: 0.527\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 3, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.208\tacc: 0.804\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.208\tacc: 0.804\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 3, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.206\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.206\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 3, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.185\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.185\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 3, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.208\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.208\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 4, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.205\tacc: 0.796\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.205\tacc: 0.796\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 4, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.206\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.206\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 4, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.184\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.184\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 4, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.207\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.207\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 5, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.202\tacc: 0.791\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.202\tacc: 0.791\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 5, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.204\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.204\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 5, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.175\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.175\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 5, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.202\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.202\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 6, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.202\tacc: 0.745\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.202\tacc: 0.745\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 6, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.205\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.205\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 6, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.176\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.176\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 6, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 7, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.200\tacc: 0.671\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.200\tacc: 0.671\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 7, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.203\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.203\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 7, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.170\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.170\tacc: 0.493\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 7, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.195\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.195\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 8, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.197\tacc: 0.621\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.197\tacc: 0.621\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 8, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.198\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.198\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 8, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.161\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.161\tacc: 0.500\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 8, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.190\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.190\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 9, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.195\tacc: 0.596\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.195\tacc: 0.596\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 9, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.202\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.202\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 9, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.150\tacc: 0.581\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.150\tacc: 0.581\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 9, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.188\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.188\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 10, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.189\tacc: 0.588\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.189\tacc: 0.588\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 10, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.160\tacc: 0.653\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.160\tacc: 0.653\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 10, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 10, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.192\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.192\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 11, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.184\tacc: 0.569\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.184\tacc: 0.569\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 11, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 11, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.150\tacc: 0.794\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.150\tacc: 0.794\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 11, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.183\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.183\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 12, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.178\tacc: 0.584\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.178\tacc: 0.584\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 12, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.195\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.195\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 12, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.144\tacc: 0.864\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.144\tacc: 0.864\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 12, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.182\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.182\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 13, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.186\tacc: 0.598\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 13, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.200\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.200\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.186\tacc: 0.598\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 13, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.132\tacc: 0.926\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.132\tacc: 0.926\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 13, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.182\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.182\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 14, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.201\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.201\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 14, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.172\tacc: 0.592\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.172\tacc: 0.592\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 14, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.120\tacc: 0.943\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.120\tacc: 0.943\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 15, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.198\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.198\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 14, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.189\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.189\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 15, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.176\tacc: 0.602\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.176\tacc: 0.602\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 15, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.127\tacc: 0.959\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.127\tacc: 0.959\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 16, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 15, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.172\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.172\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 16, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.124\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.124\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 16, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.179\tacc: 0.609\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.179\tacc: 0.609\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 17, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.195\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.195\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 16, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.176\tacc: 0.525\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.176\tacc: 0.525\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 17, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.172\tacc: 0.627\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.172\tacc: 0.627\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 17, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.126\tacc: 0.970\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.126\tacc: 0.970\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 18, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.193\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.193\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 18, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.115\tacc: 0.974\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.115\tacc: 0.974\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 17, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.174\tacc: 0.529\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.174\tacc: 0.529\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 18, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.178\tacc: 0.642\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.178\tacc: 0.642\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 19, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.200\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.200\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 19, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.112\tacc: 0.974\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.112\tacc: 0.974\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 18, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.175\tacc: 0.558\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.175\tacc: 0.558\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 19, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.181\tacc: 0.672\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.181\tacc: 0.672\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 20, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.195\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.195\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 20, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.111\tacc: 0.975\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.111\tacc: 0.975\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 19, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.178\tacc: 0.604\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.178\tacc: 0.604\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 20, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.170\tacc: 0.704\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.170\tacc: 0.704\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 21, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 21, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.104\tacc: 0.974\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.104\tacc: 0.974\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 21, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.171\tacc: 0.730\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.171\tacc: 0.730\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 20, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.175\tacc: 0.660\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.175\tacc: 0.660\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 22, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.192\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.192\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 22, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.101\tacc: 0.976\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.101\tacc: 0.976\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 22, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.164\tacc: 0.770\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.164\tacc: 0.770\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 21, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.176\tacc: 0.712\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.176\tacc: 0.712\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 23, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.191\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.191\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 23, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.163\tacc: 0.817\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.163\tacc: 0.817\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 23, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.104\tacc: 0.977\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.104\tacc: 0.977\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 22, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.175\tacc: 0.741\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.175\tacc: 0.741\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 24, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.191\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.191\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 24, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.110\tacc: 0.979\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.110\tacc: 0.979\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 24, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.169\tacc: 0.846\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.169\tacc: 0.846\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 23, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.163\tacc: 0.766\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.163\tacc: 0.766\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 25, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.193\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.193\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 25, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.110\tacc: 0.979\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.110\tacc: 0.979\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 25, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.174\tacc: 0.870\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.174\tacc: 0.870\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 24, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.172\tacc: 0.787\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.172\tacc: 0.787\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 26, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.197\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 26, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.095\tacc: 0.977\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.095\tacc: 0.977\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 26, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.160\tacc: 0.882\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.160\tacc: 0.882\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 25, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.168\tacc: 0.814\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.168\tacc: 0.814\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 27, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.185\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.185\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 27, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.088\tacc: 0.975\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.088\tacc: 0.975\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 27, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.161\tacc: 0.898\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.161\tacc: 0.898\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 28, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.187\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.187\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 26, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.168\tacc: 0.850\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.168\tacc: 0.850\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 28, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.097\tacc: 0.973\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.097\tacc: 0.973\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 28, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.170\tacc: 0.917\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.170\tacc: 0.917\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 29, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.191\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.191\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 27, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.163\tacc: 0.874\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.163\tacc: 0.874\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 29, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.100\tacc: 0.969\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.100\tacc: 0.969\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 29, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.161\tacc: 0.922\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.161\tacc: 0.922\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 30, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.189\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.189\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 28, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.165\tacc: 0.883\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.165\tacc: 0.883\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 30, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.092\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.092\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 30, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.164\tacc: 0.933\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.164\tacc: 0.933\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 31, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.188\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.188\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 29, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.171\tacc: 0.887\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.171\tacc: 0.887\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 31, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.093\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.093\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 31, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.166\tacc: 0.936\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.166\tacc: 0.936\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 32, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.188\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.188\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 32, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.090\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.090\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 30, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.162\tacc: 0.888\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.162\tacc: 0.888\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 32, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.161\tacc: 0.936\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.161\tacc: 0.936\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 33, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.185\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.185\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 31, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.163\tacc: 0.886\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.163\tacc: 0.886\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 33, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.090\tacc: 0.969\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.090\tacc: 0.969\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 33, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.158\tacc: 0.941\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.158\tacc: 0.941\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 34, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.187\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.187\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 34, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.093\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.093\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 32, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.159\tacc: 0.893\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.159\tacc: 0.893\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 35, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.184\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.184\tacc: 0.524\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 34, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.158\tacc: 0.945\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.158\tacc: 0.945\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 35, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.089\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.089\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 33, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.156\tacc: 0.898\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.156\tacc: 0.898\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 36, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.188\tacc: 0.525\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.188\tacc: 0.525\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 35, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.158\tacc: 0.946\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.158\tacc: 0.946\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 36, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.078\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.078\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 34, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.158\tacc: 0.900\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.158\tacc: 0.900\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 37, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.184\tacc: 0.526\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.184\tacc: 0.526\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 36, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.145\tacc: 0.945\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.145\tacc: 0.945\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 37, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.076\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.076\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 35, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.157\tacc: 0.908\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.157\tacc: 0.908\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 38, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.187\tacc: 0.532\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.187\tacc: 0.532\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 37, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.161\tacc: 0.945\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.161\tacc: 0.945\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 38, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.070\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.070\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 36, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.158\tacc: 0.912\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.158\tacc: 0.912\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 39, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.181\tacc: 0.538\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.181\tacc: 0.538\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 38, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.151\tacc: 0.949\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.151\tacc: 0.949\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 39, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.072\tacc: 0.969\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.072\tacc: 0.969\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 37, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.158\tacc: 0.915\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.158\tacc: 0.915\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 40, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.184\tacc: 0.551\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.184\tacc: 0.551\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 39, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.157\tacc: 0.952\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.157\tacc: 0.952\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 40, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.065\tacc: 0.973\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.065\tacc: 0.973\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 41, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.180\tacc: 0.561\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.180\tacc: 0.561\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 38, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.151\tacc: 0.917\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.151\tacc: 0.917\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 40, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.147\tacc: 0.955\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.147\tacc: 0.955\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 41, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.077\tacc: 0.977\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.077\tacc: 0.977\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 42, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.178\tacc: 0.572\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.178\tacc: 0.572\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 39, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.152\tacc: 0.919\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.152\tacc: 0.919\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 41, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.156\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.156\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 42, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.065\tacc: 0.979\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.065\tacc: 0.979\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 43, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.178\tacc: 0.577\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.178\tacc: 0.577\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 40, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.149\tacc: 0.922\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.149\tacc: 0.922\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 42, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.153\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.153\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 43, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.063\tacc: 0.980\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.063\tacc: 0.980\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 44, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.177\tacc: 0.582\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.177\tacc: 0.582\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 41, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.152\tacc: 0.922\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.152\tacc: 0.922\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 43, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.151\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.151\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 44, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.070\tacc: 0.980\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.070\tacc: 0.980\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 45, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.179\tacc: 0.596\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.179\tacc: 0.596\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 44, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.153\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.153\tacc: 0.968\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 42, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.149\tacc: 0.921\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.149\tacc: 0.921\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 45, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.072\tacc: 0.980\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.072\tacc: 0.980\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 46, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.172\tacc: 0.622\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.172\tacc: 0.622\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 45, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.161\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.161\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 43, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.146\tacc: 0.916\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.146\tacc: 0.916\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 46, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.062\tacc: 0.980\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.062\tacc: 0.980\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 47, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.174\tacc: 0.649\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.174\tacc: 0.649\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 44, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.154\tacc: 0.912\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.154\tacc: 0.912\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 46, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.153\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.153\tacc: 0.967\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 47, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.060\tacc: 0.978\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.060\tacc: 0.978\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 48, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.172\tacc: 0.678\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.172\tacc: 0.678\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 45, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.142\tacc: 0.918\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.142\tacc: 0.918\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 47, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.148\tacc: 0.966\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.148\tacc: 0.966\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 48, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.063\tacc: 0.977\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.063\tacc: 0.977\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 49, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.177\tacc: 0.702\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.177\tacc: 0.702\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 48, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.149\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 50, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.167\tacc: 0.774\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.149\tacc: 0.961\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.167\tacc: 0.774\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 46, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.146\tacc: 0.923\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.146\tacc: 0.923\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 49, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.065\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.065\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:W/update: 0.78, WO/update: 0.51\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:Keeping new module. Total: 3\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 50, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.018\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.018\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 47, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.143\tacc: 0.926\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.143\tacc: 0.926\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 49, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.146\tacc: 0.958\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.146\tacc: 0.958\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:epochs: 51, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: 0\tloss: 6.166\tacc: 0.774\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:\ttask: avg\tloss: 6.166\tacc: 0.774\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:final components: 3\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:W/update: 0.96, WO/update: 0.98\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:Not keeping new module. Total: 2\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 50, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.117\tacc: 0.960\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.117\tacc: 0.960\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:epochs: 51, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: 0\tloss: 6.020\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:\ttask: avg\tloss: 6.020\tacc: 0.971\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:final components: 2\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 48, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.148\tacc: 0.927\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.148\tacc: 0.927\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:W/update: 0.95, WO/update: 0.93\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:Not keeping new module. Total: 2\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:epochs: 51, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: 0\tloss: 6.123\tacc: 0.924\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:\ttask: avg\tloss: 6.123\tacc: 0.924\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:final components: 2\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 49, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.140\tacc: 0.931\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.140\tacc: 0.931\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 50, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.123\tacc: 0.941\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.123\tacc: 0.941\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:W/update: 0.97, WO/update: 0.91\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:Keeping new module. Total: 3\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:epochs: 51, training task: 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: 0\tloss: 6.119\tacc: 0.941\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:\ttask: avg\tloss: 6.119\tacc: 0.941\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:final components: 3\n"
     ]
    }
   ],
   "source": [
    "# local train\n",
    "fleet.train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9238805970149254}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(fleet.agents[0].eval.remote(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component.0.bias tensor(-0.0153, device='cuda:0')\n",
      "component.0.bias tensor(-0.0227, device='cuda:0')\n",
      "component.0.bias tensor(-0.0226, device='cuda:0')\n",
      "component.0.bias tensor(-0.0199, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for agent in fleet.agents:\n",
    "    net = ray.get(agent.get_net.remote())\n",
    "    print('component.0.bias', net.state_dict()[\"components.0.bias\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.0153-0.0227-0.0226-0.0199)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0218"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.0220-0.0227-0.0226-0.0199)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'components.0.weight': 0.0028567069675773382,\n",
       " 'components.0.bias': 0.002630018861964345,\n",
       " 'components.1.weight': 0.0027251215651631355,\n",
       " 'components.1.bias': 0.002240207977592945,\n",
       " 'random_linear_projection.weight': 0.0,\n",
       " 'random_linear_projection.bias': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_models(ray.get(fleet.agents[0].get_net.remote()).state_dict(), \n",
    "            ray.get(fleet.agents[1].get_net.remote()).state_dict(),\n",
    "            keys=[\"random_linear_projection\", \"components\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shell.fleet.gradient_fleet.ParallelGradFleet at 0x7f71642bf2b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:node 1 is communicating at round 0 for task 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m INFO:root:My neighbors are: [Actor(ParallelModGrad, 65a2d58fed038567f5080d6d01000000), Actor(ParallelModGrad, b55b9e3a726aaebe9fb72fb701000000), Actor(ParallelModGrad, a6cf07f4e66c81055fa72df601000000)]\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:node 0 is communicating at round 0 for task 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m INFO:root:My neighbors are: [Actor(ParallelModGrad, 2ec33562626d501ec80d6b3501000000), Actor(ParallelModGrad, b55b9e3a726aaebe9fb72fb701000000), Actor(ParallelModGrad, a6cf07f4e66c81055fa72df601000000)]\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:node 2 is communicating at round 0 for task 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m INFO:root:My neighbors are: [Actor(ParallelModGrad, 65a2d58fed038567f5080d6d01000000), Actor(ParallelModGrad, 2ec33562626d501ec80d6b3501000000), Actor(ParallelModGrad, a6cf07f4e66c81055fa72df601000000)]\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:node 3 is communicating at round 0 for task 0\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m INFO:root:My neighbors are: [Actor(ParallelModGrad, 65a2d58fed038567f5080d6d01000000), Actor(ParallelModGrad, 2ec33562626d501ec80d6b3501000000), Actor(ParallelModGrad, b55b9e3a726aaebe9fb72fb701000000)]\n"
     ]
    }
   ],
   "source": [
    "fleet.num_coms_per_round = 1\n",
    "fleet.communicate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0: tensor([ 0.0232, -0.0111,  0.0021, -0.0189, -0.0179, -0.0112, -0.0022,  0.0112,\n",
      "        -0.0076,  0.0167], device='cuda:0')\n",
      "agent 1: tensor([ 0.0232, -0.0111,  0.0021, -0.0189, -0.0179, -0.0112, -0.0022,  0.0112,\n",
      "        -0.0076,  0.0167], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# check the linear projection\n",
    "print(\"agent 0:\", ray.get(fleet.agents[0].get_net.remote()).state_dict()[\"random_linear_projection.weight\"][0, :10])\n",
    "print(\"agent 1:\", ray.get(fleet.agents[1].get_net.remote()).state_dict()[\"random_linear_projection.weight\"][0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970633)\u001b[0m stuff_added: defaultdict(<class 'int'>, {'components.0.weight': 3, 'components.0.bias': 3, 'components.1.weight': 3, 'components.1.bias': 3})\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970632)\u001b[0m stuff_added: defaultdict(<class 'int'>, {'components.0.weight': 3, 'components.0.bias': 3, 'components.1.weight': 3, 'components.1.bias': 3})\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970681)\u001b[0m stuff_added: defaultdict(<class 'int'>, {'components.0.weight': 3, 'components.0.bias': 3, 'components.1.weight': 3, 'components.1.bias': 3})\n",
      "\u001b[2m\u001b[36m(ParallelModGrad pid=1970755)\u001b[0m stuff_added: defaultdict(<class 'int'>, {'components.0.weight': 3, 'components.0.bias': 3, 'components.1.weight': 3, 'components.1.bias': 3})\n",
      "component.0.bias tensor(-0.0201, device='cuda:0')\n",
      "component.0.bias tensor(-0.0201, device='cuda:0')\n",
      "component.0.bias tensor(-0.0201, device='cuda:0')\n",
      "component.0.bias tensor(-0.0201, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for agent in fleet.agents:\n",
    "    net = ray.get(agent.get_net.remote())\n",
    "    print('component.0.bias', net.state_dict()[\"components.0.bias\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.get(fleet.agents[0].get_bytes_sent.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.get(fleet.agents[0].get_received_models.remote())[2]['components.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.get(fleet.agents[1].get_received_models.remote())[2]['components.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # before aggregation\n",
    "# ray.get(fleet.agents[0].get_model.remote())['components.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.get(fleet.agents[0].aggregate_models.remote())\n",
    "# fleet.process_communicate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make sure that this doesn't affect agent 1\n",
    "# ray.get(fleet.agents[1].get_received_models.remote())[2]['components.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # after aggregation\n",
    "# ray.get(fleet.agents[0].get_model.remote())['components.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8880597014925373}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the performance again\n",
    "ray.get(fleet.agents[0].eval.remote(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'components.0.weight': 0.0,\n",
       " 'components.0.bias': 0.0,\n",
       " 'components.1.weight': 0.0,\n",
       " 'components.1.bias': 0.0,\n",
       " 'random_linear_projection.weight': 0.0,\n",
       " 'random_linear_projection.bias': 0.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_models(ray.get(fleet.agents[0].get_net.remote()).state_dict(), \n",
    "            ray.get(fleet.agents[1].get_net.remote()).state_dict(),\n",
    "            keys=[\"random_linear_projection\", \"components\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0232, -0.0111,  0.0021, -0.0189, -0.0179, -0.0112, -0.0022,  0.0112,\n",
       "        -0.0076,  0.0167], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the linear projection\n",
    "ray.get(fleet.agents[0].get_net.remote()).state_dict()[\"random_linear_projection.weight\"][0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
