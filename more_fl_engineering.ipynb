{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.fleet.utils.fleet_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shell.fleet.fleet import Agent, Fleet\n",
    "from shell.fleet.data.data_utilize import *\n",
    "from shell.fleet.data.recv import *\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.utils import make_grid\n",
    "from shell.fleet.data.data_utilize import *\n",
    "import logging\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from shell.fleet.data.recv_utils import *\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from functools import partial\n",
    "from torchvision.utils import make_grid\n",
    "from shell.utils.oodloss import OODSeparationLoss\n",
    "from pythresh.thresholds.dsn import DSN\n",
    "from pythresh.thresholds.aucp import AUCP\n",
    "from pythresh.thresholds.boot import BOOT\n",
    "from pythresh.thresholds.zscore import ZSCORE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "from shell.learners.fl_utils import *\n",
    "import copy\n",
    "\n",
    "from shell.fleet.network import *\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \".\"\n",
    "# experiment_folder = \"rerun_opt_heuristic_experiment_results\"\n",
    "experiment_name = \"more_fl_fix_root_agent_results/fedprox_mu_0.1_comm_freq_5\"\n",
    "dataset = \"mnist\"\n",
    "# algo = \"modular\"\n",
    "algo = \"monolithic\"\n",
    "\n",
    "use_contrastive = False\n",
    "num_trains_per_class = 64 if dataset != \"cifar100\" else 256\n",
    "seed = 0\n",
    "parallel = False\n",
    "task_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_cfg=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'component_update_freq': 100, 'num_epochs': 100, 'init_component_update_freq': 100, 'init_num_epochs': 100, 'save_freq': 10}, 'dataset': {'dataset_name': 'mnist', 'num_tasks': 10, 'num_classes_per_task': 2, 'with_replacement': True, 'num_trains_per_class': 64, 'num_vals_per_class': 50, 'remap_labels': True}, 'net': {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.5, 'no_sparse_basis': True}, 'sharing_strategy': {'name': 'fedprox', 'num_coms_per_round': 1, 'comm_freq': 5, 'mu': 0.1, 'when_reoptimize_structure': 'never', 'sync_base': True, 'pre_or_post_comm': 'pre'}, 'seed': 0, 'algo': 'monolithic', 'job_name': 'mnist_monolithic_numtrain_64', 'num_agents': 8, 'root_save_dir': 'more_fl_fix_root_agent_results/fedprox_mu_0.1_comm_freq_5', 'parallel': True, 'num_init_tasks': 4, 'overwrite': False, 'topology': 'fully_connected', 'edge_drop_prob': 0.0, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': False, 'use_ood_separation_loss': False, 'lambda_ood': 2.0, 'delta_ood': 1.0}}\n",
      "Setting seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [5 0 4 3 4 6 4 3 8 0 1 0 5 9 6 4 9 0 3 0]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (1872, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (1992, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (1940, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (1992, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (1954, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (2115, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (1901, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (1940, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (1989, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (1990, 1, 28, 28)\n",
      "INFO:root:Class sequence: [4 7 5 7 6 0 3 0 5 0 3 6 2 7 6 7 6 1 0 5]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (2010, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (1920, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (1938, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (1990, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (1872, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (1968, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (2060, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (1986, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (2093, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (1872, 1, 28, 28)\n",
      "INFO:root:Class sequence: [6 7 7 8 4 1 1 8 6 1 6 4 5 7 8 0 2 3 0 3]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (1986, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (2002, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (2117, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (2109, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (2093, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (1940, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (1920, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (1954, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (2042, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (1990, 1, 28, 28)\n",
      "INFO:root:Class sequence: [2 8 0 3 7 4 3 4 4 5 9 3 0 6 9 1 3 1 7 9]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (2006, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (1990, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (2010, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (1992, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (1874, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (2019, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (1938, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (2144, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (2145, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (2037, 1, 28, 28)\n",
      "INFO:root:Class sequence: [0 3 0 2 9 7 0 9 2 1 7 6 8 6 1 8 6 4 9 8]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (1990, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (2012, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (2037, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (1989, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (2167, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (1986, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (1932, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (2109, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (1940, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (1983, 1, 28, 28)\n",
      "INFO:root:Class sequence: [8 4 6 3 3 1 1 6 4 9 3 2 2 9 6 0 5 9 7 2]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (1956, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (1968, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (2145, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (2093, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (1991, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (2042, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (2041, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (1938, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (1901, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (2060, 1, 28, 28)\n",
      "INFO:root:Class sequence: [7 5 8 4 6 9 8 3 4 6 1 3 3 1 4 1 9 2 6 2]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (1920, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (1956, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (1967, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (1984, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (1940, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (2145, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (2145, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (2117, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (2041, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (1990, 1, 28, 28)\n",
      "INFO:root:Class sequence: [5 1 8 3 9 6 5 9 5 0 7 2 7 8 6 1 6 0 0 6]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (2027, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (1984, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (1967, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (1901, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (1872, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (2060, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (2002, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (2093, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (1938, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (1938, 1, 28, 28)\n",
      "INFO:root:Class sequence: [7 0 8 4 8 3 3 9 6 4 3 2 4 6 7 4 9 0 3 1]\n",
      "INFO:root:task 0 :(128, 1, 28, 28) (100, 1, 28, 28) (2008, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28) (100, 1, 28, 28) (1956, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28) (100, 1, 28, 28) (1984, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28) (100, 1, 28, 28) (2019, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_size 28\n",
      "num_classes 2\n",
      "net_cfg {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.5, 'no_sparse_basis': True, 'i_size': 28, 'num_classes': 2, 'num_tasks': 10, 'num_init_tasks': 4, 'use_contrastive': False}\n",
      "<class 'shell.learners.er_nocomponents.NoComponentsER'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:task 4 :(128, 1, 28, 28) (100, 1, 28, 28) (1940, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28) (100, 1, 28, 28) (2042, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28) (100, 1, 28, 28) (1940, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28) (100, 1, 28, 28) (2010, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28) (100, 1, 28, 28) (1989, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28) (100, 1, 28, 28) (2145, 1, 28, 28)\n",
      "INFO:root:Agent: node_id: 69420, seed: 69420000\n",
      "INFO:root:Agent: node_id: 0, seed: 0\n",
      "INFO:root:Agent: node_id: 1, seed: 1000\n",
      "INFO:root:Agent: node_id: 2, seed: 2000\n",
      "INFO:root:Agent: node_id: 3, seed: 3000\n",
      "INFO:root:Agent: node_id: 4, seed: 4000\n",
      "INFO:root:Agent: node_id: 5, seed: 5000\n",
      "INFO:root:Agent: node_id: 6, seed: 6000\n",
      "INFO:root:Agent: node_id: 7, seed: 7000\n",
      "INFO:root:Created fleet with 8 agents\n",
      "INFO:root:Adding neighbors...\n",
      "INFO:root:Fleet initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed 69420000\n",
      "Setting seed 0\n",
      "Setting seed 1000\n",
      "Setting seed 2000\n",
      "Setting seed 3000\n",
      "Setting seed 4000\n",
      "Setting seed 5000\n",
      "Setting seed 6000\n",
      "Setting seed 7000\n"
     ]
    }
   ],
   "source": [
    "save_dir = get_save_dir(experiment_folder, experiment_name,\n",
    "                        dataset, algo, num_trains_per_class, use_contrastive, seed)\n",
    "\n",
    "fleet = setup_fleet(save_dir, task_id=task_id, parallel=False, modify_cfg=modify_cfg)\n",
    "fleet.change_save_dir('debug_more_fl_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:AGGREGATING MODELS...no_components 4\n",
      "INFO:root:AGGREGATING MODELS...no_components 4\n",
      "INFO:root:AGGREGATING MODELS...no_components 4\n",
      "INFO:root:AGGREGATING MODELS...no_components 4\n",
      "INFO:root:AGGREGATING MODELS...no_components 4\n",
      "INFO:root:AGGREGATING MODELS...no_components 4\n",
      "INFO:root:AGGREGATING MODELS...no_components 4\n",
      "INFO:root:AGGREGATING MODELS...no_components 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 0 to 5 final False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epochs: 0, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.09933410\tacc: 0.973\n",
      "INFO:root:\ttask: 1\tloss: 0.30431303\tacc: 0.938\n",
      "INFO:root:\ttask: 2\tloss: 0.36044463\tacc: 0.902\n",
      "INFO:root:\ttask: 3\tloss: 0.21486674\tacc: 0.956\n",
      "INFO:root:\ttask: 4\tloss: 0.48018463\tacc: 0.706\n",
      "INFO:root:\ttask: 5\tloss: 0.65858134\tacc: 0.537\n",
      "INFO:root:\ttask: avg\tloss: 0.35295408\tacc: 0.835\n",
      "INFO:root:epochs: 1, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.07095879\tacc: 0.980\n",
      "INFO:root:\ttask: 1\tloss: 0.30101478\tacc: 0.914\n",
      "INFO:root:\ttask: 2\tloss: 0.37637609\tacc: 0.905\n",
      "INFO:root:\ttask: 3\tloss: 0.20967555\tacc: 0.957\n",
      "INFO:root:\ttask: 4\tloss: 0.37594168\tacc: 0.847\n",
      "INFO:root:\ttask: 5\tloss: 0.32837375\tacc: 0.959\n",
      "INFO:root:\ttask: avg\tloss: 0.27705677\tacc: 0.927\n",
      "INFO:root:epochs: 0, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.09826708\tacc: 0.972\n",
      "INFO:root:\ttask: 1\tloss: 0.30048993\tacc: 0.933\n",
      "INFO:root:\ttask: 2\tloss: 0.39017496\tacc: 0.902\n",
      "INFO:root:\ttask: 3\tloss: 0.23385756\tacc: 0.956\n",
      "INFO:root:\ttask: 4\tloss: 0.27666355\tacc: 0.871\n",
      "INFO:root:\ttask: 5\tloss: 0.48745241\tacc: 0.513\n",
      "INFO:root:\ttask: avg\tloss: 0.29781758\tacc: 0.858\n",
      "INFO:root:epochs: 1, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.08267295\tacc: 0.976\n",
      "INFO:root:\ttask: 1\tloss: 0.30144818\tacc: 0.928\n",
      "INFO:root:\ttask: 2\tloss: 0.39582601\tacc: 0.899\n",
      "INFO:root:\ttask: 3\tloss: 0.23317371\tacc: 0.958\n",
      "INFO:root:\ttask: 4\tloss: 0.26570532\tacc: 0.877\n",
      "INFO:root:\ttask: 5\tloss: 0.34070729\tacc: 0.918\n",
      "INFO:root:\ttask: avg\tloss: 0.26992225\tacc: 0.926\n",
      "INFO:root:epochs: 0, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.09918966\tacc: 0.972\n",
      "INFO:root:\ttask: 1\tloss: 0.31195003\tacc: 0.921\n",
      "INFO:root:\ttask: 2\tloss: 0.35663216\tacc: 0.901\n",
      "INFO:root:\ttask: 3\tloss: 0.20678467\tacc: 0.959\n",
      "INFO:root:\ttask: 4\tloss: 0.15416078\tacc: 0.953\n",
      "INFO:root:\ttask: 5\tloss: 1.19747731\tacc: 0.494\n",
      "INFO:root:\ttask: avg\tloss: 0.38769910\tacc: 0.867\n",
      "INFO:root:epochs: 1, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.12050269\tacc: 0.966\n",
      "INFO:root:\ttask: 1\tloss: 0.25243498\tacc: 0.944\n",
      "INFO:root:\ttask: 2\tloss: 0.37064849\tacc: 0.892\n",
      "INFO:root:\ttask: 3\tloss: 0.20361993\tacc: 0.952\n",
      "INFO:root:\ttask: 4\tloss: 0.17691680\tacc: 0.949\n",
      "INFO:root:\ttask: 5\tloss: 0.70181676\tacc: 0.494\n",
      "INFO:root:\ttask: avg\tloss: 0.30432327\tacc: 0.866\n",
      "INFO:root:epochs: 0, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.07884948\tacc: 0.977\n",
      "INFO:root:\ttask: 1\tloss: 0.31616824\tacc: 0.920\n",
      "INFO:root:\ttask: 2\tloss: 0.36825940\tacc: 0.901\n",
      "INFO:root:\ttask: 3\tloss: 0.21257970\tacc: 0.958\n",
      "INFO:root:\ttask: 4\tloss: 0.19184718\tacc: 0.926\n",
      "INFO:root:\ttask: 5\tloss: 1.70459764\tacc: 0.500\n",
      "INFO:root:\ttask: avg\tloss: 0.47871694\tacc: 0.864\n",
      "INFO:root:epochs: 1, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.08790421\tacc: 0.976\n",
      "INFO:root:\ttask: 1\tloss: 0.33841649\tacc: 0.920\n",
      "INFO:root:\ttask: 2\tloss: 0.36207211\tacc: 0.907\n",
      "INFO:root:\ttask: 3\tloss: 0.20942071\tacc: 0.956\n",
      "INFO:root:\ttask: 4\tloss: 0.22168962\tacc: 0.917\n",
      "INFO:root:\ttask: 5\tloss: 0.96536026\tacc: 0.507\n",
      "INFO:root:\ttask: avg\tloss: 0.36414390\tacc: 0.864\n",
      "INFO:root:epochs: 0, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.09659274\tacc: 0.972\n",
      "INFO:root:\ttask: 1\tloss: 0.26162349\tacc: 0.928\n",
      "INFO:root:\ttask: 2\tloss: 0.37421421\tacc: 0.894\n",
      "INFO:root:\ttask: 3\tloss: 0.21509273\tacc: 0.961\n",
      "INFO:root:\ttask: 4\tloss: 0.24075372\tacc: 0.910\n",
      "INFO:root:\ttask: 5\tloss: 0.58713492\tacc: 0.518\n",
      "INFO:root:\ttask: avg\tloss: 0.29590197\tacc: 0.864\n",
      "INFO:root:epochs: 1, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.09611800\tacc: 0.974\n",
      "INFO:root:\ttask: 1\tloss: 0.26483785\tacc: 0.929\n",
      "INFO:root:\ttask: 2\tloss: 0.38902920\tacc: 0.894\n",
      "INFO:root:\ttask: 3\tloss: 0.22385806\tacc: 0.959\n",
      "INFO:root:\ttask: 4\tloss: 0.24971083\tacc: 0.896\n",
      "INFO:root:\ttask: 5\tloss: 0.38951997\tacc: 0.918\n",
      "INFO:root:\ttask: avg\tloss: 0.26884565\tacc: 0.928\n",
      "INFO:root:epochs: 0, training task: 5\n",
      "INFO:root:\ttask: 0\tloss: 0.07767901\tacc: 0.978\n",
      "INFO:root:\ttask: 1\tloss: 0.35330499\tacc: 0.911\n",
      "INFO:root:\ttask: 2\tloss: 0.35520905\tacc: 0.902\n",
      "INFO:root:\ttask: 3\tloss: 0.21943567\tacc: 0.957\n",
      "INFO:root:\ttask: 4\tloss: 0.59301188\tacc: 0.621\n",
      "INFO:root:\ttask: 5\tloss: 0.72074689\tacc: 0.495\n",
      "INFO:root:\ttask: avg\tloss: 0.38656458\tacc: 0.811\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfleet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_comm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/fleet/grad/gradient_fleet.py:62\u001b[0m, in \u001b[0;36mSyncBaseFleet.train_and_comm\u001b[0;34m(self, task_id)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_from_jointly_trained_agent()\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete_jointly_trained_agent()\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSyncBaseFleet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_comm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/fleet/fleet.py:507\u001b[0m, in \u001b[0;36mFleet.train_and_comm\u001b[0;34m(self, task_id)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# only remove modules for the last epoch\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     agent\u001b[38;5;241m.\u001b[39mset_num_coms(task_id, num_coms)\n\u001b[0;32m--> 507\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomm_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# print('>> TRAINING FROM', start_epoch,\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m#       'TO', end_epoch)\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharing_strategy\u001b[38;5;241m.\u001b[39mpre_or_post_comm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m comm_freq \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_epochs \u001b[38;5;129;01mand\u001b[39;00m (end_epoch \u001b[38;5;241m%\u001b[39m comm_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# print('>>> COMM AT EPOCH', end_epoch)\u001b[39;00m\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/fleet/grad/fedprox.py:16\u001b[0m, in \u001b[0;36mFedProxAgent.train\u001b[0;34m(self, task_id, start_epoch, communication_frequency, final)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mmu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharing_strategy\u001b[38;5;241m.\u001b[39mmu\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mexcluded_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexcluded_params\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommunication_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/fleet/fleet.py:212\u001b[0m, in \u001b[0;36mAgent.train\u001b[0;34m(self, task_id, start_epoch, communication_frequency, final, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m train_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# print('train task', task_id, 'rand torch seed', int(torch.empty(\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m#     (), dtype=torch.int64).random_().item()))\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/learners/er_nocomponents.py:80\u001b[0m, in \u001b[0;36mNoComponentsER.train\u001b[0;34m(self, trainloader, task_id, component_update_freq, start_epoch, num_epochs, save_freq, testloaders, valloader, eval_bool, train_mode, record, final)\u001b[0m\n\u001b[1;32m     68\u001b[0m mega_dataset \u001b[38;5;241m=\u001b[39m ConcatDataset(\n\u001b[1;32m     69\u001b[0m     [get_custom_tensordataset(replay\u001b[38;5;241m.\u001b[39mget_tensors(), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name,\n\u001b[1;32m     70\u001b[0m                               use_contrastive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_contrastive) \u001b[38;5;28;01mfor\u001b[39;00m replay \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffers\u001b[38;5;241m.\u001b[39mvalues()] \u001b[38;5;241m+\u001b[39m [tmp_dataset]\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;241m+\u001b[39m [get_custom_tensordataset(replay\u001b[38;5;241m.\u001b[39mget_tensors(), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name,\n\u001b[1;32m     72\u001b[0m                                 use_contrastive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_contrastive) \u001b[38;5;28;01mfor\u001b[39;00m replay \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_replay_buffers\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(replay) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     74\u001b[0m mega_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(mega_dataset,\n\u001b[1;32m     75\u001b[0m                                           batch_size\u001b[38;5;241m=\u001b[39mtrainloader\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     76\u001b[0m                                           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m                                           num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     78\u001b[0m                                           pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     79\u001b[0m                                           )\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmega_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtestloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_bool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_data(num_epochs \u001b[38;5;241m+\u001b[39m start_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, task_id,\n\u001b[1;32m     84\u001b[0m                    testloaders, final_save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39mtrain_mode,\n\u001b[1;32m     85\u001b[0m                    record\u001b[38;5;241m=\u001b[39mrecord)  \u001b[38;5;66;03m# final eval\u001b[39;00m\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/learners/er_nocomponents.py:131\u001b[0m, in \u001b[0;36mNoComponentsER._train\u001b[0;34m(self, mega_loader, start_epoch, num_epochs, task_id, testloaders, save_freq, eval_bool, train_mode, record)\u001b[0m\n\u001b[1;32m    129\u001b[0m     l \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 131\u001b[0m     \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m save_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fleet.train_and_comm(task_id=task_id+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fleet.communicate(task_id=task_id, end_epoch=None, comm_freq=None, num_epochs=None,\n",
    "#                       final=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = fleet.agents[0]\n",
    "# # agent.incoming_models[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.net.structure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_L2(agent.net, copy.deepcopy(agent.net), verbose=True, excluded_params=agent.excluded_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
