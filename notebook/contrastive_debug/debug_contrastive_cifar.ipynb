{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_root_dir = \"cifar_lasttry_im_done_results\"\n",
    "save_root_dir = \"cifar_contrastive_no_dropout_results\"\n",
    "dataset = \"cifar100\"\n",
    "algo = \"modular\"\n",
    "num_train = 256\n",
    "seed = 0\n",
    "use_contrastive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f\"{dataset}_{algo}_numtrain_{num_train}\"\n",
    "if use_contrastive:\n",
    "    job_name += \"_contrastive\"\n",
    "experiment = os.path.join(save_root_dir, job_name, dataset,algo, f\"seed_{seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'component_update_freq': 200, 'num_epochs': 200, 'init_component_update_freq': 200, 'init_num_epochs': 200, 'save_freq': 20}, 'dataset': {'dataset_name': 'cifar100', 'num_tasks': 20, 'num_classes_per_task': 5, 'with_replacement': False, 'num_trains_per_class': 256, 'num_vals_per_class': -1, 'remap_labels': True}, 'net': {'name': 'cnn', 'depth': 4, 'channels': 50, 'conv_kernel': 3, 'maxpool_kernel': 2, 'padding': 1, 'dropout': 0.0}, 'sharing_strategy': {'name': 'no_sharing', 'num_coms_per_round': 0}, 'seed': 0, 'algo': 'modular', 'job_name': 'cifar100_modular_numtrain_256_contrastive', 'num_agents': 8, 'root_save_dir': 'cifar_contrastive_no_dropout_results', 'parallel': True, 'num_init_tasks': 4, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': True}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = os.path.join(experiment, \"hydra_out\", \".hydra\", \"config.yaml\")\n",
    "# read the config file\n",
    "cfg = omegaconf.OmegaConf.load(config_path)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'component_update_freq': 200, 'num_epochs': 200, 'init_component_update_freq': 200, 'init_num_epochs': 200, 'save_freq': 20}, 'dataset': {'dataset_name': 'cifar100', 'num_tasks': 20, 'num_classes_per_task': 5, 'with_replacement': False, 'num_trains_per_class': 256, 'num_vals_per_class': -1, 'remap_labels': True}, 'net': {'name': 'cnn', 'depth': 4, 'channels': 50, 'conv_kernel': 3, 'maxpool_kernel': 2, 'padding': 1, 'dropout': 0.0}, 'sharing_strategy': {'name': 'no_sharing', 'num_coms_per_round': 0}, 'seed': 0, 'algo': 'modular', 'job_name': 'cifar100_modular_numtrain_256_contrastive', 'num_agents': 8, 'root_save_dir': 'cifar_contrastive_no_dropout_results', 'parallel': True, 'num_init_tasks': 4, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': True}}\n",
      "i_size 32\n",
      "num_classes 5\n",
      "net_cfg {'name': 'cnn', 'depth': 4, 'channels': 50, 'conv_kernel': 3, 'maxpool_kernel': 2, 'padding': 1, 'dropout': 0.0, 'i_size': 32, 'num_classes': 5, 'num_tasks': 20, 'num_init_tasks': 4, 'use_contrastive': True}\n",
      "<class 'shell.learners.er_dynamic.CompositionalDynamicER'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph, datasets, NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg, fleet_additional_cfg = setup_experiment(cfg)\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir cifar_contrastive_no_dropout_results/cifar100_modular_numtrain_256_contrastive/cifar100/modular/seed_0/agent_0/task_5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNNSoftLLDynamic:\n\tUnexpected key(s) in state_dict: \"components.5.weight\", \"components.5.bias\". \n\tsize mismatch for structure.0: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.1: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.2: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.3: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.4: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.5: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.6: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.7: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.8: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.9: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.10: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.11: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.12: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.13: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.14: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.15: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.16: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.17: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.18: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.19: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for projector.0.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.0.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.1.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.1.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.2.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.2.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.3.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.3.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.4.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.4.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.5.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.5.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.6.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.6.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.7.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.7.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.8.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.8.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.9.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.9.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.10.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.10.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.11.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.11.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.12.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.12.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.13.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.13.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.14.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.14.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.15.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.15.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.16.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.16.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.17.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.17.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.18.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.18.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.19.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.19.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m task_id \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      3\u001b[0m num_added_components \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m net \u001b[39m=\u001b[39m load_net(cfg, NetCls, net_cfg, agent_id\u001b[39m=\u001b[39;49magent_id, task_id\u001b[39m=\u001b[39;49mtask_id, num_added_components\u001b[39m=\u001b[39;49mnum_added_components)\n\u001b[1;32m      5\u001b[0m net\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/utils/experiment_utils.py:112\u001b[0m, in \u001b[0;36mload_net\u001b[0;34m(cfg, NetCls, net_cfg, agent_id, task_id, num_added_components)\u001b[0m\n\u001b[1;32m    109\u001b[0m         net\u001b[39m.\u001b[39madd_tmp_module(\u001b[39mlen\u001b[39m(net\u001b[39m.\u001b[39mcomponents)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    111\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_dir, \u001b[39m\"\u001b[39m\u001b[39mcheckpoint.pt\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 112\u001b[0m net\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39mmodel_state_dict\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m net\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNNSoftLLDynamic:\n\tUnexpected key(s) in state_dict: \"components.5.weight\", \"components.5.bias\". \n\tsize mismatch for structure.0: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.1: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.2: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.3: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.4: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.5: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.6: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.7: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.8: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.9: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.10: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.11: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.12: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.13: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.14: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.15: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.16: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.17: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.18: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for structure.19: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([5, 4]).\n\tsize mismatch for projector.0.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.0.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.1.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.1.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.2.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.2.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.3.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.3.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.4.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.4.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.5.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.5.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.6.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.6.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.7.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.7.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.8.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.8.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.9.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.9.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.10.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.10.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.11.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.11.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.12.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.12.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.13.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.13.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.14.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.14.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.15.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.15.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.16.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.16.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.17.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.17.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.18.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.18.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for projector.19.2.weight: copying a param with shape torch.Size([32, 200]) from checkpoint, the shape in current model is torch.Size([64, 200]).\n\tsize mismatch for projector.19.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64])."
     ]
    }
   ],
   "source": [
    "agent_id = 0\n",
    "task_id = 5\n",
    "num_added_components = 1\n",
    "net = load_net(cfg, NetCls, net_cfg, agent_id=agent_id, task_id=task_id, num_added_components=num_added_components)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cifar_lasttry_fr_fr_results/cifar100_modular_numtrain_256_contrastive/cifar100/modular/seed_0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['agent']['save_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
