{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shell.fleet.fleet import Agent\n",
    "from shell.fleet.data.data_utilize import *\n",
    "from shell.fleet.data.recv import *\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.utils import make_grid\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [5 0 3 4 2 6 7 1 8 9]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "use_contrastive = True\n",
    "num_tasks = 4\n",
    "\n",
    "data_cfg = {\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"num_tasks\": num_tasks,\n",
    "    \"num_train_per_task\": 128,\n",
    "    \"num_val_per_task\": 102,\n",
    "    'remap_labels': True,\n",
    "    'use_contrastive': use_contrastive,\n",
    "}\n",
    "dataset = get_dataset(**data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [9 5 7 8 4 3 6 1 0 2]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(7)\n",
    "sender_dataset = get_dataset(**data_cfg)\n",
    "# send_data = sender_dataset.trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_cfg = {\n",
    "    'depth': 4,\n",
    "    'layer_size': 64,\n",
    "    'num_init_tasks': num_tasks,\n",
    "    'i_size': 28,\n",
    "    'num_classes': 2,\n",
    "    'num_tasks': 4,\n",
    "    'dropout': 0.0,\n",
    "}\n",
    "\n",
    "agent_cfg = {\n",
    "    'memory_size': 64,\n",
    "    'use_contrastive': use_contrastive,\n",
    "    'save_dir': 'test',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Agent: node_id: 0, seed: 0\n"
     ]
    }
   ],
   "source": [
    "NetCls = MLPSoftLLDynamic\n",
    "LearnerCls = CompositionalDynamicER\n",
    "sharing_cfg = DictConfig({\n",
    "    \"scorer\": \"cross_entropy\",\n",
    "    \"num_queries\": 4,\n",
    "    \"query_score_threshold\": 0.0,\n",
    "})\n",
    "train_cfg = {\n",
    "    # \"num_epochs\": 40,\n",
    "    \"num_epochs\": 1,\n",
    "}\n",
    "\n",
    "agent = RecvDataAgent(0, 0, dataset,\n",
    "                NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg, \n",
    "                sharing_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shell.datasets.datasets.CustomTensorDataset at 0x7f5224f59c30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_data = sender_dataset.trainset[0]\n",
    "send_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: 5, 5: 0, 7: 3, 8: 4, 4: 2, 3: 6, 6: 7, 1: 1, 0: 8, 2: 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sender_sequence = sender_dataset.class_sequence\n",
    "agent_sequence = dataset.class_sequence\n",
    "label_mapping = {sender_sequence[i]: agent_sequence[i] for i in range(len(sender_sequence))}\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'nonzero'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m         agent\u001b[39m.\u001b[39mtrain_on_new_task(X_task, Y_mapped, task_id\u001b[39m=\u001b[39mt)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Train the agent using global label approach\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m global_label_utilization(agent, send_data, sender_dataset, dataset)\n",
      "\u001b[1;32m/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m label_mapping \u001b[39m=\u001b[39m {sender_sequence[i]: agent_sequence[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sender_sequence))}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_tasks):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# Extract data corresponding to the current task from send_data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     task_indices \u001b[39m=\u001b[39m (send_data[\u001b[39m1\u001b[39;49m] \u001b[39m==\u001b[39;49m t)\u001b[39m.\u001b[39;49mnonzero(as_tuple\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     X_task \u001b[39m=\u001b[39m send_data[\u001b[39m0\u001b[39m][task_indices]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     Y_task \u001b[39m=\u001b[39m send_data[\u001b[39m1\u001b[39m][task_indices]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'nonzero'"
     ]
    }
   ],
   "source": [
    "def global_label_utilization(agent, send_data, sender_dataset, dataset):\n",
    "    # Create a label mapping based on the class sequences\n",
    "    sender_sequence = sender_dataset.class_sequence\n",
    "    agent_sequence = dataset.class_sequence\n",
    "\n",
    "    label_mapping = {sender_sequence[i]: agent_sequence[i] for i in range(len(sender_sequence))}\n",
    "\n",
    "    for t in range(num_tasks):\n",
    "        # Extract data corresponding to the current task from send_data\n",
    "        task_indices = (send_data[1] == t).nonzero(as_tuple=True)[0]\n",
    "        X_task = send_data[0][task_indices]\n",
    "        Y_task = send_data[1][task_indices]\n",
    "        \n",
    "        # Convert the sender's labels to agent's labels using global label mapping\n",
    "        Y_mapped = torch.tensor([label_mapping[y.item()] for y in Y_task])\n",
    "        \n",
    "        # Fit the model\n",
    "        agent.train_on_new_task(X_task, Y_mapped, task_id=t)\n",
    "\n",
    "# Train the agent using global label approach\n",
    "global_label_utilization(agent, send_data, sender_dataset, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
