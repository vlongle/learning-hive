{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39momegaconf\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mshell\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperiment_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mshell\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetric\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.130.50.18/home/vlongle/code/learning-hive/notebook/data/data_utilization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/utils/experiment_utils.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mFile: /experiment_utils.py\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mProject: utils\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mCopyright (c) 2023 Long Le\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msubprocess\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/__init__.py:1465\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m library\n\u001b[1;32m   1464\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m-> 1465\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _meta_registrations\n\u001b[1;32m   1467\u001b[0m \u001b[39m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mTORCH_CUDA_SANITIZER\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/_meta_registrations.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutils\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_decomp\u001b[39;00m \u001b[39mimport\u001b[39;00m _add_op_to_registry, global_decomposition_table, meta_table\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m OpOverload\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims\u001b[39;00m \u001b[39mimport\u001b[39;00m _elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/_decomp/__init__.py:169\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m decompositions\n\u001b[1;32m    168\u001b[0m \u001b[39m# populate the table\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_decomp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecompositions\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_refs\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# This list was copied from torch/_inductor/decomposition.py\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39m# excluding decompositions that results in prim ops\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m# Resulting opset of decomposition is core aten ops\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/_decomp/decompositions.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Callable, cast, Iterable, List, Optional, Tuple, Union\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mprims\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutils\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/_prims/__init__.py:33\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     check,\n\u001b[1;32m     19\u001b[0m     Dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     type_to_dtype,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m \u001b[39mimport\u001b[39;00m backwards_not_supported\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_subclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfake_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m FakeTensor, FakeTensorMode\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m \u001b[39mimport\u001b[39;00m handle_torch_function, has_torch_function\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pytree\u001b[39;00m \u001b[39mimport\u001b[39;00m tree_flatten, tree_map, tree_unflatten\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/_subclasses/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_subclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfake_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     DynamicOutputShapeException,\n\u001b[1;32m      5\u001b[0m     FakeTensor,\n\u001b[1;32m      6\u001b[0m     FakeTensorMode,\n\u001b[1;32m      7\u001b[0m     UnsupportedFakeTensorException,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_subclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfake_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m CrossRefFakeMode\n\u001b[1;32m     12\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFakeTensor\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFakeTensorMode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCrossRefFakeMode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_python_dispatch\u001b[39;00m \u001b[39mimport\u001b[39;00m TorchDispatchMode\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pytree\u001b[39;00m \u001b[39mimport\u001b[39;00m PyTree, tree_flatten, tree_map, tree_map_only\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_stats\u001b[39;00m \u001b[39mimport\u001b[39;00m count, count_label\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mweak\u001b[39;00m \u001b[39mimport\u001b[39;00m WeakIdRef\n\u001b[1;32m     32\u001b[0m log \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/site-packages/torch/utils/_stats.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedDict\n\u001b[0;32m----> 8\u001b[0m simple_call_counter: OrderedDict[\u001b[39mstr\u001b[39;49m, \u001b[39mint\u001b[39;49m] \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mOrderedDict()\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount_label\u001b[39m(label):\n\u001b[1;32m     11\u001b[0m     prev \u001b[39m=\u001b[39m simple_call_counter\u001b[39m.\u001b[39msetdefault(label, \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/typing.py:309\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m    308\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m         \u001b[39mreturn\u001b[39;00m cached(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    310\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m         \u001b[39mpass\u001b[39;00m  \u001b[39m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/typing.py:1145\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.__getitem__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1143\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(_type_check(p, msg) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params)\n\u001b[1;32m   1144\u001b[0m _check_generic(\u001b[39mself\u001b[39m, params, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nparams)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_with(params)\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/typing.py:1148\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.copy_with\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy_with\u001b[39m(\u001b[39mself\u001b[39m, params):\n\u001b[0;32m-> 1148\u001b[0m     \u001b[39mreturn\u001b[39;00m _GenericAlias(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__origin__, params,\n\u001b[1;32m   1149\u001b[0m                          name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, inst\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inst)\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/typing.py:1019\u001b[0m, in \u001b[0;36m_GenericAlias.__init__\u001b[0;34m(self, origin, params, inst, name, _typevar_types, _paramspec_tvars)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, origin, params, \u001b[39m*\u001b[39m, inst\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1017\u001b[0m              _typevar_types\u001b[39m=\u001b[39mTypeVar,\n\u001b[1;32m   1018\u001b[0m              _paramspec_tvars\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 1019\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(origin, inst\u001b[39m=\u001b[39;49minst, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1020\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(params, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m   1021\u001b[0m         params \u001b[39m=\u001b[39m (params,)\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/typing.py:948\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__init__\u001b[0;34m(self, origin, inst, name)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, origin, \u001b[39m*\u001b[39m, inst\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 948\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inst \u001b[39m=\u001b[39m inst\n\u001b[1;32m    949\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[1;32m    950\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__origin__ \u001b[39m=\u001b[39m origin\n",
      "File \u001b[0;32m~/miniconda3/envs/shell/lib/python3.10/typing.py:989\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__setattr__\u001b[0;34m(self, attr, val)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, attr, val):\n\u001b[1;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_dunder(attr) \u001b[39mor\u001b[39;00m attr \u001b[39min\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39m_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_inst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_nparams\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    988\u001b[0m                                     \u001b[39m'\u001b[39m\u001b[39m_typevar_types\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_paramspec_tvars\u001b[39m\u001b[39m'\u001b[39m}:\n\u001b[0;32m--> 989\u001b[0m         \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(attr, val)\n\u001b[1;32m    990\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    991\u001b[0m         \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__origin__, attr, val)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shell.fleet.fleet import Agent\n",
    "from shell.fleet.data.data_utilize import *\n",
    "from shell.fleet.data.recv import *\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.utils import make_grid\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [5 0 3 4 2 6 7 1 8 9]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "use_contrastive = True\n",
    "# use_contrastive = False\n",
    "num_tasks = 5\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "data_cfg = {\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"num_tasks\": num_tasks,\n",
    "    \"num_train_per_task\": 128,\n",
    "    \"num_val_per_task\": 102,\n",
    "    'remap_labels': True,\n",
    "    'use_contrastive': use_contrastive,\n",
    "    # 'with_replacement': True,\n",
    "}\n",
    "dataset = get_dataset(**data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [9 5 7 8 4 3 6 1 0 2]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(7)\n",
    "sender_dataset = get_dataset(**data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_cfg = {\n",
    "    'depth': 4,\n",
    "    'layer_size': 64,\n",
    "    'num_init_tasks': num_tasks,\n",
    "    'i_size': 28,\n",
    "    'num_classes': 2,\n",
    "    'num_tasks': num_tasks,\n",
    "    'dropout': 0.0,\n",
    "}\n",
    "\n",
    "agent_cfg = {\n",
    "    'memory_size': 64,\n",
    "    'use_contrastive': use_contrastive,\n",
    "    'save_dir': 'test',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Agent: node_id: 0, seed: 0\n"
     ]
    }
   ],
   "source": [
    "## MODULAR\n",
    "NetCls = MLPSoftLLDynamic\n",
    "LearnerCls = CompositionalDynamicER\n",
    "\n",
    "## MONOLITHIC\n",
    "NetCls = MLP\n",
    "LearnerCls = NoComponentsER\n",
    "\n",
    "sharing_cfg = DictConfig({\n",
    "    \"scorer\": \"cross_entropy\",\n",
    "    \"num_queries\": 4,\n",
    "    \"query_score_threshold\": 0.0,\n",
    "})\n",
    "train_cfg = {\n",
    "    # \"num_epochs\": 40,\n",
    "    \"num_epochs\": num_epochs,\n",
    "}\n",
    "\n",
    "agent = RecvDataAgent(0, 0, dataset,\n",
    "                NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg, \n",
    "                sharing_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenatedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(dataset) for dataset in self.datasets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Find the dataset which contains the data point with the given index\n",
    "        for i, dataset in enumerate(self.datasets):\n",
    "            if index < len(dataset):\n",
    "                break\n",
    "            index -= len(dataset)\n",
    "            \n",
    "        # Get the data from the dataset\n",
    "        x, y = dataset[index]\n",
    "        return x, y, i\n",
    "\n",
    "\n",
    "def concatenate_datasets(sender_trainset):\n",
    "    \"\"\"\n",
    "    Convert and concatenate sender_dataset.trainset into one big dataset.\n",
    "    \n",
    "    :param sender_trainset: List of datasets split by tasks.\n",
    "    :return: Dataset with items (X, y_source, task_source_id).\n",
    "    \"\"\"\n",
    "    \n",
    "    return ConcatenatedDataset(sender_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = concatenate_datasets(sender_dataset.trainset)\n",
    "transformed_data = utilize_global_labels(combined_data, source_class_sequence=sender_dataset.class_sequence, target_class_sequence=\n",
    "                                         dataset.class_sequence, num_classes_per_task=dataset.num_classes_per_task)\n",
    "\n",
    "flipped_data = RandomFlippedDataset(transformed_data, flip_probability=1.0, num_classes=\n",
    "                                    dataset.num_classes_per_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epochs: 0, training task: 0\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: avg\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:epochs: 0, training task: 0\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: avg\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:epochs: 0, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: avg\tloss: 0.693\tacc: 0.508\n",
      "INFO:root:epochs: 0, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: avg\tloss: 0.693\tacc: 0.508\n",
      "INFO:root:epochs: 0, training task: 2\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.499\n",
      "INFO:root:epochs: 0, training task: 2\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.499\n",
      "INFO:root:epochs: 0, training task: 3\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.697\tacc: 0.475\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:epochs: 0, training task: 3\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.697\tacc: 0.475\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:epochs: 0, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.697\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.695\tacc: 0.491\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:epochs: 1, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.690\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.699\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.696\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.696\tacc: 0.491\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:epochs: 2, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.689\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.697\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.697\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.698\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.699\tacc: 0.486\n",
      "INFO:root:\ttask: avg\tloss: 0.696\tacc: 0.492\n",
      "INFO:root:epochs: 3, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.688\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.699\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.694\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.700\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.704\tacc: 0.366\n",
      "INFO:root:\ttask: avg\tloss: 0.697\tacc: 0.468\n",
      "INFO:root:epochs: 4, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.684\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.700\tacc: 0.395\n",
      "INFO:root:\ttask: 2\tloss: 0.690\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.699\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.704\tacc: 0.387\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.453\n",
      "INFO:root:epochs: 5, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.683\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.698\tacc: 0.371\n",
      "INFO:root:\ttask: 2\tloss: 0.687\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.697\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.704\tacc: 0.322\n",
      "INFO:root:\ttask: avg\tloss: 0.694\tacc: 0.435\n",
      "INFO:root:epochs: 6, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.683\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.697\tacc: 0.405\n",
      "INFO:root:\ttask: 2\tloss: 0.684\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.695\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.703\tacc: 0.363\n",
      "INFO:root:\ttask: avg\tloss: 0.692\tacc: 0.450\n",
      "INFO:root:epochs: 7, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.681\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.695\tacc: 0.445\n",
      "INFO:root:\ttask: 2\tloss: 0.680\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.693\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.702\tacc: 0.345\n",
      "INFO:root:\ttask: avg\tloss: 0.690\tacc: 0.454\n",
      "INFO:root:epochs: 8, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.679\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.511\n",
      "INFO:root:\ttask: 2\tloss: 0.677\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.691\tacc: 0.581\n",
      "INFO:root:\ttask: 4\tloss: 0.701\tacc: 0.351\n",
      "INFO:root:\ttask: avg\tloss: 0.688\tacc: 0.490\n",
      "INFO:root:epochs: 9, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.678\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.691\tacc: 0.617\n",
      "INFO:root:\ttask: 2\tloss: 0.675\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.689\tacc: 0.810\n",
      "INFO:root:\ttask: 4\tloss: 0.700\tacc: 0.369\n",
      "INFO:root:\ttask: avg\tloss: 0.687\tacc: 0.560\n",
      "INFO:root:epochs: 10, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.675\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.689\tacc: 0.669\n",
      "INFO:root:\ttask: 2\tloss: 0.671\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.686\tacc: 0.805\n",
      "INFO:root:\ttask: 4\tloss: 0.699\tacc: 0.385\n",
      "INFO:root:\ttask: avg\tloss: 0.684\tacc: 0.573\n",
      "INFO:root:epochs: 11, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.674\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.687\tacc: 0.722\n",
      "INFO:root:\ttask: 2\tloss: 0.668\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.684\tacc: 0.779\n",
      "INFO:root:\ttask: 4\tloss: 0.697\tacc: 0.431\n",
      "INFO:root:\ttask: avg\tloss: 0.682\tacc: 0.587\n",
      "INFO:root:epochs: 12, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.672\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.682\tacc: 0.817\n",
      "INFO:root:\ttask: 2\tloss: 0.665\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.682\tacc: 0.730\n",
      "INFO:root:\ttask: 4\tloss: 0.695\tacc: 0.447\n",
      "INFO:root:\ttask: avg\tloss: 0.679\tacc: 0.600\n",
      "INFO:root:epochs: 13, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.669\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.680\tacc: 0.813\n",
      "INFO:root:\ttask: 2\tloss: 0.664\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.679\tacc: 0.712\n",
      "INFO:root:\ttask: 4\tloss: 0.693\tacc: 0.463\n",
      "INFO:root:\ttask: avg\tloss: 0.677\tacc: 0.599\n",
      "INFO:root:epochs: 14, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.667\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.674\tacc: 0.893\n",
      "INFO:root:\ttask: 2\tloss: 0.658\tacc: 0.482\n",
      "INFO:root:\ttask: 3\tloss: 0.677\tacc: 0.788\n",
      "INFO:root:\ttask: 4\tloss: 0.690\tacc: 0.504\n",
      "INFO:root:\ttask: avg\tloss: 0.673\tacc: 0.638\n",
      "INFO:root:epochs: 15, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.663\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.669\tacc: 0.920\n",
      "INFO:root:\ttask: 2\tloss: 0.658\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.672\tacc: 0.871\n",
      "INFO:root:\ttask: 4\tloss: 0.688\tacc: 0.611\n",
      "INFO:root:\ttask: avg\tloss: 0.670\tacc: 0.681\n",
      "INFO:root:epochs: 16, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.659\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.668\tacc: 0.867\n",
      "INFO:root:\ttask: 2\tloss: 0.655\tacc: 0.504\n",
      "INFO:root:\ttask: 3\tloss: 0.671\tacc: 0.770\n",
      "INFO:root:\ttask: 4\tloss: 0.686\tacc: 0.649\n",
      "INFO:root:\ttask: avg\tloss: 0.668\tacc: 0.663\n",
      "INFO:root:epochs: 17, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.657\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.662\tacc: 0.944\n",
      "INFO:root:\ttask: 2\tloss: 0.647\tacc: 0.526\n",
      "INFO:root:\ttask: 3\tloss: 0.666\tacc: 0.864\n",
      "INFO:root:\ttask: 4\tloss: 0.683\tacc: 0.756\n",
      "INFO:root:\ttask: avg\tloss: 0.663\tacc: 0.723\n",
      "INFO:root:epochs: 18, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.652\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.659\tacc: 0.909\n",
      "INFO:root:\ttask: 2\tloss: 0.646\tacc: 0.615\n",
      "INFO:root:\ttask: 3\tloss: 0.665\tacc: 0.792\n",
      "INFO:root:\ttask: 4\tloss: 0.680\tacc: 0.790\n",
      "INFO:root:\ttask: avg\tloss: 0.660\tacc: 0.726\n",
      "INFO:root:epochs: 19, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.651\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.656\tacc: 0.935\n",
      "INFO:root:\ttask: 2\tloss: 0.643\tacc: 0.633\n",
      "INFO:root:\ttask: 3\tloss: 0.661\tacc: 0.850\n",
      "INFO:root:\ttask: 4\tloss: 0.678\tacc: 0.817\n",
      "INFO:root:\ttask: avg\tloss: 0.658\tacc: 0.752\n",
      "INFO:root:epochs: 20, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.649\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.649\tacc: 0.956\n",
      "INFO:root:\ttask: 2\tloss: 0.637\tacc: 0.657\n",
      "INFO:root:\ttask: 3\tloss: 0.657\tacc: 0.894\n",
      "INFO:root:\ttask: 4\tloss: 0.675\tacc: 0.861\n",
      "INFO:root:\ttask: avg\tloss: 0.653\tacc: 0.778\n",
      "INFO:root:epochs: 21, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.649\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.649\tacc: 0.956\n",
      "INFO:root:\ttask: 2\tloss: 0.637\tacc: 0.657\n",
      "INFO:root:\ttask: 3\tloss: 0.657\tacc: 0.894\n",
      "INFO:root:\ttask: 4\tloss: 0.675\tacc: 0.861\n",
      "INFO:root:\ttask: avg\tloss: 0.653\tacc: 0.778\n"
     ]
    }
   ],
   "source": [
    "# before additional data\n",
    "for t in range(num_tasks):\n",
    "    agent.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epochs: 1, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.684\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.680\tacc: 0.803\n",
      "INFO:root:\ttask: 2\tloss: 0.671\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.679\tacc: 0.799\n",
      "INFO:root:\ttask: 4\tloss: 0.686\tacc: 0.787\n",
      "INFO:root:\ttask: avg\tloss: 0.680\tacc: 0.679\n",
      "INFO:root:epochs: 2, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.694\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.502\n",
      "INFO:root:\ttask: 2\tloss: 0.687\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.690\tacc: 0.689\n",
      "INFO:root:\ttask: 4\tloss: 0.691\tacc: 0.682\n",
      "INFO:root:\ttask: avg\tloss: 0.691\tacc: 0.576\n",
      "INFO:root:epochs: 3, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.696\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.696\tacc: 0.387\n",
      "INFO:root:\ttask: 2\tloss: 0.690\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.693\tacc: 0.546\n",
      "INFO:root:\ttask: 4\tloss: 0.692\tacc: 0.609\n",
      "INFO:root:\ttask: avg\tloss: 0.693\tacc: 0.509\n",
      "INFO:root:epochs: 4, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.695\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.697\tacc: 0.378\n",
      "INFO:root:\ttask: 2\tloss: 0.691\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.693\tacc: 0.505\n",
      "INFO:root:\ttask: 4\tloss: 0.692\tacc: 0.543\n",
      "INFO:root:\ttask: avg\tloss: 0.694\tacc: 0.486\n",
      "INFO:root:epochs: 5, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.695\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.696\tacc: 0.382\n",
      "INFO:root:\ttask: 2\tloss: 0.691\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.693\tacc: 0.556\n",
      "INFO:root:\ttask: 4\tloss: 0.692\tacc: 0.586\n",
      "INFO:root:\ttask: avg\tloss: 0.694\tacc: 0.506\n",
      "INFO:root:epochs: 6, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.695\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.696\tacc: 0.350\n",
      "INFO:root:\ttask: 2\tloss: 0.691\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.693\tacc: 0.595\n",
      "INFO:root:\ttask: 4\tloss: 0.692\tacc: 0.602\n",
      "INFO:root:\ttask: avg\tloss: 0.693\tacc: 0.510\n"
     ]
    }
   ],
   "source": [
    "# mega_loader = torch.utils.data.DataLoader(transformed_data, batch_size=64, shuffle=True)\n",
    "mega_loader = torch.utils.data.DataLoader(flipped_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "task_id = num_tasks-1\n",
    "testloaders = {task: torch.utils.data.DataLoader(testset,\n",
    "                                                         batch_size=256,\n",
    "                                                         shuffle=False,\n",
    "                                                         num_workers=4,\n",
    "                                                         pin_memory=True,\n",
    "                                                         ) for task, testset in enumerate(agent.dataset.testset[:(task_id+1)])}\n",
    "\n",
    "\n",
    "agent.agent._train(mega_loader, num_epochs=num_epochs,\n",
    "                   task_id=task_id, testloaders=testloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
