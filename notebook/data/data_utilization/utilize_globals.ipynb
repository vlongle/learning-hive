{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shell.fleet.fleet import Agent\n",
    "from shell.fleet.data.data_utilize import *\n",
    "from shell.fleet.data.recv import *\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.utils import make_grid\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [5 0 3 4 2 6 7 1 8 9]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "use_contrastive = True\n",
    "# use_contrastive = False\n",
    "num_tasks = 5\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "data_cfg = {\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"num_tasks\": num_tasks,\n",
    "    \"num_train_per_task\": 128,\n",
    "    \"num_val_per_task\": 102,\n",
    "    'remap_labels': True,\n",
    "    'use_contrastive': use_contrastive,\n",
    "    # 'with_replacement': True,\n",
    "}\n",
    "dataset = get_dataset(**data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [9 5 7 8 4 3 6 1 0 2]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(7)\n",
    "sender_dataset = get_dataset(**data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_cfg = {\n",
    "    'depth': 4,\n",
    "    'layer_size': 64,\n",
    "    'num_init_tasks': num_tasks,\n",
    "    'i_size': 28,\n",
    "    'num_classes': 2,\n",
    "    'num_tasks': num_tasks,\n",
    "    'dropout': 0.0,\n",
    "}\n",
    "\n",
    "agent_cfg = {\n",
    "    'memory_size': 64,\n",
    "    'use_contrastive': use_contrastive,\n",
    "    'save_dir': 'test',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Agent: node_id: 0, seed: 0\n"
     ]
    }
   ],
   "source": [
    "## MODULAR\n",
    "NetCls = MLPSoftLLDynamic\n",
    "LearnerCls = CompositionalDynamicER\n",
    "\n",
    "## MONOLITHIC\n",
    "NetCls = MLP\n",
    "LearnerCls = NoComponentsER\n",
    "\n",
    "sharing_cfg = DictConfig({\n",
    "    \"scorer\": \"cross_entropy\",\n",
    "    \"num_queries\": 4,\n",
    "    \"query_score_threshold\": 0.0,\n",
    "})\n",
    "train_cfg = {\n",
    "    # \"num_epochs\": 40,\n",
    "    \"num_epochs\": num_epochs,\n",
    "}\n",
    "\n",
    "agent = RecvDataAgent(0, 0, dataset,\n",
    "                NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg, \n",
    "                sharing_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenatedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(dataset) for dataset in self.datasets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Find the dataset which contains the data point with the given index\n",
    "        for task_id, dataset in enumerate(self.datasets):\n",
    "            if index < len(dataset):\n",
    "                break\n",
    "            index -= len(dataset)\n",
    "            \n",
    "        # Get the data from the dataset\n",
    "        x, y = dataset[index]\n",
    "        return x, y, task_id\n",
    "\n",
    "\n",
    "def concatenate_datasets(sender_trainset):\n",
    "    \"\"\"\n",
    "    Convert and concatenate sender_dataset.trainset into one big dataset.\n",
    "    \n",
    "    :param sender_trainset: List of datasets split by tasks.\n",
    "    :return: Dataset with items (X, y_source, task_source_id).\n",
    "    \"\"\"\n",
    "    \n",
    "    return ConcatenatedDataset(sender_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = concatenate_datasets(sender_dataset.trainset)\n",
    "transformed_data = utilize_global_labels(combined_data, source_class_sequence=sender_dataset.class_sequence, target_class_sequence=\n",
    "                                         dataset.class_sequence, num_classes_per_task=dataset.num_classes_per_task)\n",
    "\n",
    "# flipped_data = RandomFlippedDataset(transformed_data, flip_probability=1.0, num_classes=\n",
    "#                                     dataset.num_classes_per_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epochs: 0, training task: 0\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: avg\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:epochs: 0, training task: 0\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: avg\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:epochs: 0, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: avg\tloss: 0.693\tacc: 0.508\n",
      "INFO:root:epochs: 0, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: avg\tloss: 0.693\tacc: 0.508\n",
      "INFO:root:epochs: 0, training task: 2\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.499\n",
      "INFO:root:epochs: 0, training task: 2\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.499\n",
      "INFO:root:epochs: 0, training task: 3\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.697\tacc: 0.475\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:epochs: 0, training task: 3\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.697\tacc: 0.475\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:epochs: 0, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.691\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.700\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.697\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.695\tacc: 0.491\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:epochs: 1, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.690\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.699\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.696\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.696\tacc: 0.491\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.493\n",
      "INFO:root:epochs: 2, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.689\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.697\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.697\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.698\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.699\tacc: 0.486\n",
      "INFO:root:\ttask: avg\tloss: 0.696\tacc: 0.492\n",
      "INFO:root:epochs: 3, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.688\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.699\tacc: 0.493\n",
      "INFO:root:\ttask: 2\tloss: 0.694\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.700\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.704\tacc: 0.366\n",
      "INFO:root:\ttask: avg\tloss: 0.697\tacc: 0.468\n",
      "INFO:root:epochs: 4, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.684\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.700\tacc: 0.395\n",
      "INFO:root:\ttask: 2\tloss: 0.690\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.699\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.704\tacc: 0.387\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.453\n",
      "INFO:root:epochs: 5, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.683\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.698\tacc: 0.371\n",
      "INFO:root:\ttask: 2\tloss: 0.687\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.697\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.704\tacc: 0.322\n",
      "INFO:root:\ttask: avg\tloss: 0.694\tacc: 0.435\n",
      "INFO:root:epochs: 6, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.683\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.697\tacc: 0.405\n",
      "INFO:root:\ttask: 2\tloss: 0.684\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.695\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.703\tacc: 0.363\n",
      "INFO:root:\ttask: avg\tloss: 0.692\tacc: 0.450\n",
      "INFO:root:epochs: 7, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.681\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.695\tacc: 0.445\n",
      "INFO:root:\ttask: 2\tloss: 0.680\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.693\tacc: 0.475\n",
      "INFO:root:\ttask: 4\tloss: 0.702\tacc: 0.345\n",
      "INFO:root:\ttask: avg\tloss: 0.690\tacc: 0.454\n",
      "INFO:root:epochs: 8, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.679\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.511\n",
      "INFO:root:\ttask: 2\tloss: 0.677\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.691\tacc: 0.581\n",
      "INFO:root:\ttask: 4\tloss: 0.701\tacc: 0.351\n",
      "INFO:root:\ttask: avg\tloss: 0.688\tacc: 0.490\n",
      "INFO:root:epochs: 9, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.678\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.691\tacc: 0.617\n",
      "INFO:root:\ttask: 2\tloss: 0.675\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.689\tacc: 0.810\n",
      "INFO:root:\ttask: 4\tloss: 0.700\tacc: 0.369\n",
      "INFO:root:\ttask: avg\tloss: 0.687\tacc: 0.560\n",
      "INFO:root:epochs: 10, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.675\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.689\tacc: 0.669\n",
      "INFO:root:\ttask: 2\tloss: 0.671\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.686\tacc: 0.805\n",
      "INFO:root:\ttask: 4\tloss: 0.699\tacc: 0.385\n",
      "INFO:root:\ttask: avg\tloss: 0.684\tacc: 0.573\n",
      "INFO:root:epochs: 11, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.675\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.689\tacc: 0.669\n",
      "INFO:root:\ttask: 2\tloss: 0.671\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.686\tacc: 0.805\n",
      "INFO:root:\ttask: 4\tloss: 0.699\tacc: 0.385\n",
      "INFO:root:\ttask: avg\tloss: 0.684\tacc: 0.573\n"
     ]
    }
   ],
   "source": [
    "# before additional data\n",
    "for t in range(num_tasks):\n",
    "    agent.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epochs: 1, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.669\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.679\tacc: 0.831\n",
      "INFO:root:\ttask: 2\tloss: 0.664\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.676\tacc: 0.888\n",
      "INFO:root:\ttask: 4\tloss: 0.692\tacc: 0.475\n",
      "INFO:root:\ttask: avg\tloss: 0.676\tacc: 0.640\n",
      "INFO:root:epochs: 2, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.662\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.670\tacc: 0.900\n",
      "INFO:root:\ttask: 2\tloss: 0.659\tacc: 0.481\n",
      "INFO:root:\ttask: 3\tloss: 0.669\tacc: 0.946\n",
      "INFO:root:\ttask: 4\tloss: 0.687\tacc: 0.726\n",
      "INFO:root:\ttask: avg\tloss: 0.670\tacc: 0.715\n",
      "INFO:root:epochs: 3, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.653\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.666\tacc: 0.906\n",
      "INFO:root:\ttask: 2\tloss: 0.652\tacc: 0.533\n",
      "INFO:root:\ttask: 3\tloss: 0.664\tacc: 0.968\n",
      "INFO:root:\ttask: 4\tloss: 0.684\tacc: 0.795\n",
      "INFO:root:\ttask: avg\tloss: 0.664\tacc: 0.745\n",
      "INFO:root:epochs: 4, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.650\tacc: 0.524\n",
      "INFO:root:\ttask: 1\tloss: 0.657\tacc: 0.939\n",
      "INFO:root:\ttask: 2\tloss: 0.647\tacc: 0.589\n",
      "INFO:root:\ttask: 3\tloss: 0.658\tacc: 0.978\n",
      "INFO:root:\ttask: 4\tloss: 0.679\tacc: 0.881\n",
      "INFO:root:\ttask: avg\tloss: 0.658\tacc: 0.782\n",
      "INFO:root:epochs: 5, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.642\tacc: 0.619\n",
      "INFO:root:\ttask: 1\tloss: 0.651\tacc: 0.945\n",
      "INFO:root:\ttask: 2\tloss: 0.640\tacc: 0.608\n",
      "INFO:root:\ttask: 3\tloss: 0.650\tacc: 0.983\n",
      "INFO:root:\ttask: 4\tloss: 0.675\tacc: 0.877\n",
      "INFO:root:\ttask: avg\tloss: 0.652\tacc: 0.806\n",
      "INFO:root:epochs: 6, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.635\tacc: 0.756\n",
      "INFO:root:\ttask: 1\tloss: 0.645\tacc: 0.949\n",
      "INFO:root:\ttask: 2\tloss: 0.634\tacc: 0.717\n",
      "INFO:root:\ttask: 3\tloss: 0.643\tacc: 0.973\n",
      "INFO:root:\ttask: 4\tloss: 0.671\tacc: 0.886\n",
      "INFO:root:\ttask: avg\tloss: 0.646\tacc: 0.856\n",
      "INFO:root:epochs: 7, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.626\tacc: 0.793\n",
      "INFO:root:\ttask: 1\tloss: 0.638\tacc: 0.949\n",
      "INFO:root:\ttask: 2\tloss: 0.626\tacc: 0.876\n",
      "INFO:root:\ttask: 3\tloss: 0.636\tacc: 0.970\n",
      "INFO:root:\ttask: 4\tloss: 0.665\tacc: 0.914\n",
      "INFO:root:\ttask: avg\tloss: 0.638\tacc: 0.901\n",
      "INFO:root:epochs: 8, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.619\tacc: 0.844\n",
      "INFO:root:\ttask: 1\tloss: 0.627\tacc: 0.962\n",
      "INFO:root:\ttask: 2\tloss: 0.615\tacc: 0.871\n",
      "INFO:root:\ttask: 3\tloss: 0.631\tacc: 0.976\n",
      "INFO:root:\ttask: 4\tloss: 0.659\tacc: 0.892\n",
      "INFO:root:\ttask: avg\tloss: 0.630\tacc: 0.909\n",
      "INFO:root:epochs: 9, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.608\tacc: 0.876\n",
      "INFO:root:\ttask: 1\tloss: 0.619\tacc: 0.963\n",
      "INFO:root:\ttask: 2\tloss: 0.608\tacc: 0.887\n",
      "INFO:root:\ttask: 3\tloss: 0.621\tacc: 0.946\n",
      "INFO:root:\ttask: 4\tloss: 0.653\tacc: 0.874\n",
      "INFO:root:\ttask: avg\tloss: 0.622\tacc: 0.909\n",
      "INFO:root:epochs: 10, training task: 4\n",
      "INFO:root:\ttask: 0\tloss: 0.600\tacc: 0.892\n",
      "INFO:root:\ttask: 1\tloss: 0.604\tacc: 0.968\n",
      "INFO:root:\ttask: 2\tloss: 0.598\tacc: 0.908\n",
      "INFO:root:\ttask: 3\tloss: 0.613\tacc: 0.953\n",
      "INFO:root:\ttask: 4\tloss: 0.643\tacc: 0.890\n",
      "INFO:root:\ttask: avg\tloss: 0.612\tacc: 0.922\n"
     ]
    }
   ],
   "source": [
    "mega_loader = torch.utils.data.DataLoader(transformed_data, batch_size=64, shuffle=True)\n",
    "# mega_loader = torch.utils.data.DataLoader(flipped_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "task_id = num_tasks-1\n",
    "testloaders = {task: torch.utils.data.DataLoader(testset,\n",
    "                                                         batch_size=256,\n",
    "                                                         shuffle=False,\n",
    "                                                         num_workers=4,\n",
    "                                                         pin_memory=True,\n",
    "                                                         ) for task, testset in enumerate(agent.dataset.testset[:(task_id+1)])}\n",
    "\n",
    "\n",
    "agent.agent._train(mega_loader, num_epochs=num_epochs,\n",
    "                   task_id=task_id, testloaders=testloaders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
