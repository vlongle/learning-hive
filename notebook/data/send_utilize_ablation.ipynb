{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shell.fleet.fleet import Agent\n",
    "from shell.fleet.data.send_utilize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_root_dir = \"vanilla_results\"\n",
    "save_root_dir = \"vanilla_remove_datasets_hack_results\"\n",
    "dataset = \"mnist\"\n",
    "algo = \"modular\"\n",
    "num_train = 64\n",
    "seed = 0\n",
    "use_contrastive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f\"{dataset}_{algo}_numtrain_{num_train}\"\n",
    "if use_contrastive:\n",
    "    job_name += \"_contrastive\"\n",
    "experiment = os.path.join(save_root_dir, job_name, dataset,algo, f\"seed_{seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'component_update_freq': 100, 'num_epochs': 100, 'init_component_update_freq': 100, 'init_num_epochs': 100, 'save_freq': 1}, 'dataset': {'dataset_name': 'mnist', 'num_tasks': 10, 'num_classes_per_task': 2, 'with_replacement': True, 'num_trains_per_class': 64, 'num_vals_per_class': 50, 'remap_labels': True}, 'net': {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.0}, 'sharing_strategy': {'name': 'no_sharing', 'num_coms_per_round': 0}, 'seed': 0, 'algo': 'modular', 'job_name': 'mnist_modular_numtrain_64_contrastive', 'num_agents': 8, 'root_save_dir': 'vanilla_remove_datasets_hack_results', 'parallel': True, 'num_init_tasks': 4, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': True}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = os.path.join(experiment, \"hydra_out\", \".hydra\", \"config.yaml\")\n",
    "# read the config file\n",
    "cfg = omegaconf.OmegaConf.load(config_path)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'component_update_freq': 100, 'num_epochs': 100, 'init_component_update_freq': 100, 'init_num_epochs': 100, 'save_freq': 1}, 'dataset': {'dataset_name': 'mnist', 'num_tasks': 10, 'num_classes_per_task': 2, 'with_replacement': True, 'num_trains_per_class': 64, 'num_vals_per_class': 50, 'remap_labels': True}, 'net': {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.0}, 'sharing_strategy': {'name': 'no_sharing', 'num_coms_per_round': 0}, 'seed': 0, 'algo': 'modular', 'job_name': 'mnist_modular_numtrain_64_contrastive', 'num_agents': 8, 'root_save_dir': 'vanilla_remove_datasets_hack_results', 'parallel': True, 'num_init_tasks': 4, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': True}}\n",
      "i_size 28\n",
      "num_classes 2\n",
      "net_cfg {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.0, 'i_size': 28, 'num_classes': 2, 'num_tasks': 10, 'num_init_tasks': 4, 'use_contrastive': True}\n",
      "<class 'shell.learners.er_dynamic.CompositionalDynamicER'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph, datasets, NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg, fleet_additional_cfg = setup_experiment(cfg)\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5, 0, 4, 3, 4, 6, 4, 3, 8, 0, 1, 0, 5, 9, 6, 4, 9, 0, 3, 0]),\n",
       " array([4, 7, 5, 7, 6, 0, 3, 0, 5, 0, 3, 6, 2, 7, 6, 7, 6, 1, 0, 5]),\n",
       " array([6, 7, 7, 8, 4, 1, 1, 8, 6, 1, 6, 4, 5, 7, 8, 0, 2, 3, 0, 3]),\n",
       " array([2, 8, 0, 3, 7, 4, 3, 4, 4, 5, 9, 3, 0, 6, 9, 1, 3, 1, 7, 9]),\n",
       " array([0, 3, 0, 2, 9, 7, 0, 9, 2, 1, 7, 6, 8, 6, 1, 8, 6, 4, 9, 8]),\n",
       " array([8, 4, 6, 3, 3, 1, 1, 6, 4, 9, 3, 2, 2, 9, 6, 0, 5, 9, 7, 2]),\n",
       " array([7, 5, 8, 4, 6, 9, 8, 3, 4, 6, 1, 3, 3, 1, 4, 1, 9, 2, 6, 2]),\n",
       " array([5, 1, 8, 3, 9, 6, 5, 9, 5, 0, 7, 2, 7, 8, 6, 1, 6, 0, 0, 6])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_sequence_list = [dataset.class_sequence for dataset in datasets]\n",
    "classes_sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = 3\n",
    "num_added_components = None\n",
    "agent_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[agent_id]\n",
    "testloaders = {task: torch.utils.data.DataLoader(testset,\n",
    "                                                         batch_size=128,\n",
    "                                                         shuffle=False,\n",
    "                                                         num_workers=0,\n",
    "                                                         pin_memory=True,\n",
    "                                                         ) for task, testset in enumerate(dataset.testset[:(task_id+1)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(agent_id, seed, dataset,\n",
    "                NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg, \n",
    "                cfg.sharing_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPSoftLLDynamic(\n",
       "  (structure): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (1): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (2): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (3): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (4): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (5): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (6): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (7): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (8): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "      (9): Parameter containing: [torch.float32 of size 4x4 (GPU 0)]\n",
       "  )\n",
       "  (softmax): Softmax(dim=0)\n",
       "  (components): ModuleList(\n",
       "    (0-3): 4 x Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (random_linear_projection): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (decoder): ModuleList(\n",
       "    (0-9): 10 x Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.net = load_net(cfg, NetCls, net_cfg, agent_id=agent_id, task_id=task_id, num_added_components=num_added_components)\n",
    "agent.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9668803418803419,\n",
       " 1: 0.9844377510040161,\n",
       " 2: 0.9788659793814433,\n",
       " 3: 0.9799196787148594,\n",
       " 'avg': 0.9775259377451653}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_net(agent.net, testloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 3, 4, 5, 6}\n",
      "{0, 3, 4, 5, 6, 7}\n"
     ]
    }
   ],
   "source": [
    "num_classes_per_task = cfg.dataset.num_classes_per_task\n",
    "print(set(dataset.class_sequence[:(task_id + 1)* num_classes_per_task]))\n",
    "print(set(datasets[1].class_sequence[:(task_id + 1)* num_classes_per_task]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
