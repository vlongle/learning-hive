{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.fleet.utils.fleet_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shell.fleet.fleet import Agent, Fleet\n",
    "from shell.fleet.data.data_utilize import *\n",
    "from shell.fleet.data.recv import *\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.utils import make_grid\n",
    "from shell.fleet.data.data_utilize import *\n",
    "import logging\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from shell.fleet.data.recv_utils import *\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from functools import partial\n",
    "from torchvision.utils import make_grid\n",
    "from shell.utils.oodloss import OODSeparationLoss\n",
    "from pythresh.thresholds.dsn import DSN\n",
    "from pythresh.thresholds.aucp import AUCP\n",
    "from pythresh.thresholds.boot import BOOT\n",
    "from pythresh.thresholds.zscore import ZSCORE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [5 0 4 3 4 6 4 3 8 0 1 0 5 9 6 4 9 0 3 0]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'component_update_freq': 100, 'num_epochs': 100, 'init_component_update_freq': 100, 'init_num_epochs': 100, 'save_freq': 20}, 'dataset': {'dataset_name': 'mnist', 'num_tasks': 10, 'num_classes_per_task': 2, 'with_replacement': True, 'num_trains_per_class': 64, 'num_vals_per_class': 50, 'remap_labels': True}, 'net': {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.0}, 'sharing_strategy': {'name': 'no_sharing', 'num_coms_per_round': 0}, 'seed': 0, 'algo': 'modular', 'job_name': 'mnist_modular_numtrain_64_contrastive', 'num_agents': 8, 'root_save_dir': 'experiment_results/vanilla_fix_bug_compute_loss_encodev2', 'parallel': True, 'num_init_tasks': 4, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': True}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [4 7 5 7 6 0 3 0 5 0 3 6 2 7 6 7 6 1 0 5]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [6 7 7 8 4 1 1 8 6 1 6 4 5 7 8 0 2 3 0 3]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [2 8 0 3 7 4 3 4 4 5 9 3 0 6 9 1 3 1 7 9]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [0 3 0 2 9 7 0 9 2 1 7 6 8 6 1 8 6 4 9 8]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [8 4 6 3 3 1 1 6 4 9 3 2 2 9 6 0 5 9 7 2]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [7 5 8 4 6 9 8 3 4 6 1 3 3 1 4 1 9 2 6 2]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n",
      "INFO:root:Class sequence: [5 1 8 3 9 6 5 9 5 0 7 2 7 8 6 1 6 0 0 6]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n",
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_size 28\n",
      "num_classes 2\n",
      "net_cfg {'name': 'mlp', 'depth': 4, 'layer_size': 64, 'dropout': 0.0, 'i_size': 28, 'num_classes': 2, 'num_tasks': 10, 'num_init_tasks': 4, 'use_contrastive': True}\n",
      "<class 'shell.learners.er_dynamic.CompositionalDynamicER'>\n"
     ]
    }
   ],
   "source": [
    "dataset = \"mnist\"\n",
    "algo = \"modular\"\n",
    "prefilter_strategy = \"oracle\"\n",
    "scorer = \"cross_entropy\"\n",
    "\n",
    "experiment_folder = \"experiment_results\"\n",
    "experiment_name = \"vanilla_fix_bug_compute_loss_encodev2\"\n",
    "\n",
    "use_contrastive = True\n",
    "num_trains_per_class = 64\n",
    "seed = 0\n",
    "num_tasks = 10\n",
    "parallel = False\n",
    "comm_freq = None  # \"None\" means no communication, doesn't matter for this analysis\n",
    "\n",
    "\n",
    "save_dir = get_save_dir(experiment_folder, experiment_name,\n",
    "                        dataset, algo, num_trains_per_class, use_contrastive, seed)\n",
    "graph, datasets, NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg, fleet_additional_cfg, cfg = get_cfg(\n",
    "    save_dir)\n",
    "\n",
    "cfg.sharing_strategy = DictConfig({\n",
    "    \"name\": \"recv_data\",\n",
    "    \"scorer\": scorer,\n",
    "    \"num_queries\": 5,\n",
    "    'num_data_neighbors': 5,\n",
    "    'num_filter_neighbors': 5,\n",
    "    'num_coms_per_round': 2,\n",
    "    \"query_score_threshold\": 0.0,\n",
    "    \"shared_memory_size\": 50,\n",
    "    \"comm_freq\": comm_freq,\n",
    "    \"prefilter_strategy\": prefilter_strategy,\n",
    "    \"use_ood_separation_loss\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentCls = get_agent_cls(cfg.sharing_strategy, cfg.algo, parallel)\n",
    "FleetCls = get_fleet(cfg.sharing_strategy, parallel)\n",
    "\n",
    "def setup_fleet(task_id=None): \n",
    "    fleet = FleetCls(graph, cfg.seed, datasets, cfg.sharing_strategy, AgentCls, NetCls=NetCls,\n",
    "                    LearnerCls=LearnerCls, net_kwargs=net_cfg, agent_kwargs=agent_cfg,\n",
    "                    train_kwargs=train_cfg, **fleet_additional_cfg)\n",
    "    if task_id is not None:\n",
    "        fleet.load_model_from_ckpoint(task_ids=task_id)\n",
    "    return fleet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
