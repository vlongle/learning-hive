{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Class sequence: [1 2 4 6 4 8 8 7 8 2 7 3 3 0 4 5 1 0 4 2]\n",
      "INFO:root:task 0 :(128, 1, 28, 28)\n",
      "INFO:root:task 1 :(128, 1, 28, 28)\n",
      "INFO:root:task 2 :(128, 1, 28, 28)\n",
      "INFO:root:task 3 :(128, 1, 28, 28)\n",
      "INFO:root:task 4 :(128, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:task 5 :(128, 1, 28, 28)\n",
      "INFO:root:task 6 :(128, 1, 28, 28)\n",
      "INFO:root:task 7 :(128, 1, 28, 28)\n",
      "INFO:root:task 8 :(128, 1, 28, 28)\n",
      "INFO:root:task 9 :(128, 1, 28, 28)\n",
      "INFO:root:Agent: node_id: 0, seed: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Agent: node_id: 1, seed: 1000\n",
      "INFO:root:epochs: 0, training task: 0\n",
      "INFO:root:\ttask: 0\tloss: 0.695\tacc: 0.502\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.502\n",
      "INFO:root:epochs: 0, training task: 0\n",
      "INFO:root:\ttask: 0\tloss: 0.695\tacc: 0.502\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.502\n",
      "INFO:root:final components: 2\n",
      "INFO:root:epochs: 0, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.695\tacc: 0.502\n",
      "INFO:root:\ttask: 1\tloss: 0.694\tacc: 0.492\n",
      "INFO:root:\ttask: avg\tloss: 0.695\tacc: 0.497\n",
      "INFO:root:epochs: 1, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.690\tacc: 0.510\n",
      "INFO:root:\ttask: 1\tloss: 0.689\tacc: 0.649\n",
      "INFO:root:\ttask: avg\tloss: 0.689\tacc: 0.579\n",
      "INFO:root:epochs: 2, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.686\tacc: 0.518\n",
      "INFO:root:\ttask: 1\tloss: 0.682\tacc: 0.534\n",
      "INFO:root:\ttask: avg\tloss: 0.684\tacc: 0.526\n",
      "INFO:root:epochs: 3, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.681\tacc: 0.530\n",
      "INFO:root:\ttask: 1\tloss: 0.676\tacc: 0.515\n",
      "INFO:root:\ttask: avg\tloss: 0.679\tacc: 0.523\n",
      "INFO:root:epochs: 4, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.676\tacc: 0.568\n",
      "INFO:root:\ttask: 1\tloss: 0.669\tacc: 0.514\n",
      "INFO:root:\ttask: avg\tloss: 0.673\tacc: 0.541\n",
      "INFO:root:epochs: 5, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.669\tacc: 0.639\n",
      "INFO:root:\ttask: 1\tloss: 0.660\tacc: 0.517\n",
      "INFO:root:\ttask: avg\tloss: 0.664\tacc: 0.578\n",
      "INFO:root:epochs: 6, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.661\tacc: 0.723\n",
      "INFO:root:\ttask: 1\tloss: 0.648\tacc: 0.529\n",
      "INFO:root:\ttask: avg\tloss: 0.655\tacc: 0.626\n",
      "INFO:root:epochs: 7, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.652\tacc: 0.755\n",
      "INFO:root:\ttask: 1\tloss: 0.633\tacc: 0.570\n",
      "INFO:root:\ttask: avg\tloss: 0.643\tacc: 0.663\n",
      "INFO:root:epochs: 8, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.641\tacc: 0.798\n",
      "INFO:root:\ttask: 1\tloss: 0.614\tacc: 0.629\n",
      "INFO:root:\ttask: avg\tloss: 0.628\tacc: 0.714\n",
      "INFO:root:epochs: 9, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.627\tacc: 0.832\n",
      "INFO:root:\ttask: 1\tloss: 0.592\tacc: 0.694\n",
      "INFO:root:\ttask: avg\tloss: 0.609\tacc: 0.763\n",
      "INFO:root:epochs: 10, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.609\tacc: 0.863\n",
      "INFO:root:\ttask: 1\tloss: 0.568\tacc: 0.740\n",
      "INFO:root:\ttask: avg\tloss: 0.589\tacc: 0.802\n",
      "INFO:root:epochs: 11, training task: 1\n",
      "INFO:root:\ttask: 0\tloss: 0.609\tacc: 0.863\n",
      "INFO:root:\ttask: 1\tloss: 0.568\tacc: 0.740\n",
      "INFO:root:\ttask: avg\tloss: 0.589\tacc: 0.802\n",
      "INFO:root:final components: 2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'named_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 131\u001b[0m\n\u001b[1;32m    128\u001b[0m alice\u001b[39m.\u001b[39mtrain(\u001b[39m1\u001b[39m)\n\u001b[1;32m    130\u001b[0m alice\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m alice\u001b[39m.\u001b[39mprepare_model()\n\u001b[0;32m--> 131\u001b[0m fisher \u001b[39m=\u001b[39m alice\u001b[39m.\u001b[39;49mprepare_fisher_diag()\n\u001b[1;32m    133\u001b[0m \u001b[39mprint\u001b[39m(fisher)\n\u001b[1;32m    135\u001b[0m \u001b[39m# # training ...\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# for task_id in range(2):\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m#     testloaders = {task: torch.utils.data.DataLoader(testset,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39m# # # print(alice.net.structure[2])\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39m# # print(eval_net(alice.net, testloaders))\u001b[39;00m\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/fleet/grad/fisher_monograd.py:18\u001b[0m, in \u001b[0;36mModelFisherSyncAgent.prepare_fisher_diag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_fisher_diag\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     17\u001b[0m     \u001b[39m# compute the fisher on the replayed data\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     ewc \u001b[39m=\u001b[39m EWC(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mmemory_loaders)\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m ewc\u001b[39m.\u001b[39m_precision_matrices\n",
      "File \u001b[0;32m~/code/learning-hive/src/shell/fleet/grad/fisher_utils.py:39\u001b[0m, in \u001b[0;36mEWC.__init__\u001b[0;34m(self, model, dataloaders, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtot_n_pts \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([\u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m     35\u001b[0m                       \u001b[39mfor\u001b[39;00m dataloader \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloaders\u001b[39m.\u001b[39mvalues()])\n\u001b[1;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m {n: p \u001b[39mfor\u001b[39;00m n,\n\u001b[0;32m---> 39\u001b[0m                p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mnamed_parameters() \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mrequires_grad}\n\u001b[1;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_means \u001b[39m=\u001b[39m {}\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_precision_matrices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_diag_fisher()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'named_parameters'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "File: /grad_sanity_check2.py\n",
    "Project: experiments\n",
    "Created Date: Thursday September 7th 2023\n",
    "Author: Long Le (vlongle@seas.upenn.edu)\n",
    "\n",
    "Copyright (c) 2023 Long Le\n",
    "'''\n",
    "'''\n",
    "File: /grad_sanity_check.py\n",
    "Project: experiments\n",
    "Created Date: Tuesday September 5th 2023\n",
    "Author: Long Le (vlongle@seas.upenn.edu)\n",
    "\n",
    "Copyright (c) 2023 Long Le\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "1. Does the normal averaging destroy the structure of learned weights?\n",
    "2. Under the toy domain, the fisher fixes that?\n",
    "\n",
    "Settings: 2 agents with 2 tasks. We'd like to basically distill into one model that solves both tasks.\n",
    "\n",
    "Checklist\n",
    "[] Copying works.\n",
    "[] See how long takes to bounce back\n",
    "[] fischer info\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from shell.fleet.grad.fisher_monograd import ModelFisherSyncAgent\n",
    "from copy import deepcopy\n",
    "from shell.datasets.datasets import get_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from shell.utils.utils import seed_everything, viz_embedding\n",
    "import torch\n",
    "import subprocess\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from shell.datasets.datasets import get_dataset\n",
    "from shell.utils.utils import seed_everything\n",
    "from pprint import pprint\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "from shell.models.cnn_soft_lifelong_dynamic import CNNSoftLLDynamic\n",
    "from shell.models.cnn import CNN\n",
    "from shell.models.mlp import MLP\n",
    "from shell.models.mlp_soft_lifelong_dynamic import MLPSoftLLDynamic\n",
    "from shell.learners.er_dynamic import CompositionalDynamicER\n",
    "from shell.learners.er_nocomponents import NoComponentsER\n",
    "from shell.utils.experiment_utils import eval_net\n",
    "from shell.utils.experiment_utils import setup_experiment\n",
    "from sklearn.manifold import TSNE\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\"\"\"\n",
    "Two agents trained separately\n",
    "\"\"\"\n",
    "\n",
    "num_tasks = 10\n",
    "\n",
    "net_cfg = {\n",
    "    'depth': 2,\n",
    "    'layer_size': 64,\n",
    "    'num_init_tasks': 2,\n",
    "    'i_size': 28,\n",
    "    'num_classes': 2,\n",
    "    'num_tasks': num_tasks,\n",
    "    'dropout': 0.0,\n",
    "}\n",
    "\n",
    "agent_cfg = {\n",
    "    'memory_size': 64,\n",
    "    'use_contrastive': False,\n",
    "    'save_dir': '',\n",
    "}\n",
    "\n",
    "\n",
    "data_cfg = {\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"num_tasks\": num_tasks,\n",
    "    \"num_train_per_task\": 128,\n",
    "    \"num_val_per_task\": 102,\n",
    "    'remap_labels': True,\n",
    "    'use_contrastive': False,\n",
    "    \"with_replacement\": True,\n",
    "}\n",
    "print(num_tasks)\n",
    "bob_dataset = get_dataset(**data_cfg)\n",
    "print(len(bob_dataset.trainset))\n",
    "\n",
    "# # alice dataset is the same as bob's but tasks 0,1 are switched with 2,3\n",
    "alice_dataset = deepcopy(bob_dataset)\n",
    "alice_dataset.trainset[0], alice_dataset.trainset[2] = alice_dataset.trainset[2], alice_dataset.trainset[0]\n",
    "alice_dataset.trainset[1], alice_dataset.trainset[3] = alice_dataset.trainset[3], alice_dataset.trainset[1]\n",
    "alice_dataset.testset[0], alice_dataset.testset[2] = alice_dataset.testset[2], alice_dataset.testset[0]\n",
    "alice_dataset.testset[1], alice_dataset.testset[3] = alice_dataset.testset[3], alice_dataset.testset[1]\n",
    "alice_dataset.valset[0], alice_dataset.valset[2] = alice_dataset.valset[2], alice_dataset.valset[0]\n",
    "alice_dataset.valset[1], alice_dataset.valset[3] = alice_dataset.valset[3], alice_dataset.valset[1]\n",
    "alice_dataset.class_sequence[0], alice_dataset.class_sequence[\n",
    "    2] = alice_dataset.class_sequence[2], alice_dataset.class_sequence[0]\n",
    "alice_dataset.class_sequence[1], alice_dataset.class_sequence[\n",
    "    3] = alice_dataset.class_sequence[3], alice_dataset.class_sequence[1]\n",
    "\n",
    "# alice = CompositionalDynamicER(MLPSoftLLDynamic(**net_cfg), **agent_cfg)\n",
    "# bob = CompositionalDynamicER(MLPSoftLLDynamic(**net_cfg), **agent_cfg)\n",
    "\n",
    "train_cfg = {'num_epochs': 10}\n",
    "sharing_cfg = {}\n",
    "alice = ModelFisherSyncAgent(0, 0, alice_dataset, MLPSoftLLDynamic, CompositionalDynamicER, net_cfg, agent_cfg,\n",
    "                             train_cfg, sharing_cfg)\n",
    "\n",
    "bob = ModelFisherSyncAgent(1, 0, alice_dataset, MLPSoftLLDynamic, CompositionalDynamicER, net_cfg, agent_cfg,\n",
    "                           train_cfg, sharing_cfg)\n",
    "\n",
    "# synchronizing the random projection to make sure they're the same.\n",
    "alice.net.random_linear_projection.weight = bob.net.random_linear_projection.weight\n",
    "alice.net.random_linear_projection.bias = bob.net.random_linear_projection.bias\n",
    "\n",
    "\n",
    "alice.train(0)\n",
    "alice.train(1)\n",
    "\n",
    "# alice.model = alice.prepare_model()\n",
    "# fisher = alice.prepare_fisher_diag()\n",
    "\n",
    "# print(fisher)\n",
    "\n",
    "# # training ...\n",
    "# for task_id in range(2):\n",
    "#     testloaders = {task: torch.utils.data.DataLoader(testset,\n",
    "#                                                      batch_size=128,\n",
    "#                                                      shuffle=False,\n",
    "#                                                      num_workers=0,\n",
    "#                                                      pin_memory=True,\n",
    "#                                                      ) for task, testset in enumerate(bob_dataset.testset[:(task_id+1)])}\n",
    "\n",
    "#     trainloader = torch.utils.data.DataLoader(bob_dataset.trainset[task_id],\n",
    "#                                               batch_size=64,\n",
    "#                                               shuffle=True,\n",
    "#                                               num_workers=0,\n",
    "#                                               pin_memory=True,\n",
    "#                                               )\n",
    "#     valloader = torch.utils.data.DataLoader(bob_dataset.valset[task_id],\n",
    "#                                             batch_size=256,\n",
    "#                                             shuffle=False,\n",
    "#                                             num_workers=4,\n",
    "#                                             pin_memory=True,\n",
    "#                                             )\n",
    "\n",
    "#     bob.train(trainloader, task_id=task_id, num_epochs=10, testloaders=testloaders,\n",
    "#               valloader=valloader, save_freq=1)\n",
    "\n",
    "\n",
    "# print('\\n\\n\\n')\n",
    "# for task_id in range(2):\n",
    "#     testloaders = {task: torch.utils.data.DataLoader(testset,\n",
    "#                                                      batch_size=128,\n",
    "#                                                      shuffle=False,\n",
    "#                                                      num_workers=0,\n",
    "#                                                      pin_memory=True,\n",
    "#                                                      ) for task, testset in enumerate(alice_dataset.testset[:(task_id+1+2)])}\n",
    "\n",
    "#     trainloader = torch.utils.data.DataLoader(alice_dataset.trainset[task_id],\n",
    "#                                               batch_size=64,\n",
    "#                                               shuffle=True,\n",
    "#                                               num_workers=0,\n",
    "#                                               pin_memory=True,\n",
    "#                                               )\n",
    "#     valloader = torch.utils.data.DataLoader(alice_dataset.valset[task_id],\n",
    "#                                             batch_size=256,\n",
    "#                                             shuffle=False,\n",
    "#                                             num_workers=4,\n",
    "#                                             pin_memory=True,\n",
    "#                                             )\n",
    "\n",
    "#     alice.train(trainloader, task_id=task_id, num_epochs=10, testloaders=testloaders,\n",
    "#                 valloader=valloader, save_freq=1)\n",
    "\n",
    "# # print(alice.net)\n",
    "\n",
    "\n",
    "# # manually plug bob weights into alice...\n",
    "# alice.net.add_tmp_module(task_id=2)\n",
    "# alice.net.add_tmp_module(task_id=2)\n",
    "\n",
    "# # turn the dict testloaders into one combined_testloader\n",
    "# # combined_testloader = torch.utils.data.DataLoader(\n",
    "# #     torch.utils.data.ConcatDataset(\n",
    "# #         [testset.dataset for testset in testloaders.values()]),\n",
    "# #     batch_size=128,\n",
    "# #     shuffle=False,\n",
    "# #     num_workers=0,\n",
    "# #     pin_memory=True,\n",
    "# # )\n",
    "\n",
    "# alice_testloaders = {task: torch.utils.data.DataLoader(testset,\n",
    "#                                                        batch_size=128,\n",
    "#                                                        shuffle=False,\n",
    "#                                                        num_workers=0,\n",
    "#                                                        pin_memory=True,\n",
    "#                                                        ) for task, testset in enumerate(alice_dataset.testset[:(task_id+1)])}\n",
    "# print(alice_testloaders)\n",
    "# ewc = EWC(alice.net, alice_testloaders)\n",
    "# print(\"precision matrices\")\n",
    "# print(ewc._precision_matrices)\n",
    "\n",
    "# \"\"\"\n",
    "# TODO: re-examine EWC.\n",
    "# \"\"\"\n",
    "\n",
    "# # # print(alice.net)\n",
    "# # alice.net.components[2].weight = bob.net.components[0].weight\n",
    "# # alice.net.components[3].weight = bob.net.components[1].weight\n",
    "\n",
    "# # alice.net.components[2].bias = bob.net.components[0].bias\n",
    "# # alice.net.components[3].bias = bob.net.components[1].bias\n",
    "\n",
    "# # # bob has 2 modules and alice has 4 modules. Black out modules 1 and 2\n",
    "# # # of alice, and copy over the structure of bob's modules 1 and 2 into alice's modules 3 and 4\n",
    "# # # 1. set all structure to -inf\n",
    "# # alice.net.structure[2].data = -np.inf * torch.ones(4, 2)\n",
    "# # alice.net.structure[3].data = -np.inf * torch.ones(4, 2)\n",
    "\n",
    "# # # 2. copy over the structure of bob's modules 1 and 2 into alice's modules 3 and 4\n",
    "# # alice.net.structure[2].data[2:, :] = bob.net.structure[0].data\n",
    "# # alice.net.structure[3].data[2:, :] = bob.net.structure[1].data\n",
    "\n",
    "# # # need to copy over the decoder as well\n",
    "# # alice.net.decoder[2].weight = bob.net.decoder[0].weight\n",
    "# # alice.net.decoder[3].weight = bob.net.decoder[1].weight\n",
    "# # alice.net.decoder[2].bias = bob.net.decoder[0].bias\n",
    "# # alice.net.decoder[3].bias = bob.net.decoder[1].bias\n",
    "\n",
    "# # # print(alice.net.structure[2])\n",
    "# # print(eval_net(alice.net, testloaders))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.model = alice.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher = alice.prepare_fisher_diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'components.0.weight': tensor([[2.1598e-09, 5.1071e-07, 2.2493e-07,  ..., 5.7379e-08, 1.5239e-08,\n",
       "          1.1850e-08],\n",
       "         [1.3021e-11, 6.1282e-10, 2.6502e-10,  ..., 3.6133e-09, 3.9926e-09,\n",
       "          5.6248e-10],\n",
       "         [9.1271e-12, 1.8683e-09, 1.3990e-10,  ..., 6.1934e-12, 1.0104e-09,\n",
       "          1.2679e-10],\n",
       "         ...,\n",
       "         [1.8940e-09, 3.2291e-07, 1.1065e-07,  ..., 1.5047e-09, 6.3026e-08,\n",
       "          2.4780e-08],\n",
       "         [2.6458e-09, 2.6954e-08, 1.2392e-09,  ..., 1.0581e-09, 1.0557e-08,\n",
       "          6.8356e-09],\n",
       "         [4.4564e-10, 3.8562e-08, 7.2080e-11,  ..., 1.1137e-08, 1.1507e-08,\n",
       "          9.7732e-09]], device='cuda:0'),\n",
       " 'components.0.bias': tensor([2.7003e-06, 4.8618e-08, 7.3080e-09, 5.4496e-08, 2.8545e-08, 6.5768e-07,\n",
       "         2.9294e-07, 6.7019e-07, 1.2863e-06, 1.9150e-06, 6.8796e-08, 1.1867e-06,\n",
       "         0.0000e+00, 8.0132e-08, 0.0000e+00, 1.3524e-07, 2.6895e-07, 7.2265e-08,\n",
       "         8.0536e-08, 7.0292e-07, 3.2829e-08, 1.7377e-06, 9.1122e-07, 1.6109e-06,\n",
       "         2.0312e-07, 3.7114e-07, 1.5628e-09, 9.7510e-08, 3.1307e-06, 3.6809e-07,\n",
       "         8.1505e-07, 0.0000e+00, 1.0607e-06, 8.5782e-07, 2.5033e-07, 1.3334e-06,\n",
       "         8.8062e-07, 3.3696e-07, 2.7554e-06, 5.1956e-08, 3.3534e-07, 4.3228e-07,\n",
       "         1.5227e-07, 1.4474e-08, 3.9754e-09, 1.7512e-09, 1.7291e-09, 4.0417e-08,\n",
       "         5.8068e-07, 4.4770e-06, 2.0977e-06, 8.5167e-07, 5.4380e-07, 4.8779e-07,\n",
       "         6.9911e-07, 1.7406e-06, 6.8332e-09, 2.7843e-08, 4.5672e-08, 3.0275e-07,\n",
       "         0.0000e+00, 1.4440e-06, 7.6615e-08, 1.3083e-07], device='cuda:0'),\n",
       " 'components.1.weight': tensor([[3.8309e-09, 4.3105e-09, 3.7010e-11,  ..., 6.1001e-09, 6.3084e-09,\n",
       "          4.3583e-09],\n",
       "         [5.7384e-08, 4.9411e-11, 1.1348e-07,  ..., 5.3263e-08, 7.6136e-09,\n",
       "          6.5476e-08],\n",
       "         [6.2362e-09, 8.4353e-09, 1.8342e-07,  ..., 2.7657e-08, 6.9871e-09,\n",
       "          1.8467e-08],\n",
       "         ...,\n",
       "         [3.8425e-08, 3.4719e-08, 3.9529e-12,  ..., 4.4691e-08, 5.5788e-08,\n",
       "          5.0943e-08],\n",
       "         [1.3584e-07, 5.4717e-08, 3.3942e-10,  ..., 9.3216e-08, 1.2606e-07,\n",
       "          1.1201e-07],\n",
       "         [5.8854e-08, 8.6085e-09, 7.0708e-10,  ..., 2.2293e-08, 2.4415e-08,\n",
       "          2.2268e-08]], device='cuda:0'),\n",
       " 'components.1.bias': tensor([2.5566e-08, 1.4683e-06, 1.1385e-06, 2.1440e-07, 2.8318e-08, 8.9370e-07,\n",
       "         6.0445e-06, 2.5580e-07, 2.6238e-07, 3.8131e-08, 3.7997e-11, 3.5015e-07,\n",
       "         8.0992e-08, 4.6017e-06, 1.7528e-06, 3.8145e-06, 1.6468e-06, 1.4272e-07,\n",
       "         1.7910e-06, 1.5851e-06, 5.7853e-08, 2.8460e-06, 9.4497e-07, 1.5107e-07,\n",
       "         3.8265e-09, 1.1055e-07, 1.1549e-06, 1.4262e-06, 4.6746e-08, 2.6795e-06,\n",
       "         3.6531e-08, 2.0785e-07, 1.5323e-07, 2.1953e-07, 1.2614e-09, 8.3376e-07,\n",
       "         1.4248e-08, 1.7107e-07, 1.7745e-08, 1.0243e-11, 2.3493e-06, 1.4975e-07,\n",
       "         1.9531e-06, 6.1420e-09, 1.6929e-06, 2.4157e-06, 1.8290e-07, 2.5646e-06,\n",
       "         4.9029e-07, 2.8181e-06, 4.1396e-07, 6.0084e-07, 2.9586e-08, 2.0794e-06,\n",
       "         1.9288e-07, 0.0000e+00, 1.1827e-06, 9.3558e-09, 6.9714e-10, 5.5200e-07,\n",
       "         7.7170e-10, 6.5642e-07, 2.3028e-06, 1.0189e-06], device='cuda:0'),\n",
       " 'decoder.0.weight': tensor([[2.0123e-07, 3.4564e-09, 1.5471e-06, 0.0000e+00, 4.3474e-12, 2.7784e-06,\n",
       "          5.5740e-06, 0.0000e+00, 1.8880e-07, 9.1186e-07, 3.8678e-09, 4.8413e-06,\n",
       "          2.6896e-06, 6.3095e-06, 2.3789e-06, 7.4363e-06, 1.2692e-12, 3.2082e-06,\n",
       "          1.5895e-05, 8.1262e-06, 2.2497e-08, 7.3058e-06, 1.6620e-06, 8.5296e-06,\n",
       "          1.0074e-07, 7.0169e-11, 2.4498e-06, 1.1666e-06, 2.0727e-09, 3.7248e-06,\n",
       "          8.4846e-11, 2.6966e-07, 8.8773e-10, 2.3958e-06, 0.0000e+00, 6.2355e-07,\n",
       "          0.0000e+00, 1.1674e-07, 1.3734e-06, 0.0000e+00, 3.3820e-07, 3.6257e-06,\n",
       "          3.7575e-07, 4.0036e-10, 1.2054e-06, 2.3938e-06, 9.6684e-07, 7.3576e-07,\n",
       "          9.1410e-06, 6.9862e-10, 6.7288e-06, 1.0388e-06, 0.0000e+00, 2.6419e-11,\n",
       "          3.3362e-10, 0.0000e+00, 4.0450e-06, 1.4953e-08, 1.0588e-10, 6.8045e-06,\n",
       "          4.7091e-12, 5.4636e-06, 8.8123e-06, 7.1113e-07],\n",
       "         [2.0123e-07, 3.4564e-09, 1.5471e-06, 0.0000e+00, 4.3474e-12, 2.7784e-06,\n",
       "          5.5740e-06, 0.0000e+00, 1.8880e-07, 9.1186e-07, 3.8678e-09, 4.8413e-06,\n",
       "          2.6896e-06, 6.3095e-06, 2.3789e-06, 7.4363e-06, 1.2692e-12, 3.2082e-06,\n",
       "          1.5895e-05, 8.1262e-06, 2.2497e-08, 7.3058e-06, 1.6620e-06, 8.5296e-06,\n",
       "          1.0074e-07, 7.0169e-11, 2.4498e-06, 1.1666e-06, 2.0727e-09, 3.7248e-06,\n",
       "          8.4846e-11, 2.6966e-07, 8.8773e-10, 2.3958e-06, 0.0000e+00, 6.2355e-07,\n",
       "          0.0000e+00, 1.1674e-07, 1.3734e-06, 0.0000e+00, 3.3820e-07, 3.6257e-06,\n",
       "          3.7575e-07, 4.0036e-10, 1.2054e-06, 2.3938e-06, 9.6684e-07, 7.3576e-07,\n",
       "          9.1410e-06, 6.9862e-10, 6.7288e-06, 1.0388e-06, 0.0000e+00, 2.6419e-11,\n",
       "          3.3362e-10, 0.0000e+00, 4.0450e-06, 1.4953e-08, 1.0588e-10, 6.8045e-06,\n",
       "          4.7091e-12, 5.4636e-06, 8.8123e-06, 7.1113e-07]], device='cuda:0'),\n",
       " 'decoder.0.bias': tensor([1.9563e-05, 1.9563e-05], device='cuda:0'),\n",
       " 'decoder.1.weight': tensor([[1.2798e-05, 0.0000e+00, 3.1822e-07, 1.7750e-06, 7.6278e-07, 8.7555e-06,\n",
       "          7.3676e-06, 1.3201e-05, 2.0075e-05, 0.0000e+00, 0.0000e+00, 1.5113e-07,\n",
       "          0.0000e+00, 3.8712e-06, 0.0000e+00, 0.0000e+00, 2.8542e-06, 0.0000e+00,\n",
       "          9.0716e-10, 6.8656e-06, 0.0000e+00, 1.9561e-10, 9.7899e-06, 2.4857e-05,\n",
       "          1.8996e-07, 1.5556e-05, 4.1251e-10, 0.0000e+00, 2.7816e-05, 3.2792e-09,\n",
       "          1.0724e-05, 0.0000e+00, 9.4946e-06, 4.5924e-08, 1.3821e-05, 1.1248e-05,\n",
       "          3.0802e-06, 1.2675e-05, 3.6193e-05, 9.5284e-07, 3.6259e-06, 2.5457e-08,\n",
       "          7.0971e-09, 5.6773e-07, 3.1569e-09, 2.1651e-09, 0.0000e+00, 4.2512e-09,\n",
       "          9.4351e-11, 1.3007e-05, 7.3627e-06, 1.0063e-05, 4.7469e-06, 1.5598e-06,\n",
       "          1.0602e-09, 7.3842e-06, 1.0468e-06, 1.5874e-06, 9.4682e-07, 2.5666e-06,\n",
       "          0.0000e+00, 4.1198e-06, 1.4990e-07, 1.9984e-09],\n",
       "         [1.2798e-05, 0.0000e+00, 3.1822e-07, 1.7750e-06, 7.6278e-07, 8.7555e-06,\n",
       "          7.3676e-06, 1.3201e-05, 2.0075e-05, 0.0000e+00, 0.0000e+00, 1.5113e-07,\n",
       "          0.0000e+00, 3.8712e-06, 0.0000e+00, 0.0000e+00, 2.8542e-06, 0.0000e+00,\n",
       "          9.0716e-10, 6.8656e-06, 0.0000e+00, 1.9561e-10, 9.7899e-06, 2.4857e-05,\n",
       "          1.8996e-07, 1.5556e-05, 4.1251e-10, 0.0000e+00, 2.7816e-05, 3.2792e-09,\n",
       "          1.0724e-05, 0.0000e+00, 9.4946e-06, 4.5924e-08, 1.3821e-05, 1.1248e-05,\n",
       "          3.0802e-06, 1.2675e-05, 3.6193e-05, 9.5284e-07, 3.6259e-06, 2.5457e-08,\n",
       "          7.0971e-09, 5.6773e-07, 3.1569e-09, 2.1651e-09, 0.0000e+00, 4.2512e-09,\n",
       "          9.4351e-11, 1.3007e-05, 7.3627e-06, 1.0063e-05, 4.7469e-06, 1.5598e-06,\n",
       "          1.0602e-09, 7.3842e-06, 1.0468e-06, 1.5874e-06, 9.4682e-07, 2.5666e-06,\n",
       "          0.0000e+00, 4.1198e-06, 1.4990e-07, 1.9984e-09]], device='cuda:0'),\n",
       " 'decoder.1.bias': tensor([3.6338e-05, 3.6338e-05], device='cuda:0'),\n",
       " 'decoder.2.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'decoder.2.bias': tensor([0., 0.], device='cuda:0'),\n",
       " 'decoder.3.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'decoder.3.bias': tensor([0., 0.], device='cuda:0'),\n",
       " 'decoder.4.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'decoder.4.bias': tensor([0., 0.], device='cuda:0'),\n",
       " 'decoder.5.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'decoder.5.bias': tensor([0., 0.], device='cuda:0'),\n",
       " 'decoder.6.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'decoder.6.bias': tensor([0., 0.], device='cuda:0'),\n",
       " 'decoder.7.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'decoder.7.bias': tensor([0., 0.], device='cuda:0'),\n",
       " 'decoder.8.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'decoder.8.bias': tensor([0., 0.], device='cuda:0'),\n",
       " 'decoder.9.weight': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'decoder.9.bias': tensor([0., 0.], device='cuda:0')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = alice.agent.memory_loaders[0].dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.agent.replay_buffers[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
