{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1671388/4256843647.py:4: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-whitegrid')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd\n",
    "from plot import *\n",
    "from analyze import *\n",
    "from analyze_budget import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_df(series, exclude_keys=None):\n",
    "    \"\"\"\n",
    "    Takes a pandas Series with a MultiIndex and folds over all keys except for those specified\n",
    "    in `exclude_keys` by concatenating the key name and its value into the 'algo' column values.\n",
    "\n",
    "    Parameters:\n",
    "    - series: pandas.Series with a MultiIndex.\n",
    "    - exclude_keys: list of strings representing keys to exclude from the folding process.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with 'algo' and 'dataset' columns, where 'algo' has been modified to include\n",
    "      information from other keys.\n",
    "    \"\"\"\n",
    "\n",
    "    if exclude_keys is None:\n",
    "      exclude_keys=['algo', 'dataset', 'final_acc']\n",
    "    # Convert the Series into a DataFrame\n",
    "    df = series.reset_index()\n",
    "    \n",
    "    # # Initialize a column to store the modified algo values\n",
    "    df['modified_algo'] = df['algo']\n",
    "    exclude_keys += ['modified_algo']\n",
    "    \n",
    "    # # Iterate over each level of the original MultiIndex (now columns in df)\n",
    "    for key in df.columns:\n",
    "        if key not in exclude_keys:\n",
    "            # Append the key name and its value to the 'modified_algo' entries\n",
    "            df['modified_algo'] = df['modified_algo'] + '_' + key + ':' + df[key].astype(str)\n",
    "    \n",
    "    # # Select and rename the relevant columns for the final DataFrame\n",
    "    final_df = df[['modified_algo', 'dataset', series.name]].copy()\n",
    "    final_df.rename(columns={'modified_algo': 'algo', series.name: 'value'}, inplace=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def aggregate_results(df, keys=None, metric=None, post_process=True,\n",
    "                      error_type=\"sem\"):\n",
    "   if keys is None:\n",
    "      keys = [\"algo\", \"use_contrastive\"]\n",
    "   if metric is None:\n",
    "      metric = \"final_acc\"\n",
    "   keys += [\"dataset\"]\n",
    "   m = df.groupby(keys)[\n",
    "         metric].mean()\n",
    "   if error_type == \"sem\":\n",
    "      stderr = df.groupby(keys)[metric].sem()\n",
    "   else:\n",
    "      stderr = df.groupby(keys)[metric].std()\n",
    "   if post_process:\n",
    "      exclude_keys=[\"algo\", \"dataset\", metric]\n",
    "      m = postprocess_df(m, exclude_keys)\n",
    "      stderr = postprocess_df(stderr, exclude_keys)\n",
    "   return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=None\n",
    "error_type=\"sem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_for_table(m):\n",
    "    res = m.copy()\n",
    "    # Remove the \"_use_contrastive:False\" part for cleaner extraction\n",
    "    res['algo_clean'] = res['algo'].str.replace('_use_contrastive:False', '')\n",
    "\n",
    "    # Now, extract 'base' and 'algorithm' accurately\n",
    "    res['base'] = res['algo_clean'].str.extract(r'^([^_]+)')[0]\n",
    "    res['algorithm'] = res['algo_clean'].str.extract(r'_(.+)$')[0]\n",
    "\n",
    "    # Fill NaN in 'algorithm' with 'vanilla'\n",
    "    res['algorithm'].fillna('vanilla', inplace=True)\n",
    "\n",
    "    # Drop the columns we don't need anymore\n",
    "    res.drop(['algo', 'algo_clean'], axis=1, inplace=True)\n",
    "\n",
    "    res = res.pivot_table(index=['base', 'algorithm'], columns='dataset', values='value', aggfunc='first').reset_index()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickbest(m, stderr, algo_part):\n",
    "    # Create empty DataFrames to hold the best configurations and their corresponding standard errors\n",
    "    best_configs = pd.DataFrame()\n",
    "    best_errors = pd.DataFrame()\n",
    "    \n",
    "    # Filter both DataFrames to include only the rows where the 'algo' column contains the algorithm part\n",
    "    filtered_m = m[m['algo'].str.contains(algo_part)]\n",
    "    filtered_stderr = stderr[stderr['algo'].str.contains(algo_part)]\n",
    "    \n",
    "    # Loop over each unique dataset\n",
    "    for dataset in filtered_m['dataset'].unique():\n",
    "        # Filter to only include rows for this dataset\n",
    "        dataset_m = filtered_m[filtered_m['dataset'] == dataset]\n",
    "        dataset_stderr = filtered_stderr[filtered_stderr['dataset'] == dataset]\n",
    "        \n",
    "        # Find the index of the row with the highest 'mean' value in this subset\n",
    "        best_index = dataset_m['value'].idxmax()\n",
    "        \n",
    "        # Append the row at best_index to the best_configs DataFrame and the corresponding errors\n",
    "        best_configs = best_configs.append(dataset_m.loc[best_index])\n",
    "        best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
    "    \n",
    "    # Reset index of the resulting DataFrames for cleanliness\n",
    "    best_configs.reset_index(drop=True, inplace=True)\n",
    "    best_errors.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return best_configs, best_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_sparse = True\n",
    "add_data_backward = True\n",
    "make_new_opt = False\n",
    "\n",
    "remap = {\n",
    "\n",
    "# f'modmod_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod',\n",
    "# f'recv_data_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'data',\n",
    "# f'grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'fed',\n",
    "\n",
    "# f'modmod+recv_data_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod+data',\n",
    "# f'modmod+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod+fed',\n",
    "# f'recv_data+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'data + fed',\n",
    "\n",
    "# f'modmod+heuristic_data_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod+data',\n",
    "# f'modmod+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod+fed',\n",
    "# f'heuristic_data+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'data+fed',\n",
    "\n",
    "f'recv_data+modmod+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod + data + fed',\n",
    "f'heuristic_data+modmod+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod + data + fed',\n",
    "\n",
    "# 'heuristic_data': 'data',\n",
    "# 'heuristic_data+grad_sharing': 'data + fed',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_modular_combine(metric, only_all=False):\n",
    "    df = pd.read_csv('combine_modes_results.csv')\n",
    "    cifar_df = pd.read_csv('cifar_combine_modes_results.csv')\n",
    "    df = pd.concat([cifar_df, df])\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = m['algorithm'].map(remap)\n",
    "    stderr['algorithm'] = stderr['algorithm'].map(remap)\n",
    "    m = m[m['base'] == 'modular']\n",
    "    # hack\n",
    "    if only_all:\n",
    "        m = m[m['algorithm'] == 'modmod + data + fed']\n",
    "    stderr = stderr[stderr['base'] == 'modular']\n",
    "    # hack\n",
    "    if only_all:\n",
    "        stderr = stderr[stderr['algorithm'] == 'modmod + data + fed']\n",
    "    m = m[~pd.isna(m['algorithm'])]\n",
    "    stderr = stderr[~pd.isna(stderr['algorithm'])]\n",
    "    m = m.groupby(['base', 'algorithm']).mean().reset_index()\n",
    "    stderr = stderr.groupby(['base', 'algorithm']).mean().reset_index()\n",
    "    return m, stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_monolithic_combine(metric):\n",
    "    df = pd.read_csv('monolithic_combine_modes_results.csv')\n",
    "    cifar_df = pd.read_csv('cifar100_monolithic_combine_modes_results.csv')\n",
    "    df = pd.concat([cifar_df, df])\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = m['algorithm'].map(remap)\n",
    "    stderr['algorithm'] = stderr['algorithm'].map(remap)\n",
    "    m = m[m['base'] == 'monolithic']\n",
    "    stderr = stderr[stderr['base'] == 'monolithic']\n",
    "    m = m[~pd.isna(m['algorithm'])]\n",
    "    stderr = stderr[~pd.isna(stderr['algorithm'])]\n",
    "    m = m.groupby(['base', 'algorithm']).mean().reset_index()\n",
    "    stderr = stderr.groupby(['base', 'algorithm']).mean().reset_index()\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_baseline(metric):\n",
    "    df = pd.read_csv('experiment_results/vanilla_jorge_setting_basis_no_sparse.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric,\n",
    "                                    error_type=error_type)\n",
    "\n",
    "\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recv(metric):\n",
    "    # analyze('experiment_results/jorge_setting_recv')\n",
    "    df = pd.read_csv('experiment_results/jorge_setting_recv.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric,\n",
    "                                    error_type=error_type)\n",
    "\n",
    "\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = 'data'\n",
    "    stderr['algorithm'] = 'data'\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_modmod(metric):\n",
    "    df = pd.read_csv('experiment_results/jorge_setting_lowest_task_id_wins_modmod_test_sync_base_True_opt_with_random_False_frozen_False_transfer_decoder_True_transfer_structure_True_no_sparse_basis_True.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "\n",
    "    leep_df = pd.read_csv('experiment_results/leep_jorge_setting_lowest_task_id_wins_modmod_test_sync_base_True_opt_with_random_False_frozen_False_transfer_decoder_True_transfer_structure_True_no_sparse_basis_True.csv')\n",
    "    leep_df = leep_df[leep_df['use_contrastive'] == False]\n",
    "    leep_df = leep_df[leep_df['dataset'] == 'combined']\n",
    "\n",
    "    df = pd.concat([df, leep_df])\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = 'modmod'\n",
    "    stderr['algorithm'] = 'modmod'\n",
    "    return m, stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fedavg(metric):\n",
    "    df = pd.read_csv('experiment_results/jorge_setting_fedavg.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = 'fedavg'\n",
    "    stderr['algorithm'] = 'fedavg'\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fl(metric):\n",
    "    df = pd.read_csv('best_fl_results.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "\n",
    "    bases = ['modular', 'monolithic']\n",
    "    fed_algos = ['fedcurv', 'fedprox']\n",
    "    best_fls = []\n",
    "    best_errs = []\n",
    "    for base in bases:\n",
    "        for fed_algo in fed_algos:\n",
    "            best_fl, best_err = pickbest(m, stderr, f\"{base}_{fed_algo}\")\n",
    "            best_fl['algo'] = f\"{base}_{fed_algo}\"\n",
    "            best_err['algo'] = f\"{base}_{fed_algo}\"\n",
    "\n",
    "            best_fls.append(best_fl)\n",
    "            best_errs.append(best_err)\n",
    "\n",
    "    best_fl = pd.concat(best_fls)\n",
    "    best_err = pd.concat(best_errs)\n",
    "    best_fl = format_df_for_table(best_fl)\n",
    "    best_err = format_df_for_table(best_err)\n",
    "    return best_fl, best_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n"
     ]
    }
   ],
   "source": [
    "metric = 'auc'\n",
    "funcs = [load_baseline, load_recv, load_fedavg, load_fl, load_modmod, load_modular_combine, load_monolithic_combine]\n",
    "dfs = []\n",
    "df_errs = []\n",
    "for func in funcs:\n",
    "    m, err = func(metric=metric)\n",
    "    dfs.append(m)\n",
    "    df_errs.append(err)\n",
    "df_auc = pd.concat(dfs)\n",
    "df_auc_err = pd.concat(df_errs)\n",
    "\n",
    "\n",
    "# Resetting the index to fix any issues with non-unique or unordered indices\n",
    "df_auc.reset_index(drop=True, inplace=True)\n",
    "# Resetting the index to fix any issues with non-unique or unordered indices\n",
    "df_auc_err.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if metric == 'final_acc':\n",
    "    df_auc.loc[:, ~df_auc.columns.isin(['base', 'algorithm'])] *= 100\n",
    "    df_auc_err.loc[:, ~df_auc_err.columns.isin(['base', 'algorithm'])] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Base</th><th>Algorithm</th><th>cifar100</th><th>combined</th><th>fashionmnist</th><th>kmnist</th><th>mnist</th></tr><tr><td>modular</td><td>vanilla</td><td>71.83095 +/- 0.13</td><td>88.04524 +/- 0.28</td><td>92.03035 +/- 0.32</td><td>80.62320 +/- 0.31</td><td>92.67858 +/- 0.22</td></tr><tr><td>monolithic</td><td>vanilla</td><td>65.59769 +/- 0.32</td><td>87.69488 +/- 0.28</td><td>93.27110 +/- 0.36</td><td>79.41837 +/- 0.31</td><td>93.10231 +/- 0.22</td></tr><tr><td>modular</td><td>data</td><td>73.42025 +/- 0.14</td><td>89.48271 +/- 0.25</td><td>92.96718 +/- 0.30</td><td>82.03789 +/- 0.29</td><td>93.89448 +/- 0.14</td></tr><tr><td>monolithic</td><td>data</td><td>67.23490 +/- 0.21</td><td>88.59379 +/- 0.28</td><td><b>94.71689 +/- 0.38</b></td><td>81.00830 +/- 0.29</td><td>94.54293 +/- 0.21</td></tr><tr><td>modular</td><td>fedavg</td><td>73.95755 +/- 0.14</td><td>87.99336 +/- 0.31</td><td>91.95554 +/- 0.45</td><td>80.09533 +/- 0.34</td><td>92.81523 +/- 0.23</td></tr><tr><td>monolithic</td><td>fedavg</td><td>69.10859 +/- 0.18</td><td>86.76124 +/- 0.31</td><td>93.59634 +/- 0.39</td><td>80.49006 +/- 0.35</td><td>93.75833 +/- 0.26</td></tr><tr><td>modular</td><td>fedcurv</td><td>73.94089 +/- 0.14</td><td>87.98533 +/- 0.29</td><td>92.32104 +/- 0.44</td><td>80.14174 +/- 0.38</td><td>92.75850 +/- 0.26</td></tr><tr><td>modular</td><td>fedprox</td><td>73.84597 +/- 0.13</td><td>88.02116 +/- 0.29</td><td>92.06747 +/- 0.46</td><td>80.20258 +/- 0.35</td><td>93.05266 +/- 0.21</td></tr><tr><td>monolithic</td><td>fedcurv</td><td>68.92815 +/- 0.17</td><td>86.86572 +/- 0.31</td><td>93.85225 +/- 0.40</td><td>80.39766 +/- 0.35</td><td>93.36926 +/- 0.31</td></tr><tr><td>monolithic</td><td>fedprox</td><td>69.09095 +/- 0.16</td><td>87.16168 +/- 0.31</td><td>93.99292 +/- 0.39</td><td>80.46526 +/- 0.35</td><td>93.64959 +/- 0.30</td></tr><tr><td>modular</td><td>modmod</td><td>76.79904 +/- 0.13</td><td>89.61856 +/- 0.26</td><td>93.25570 +/- 0.41</td><td>81.77697 +/- 0.29</td><td>93.94069 +/- 0.19</td></tr><tr><td>modular</td><td>modmod + data + fed</td><td><b>77.07444 +/- 0.14</b></td><td><b>90.40897 +/- 0.24</b></td><td>94.42651 +/- 0.35</td><td><b>82.89506 +/- 0.25</b></td><td><b>94.74525 +/- 0.14</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_table_v3(df_auc, df_auc_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>base</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>cifar100</th>\n",
       "      <th>combined</th>\n",
       "      <th>fashionmnist</th>\n",
       "      <th>kmnist</th>\n",
       "      <th>mnist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modular</td>\n",
       "      <td>modmod + data + fed</td>\n",
       "      <td>77.074436</td>\n",
       "      <td>90.408967</td>\n",
       "      <td>94.426507</td>\n",
       "      <td>82.895064</td>\n",
       "      <td>94.745248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset     base            algorithm   cifar100   combined  fashionmnist  \\\n",
       "0        modular  modmod + data + fed  77.074436  90.408967     94.426507   \n",
       "\n",
       "dataset     kmnist      mnist  \n",
       "0        82.895064  94.745248  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, e = load_modular_combine(metric='auc')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_1671388/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n"
     ]
    }
   ],
   "source": [
    "metric = 'final_acc'\n",
    "funcs = [load_baseline, load_recv, load_fedavg, load_fl, load_modmod, load_modular_combine, load_monolithic_combine]\n",
    "dfs = []\n",
    "df_errs = []\n",
    "for func in funcs:\n",
    "    m, err = func(metric=metric)\n",
    "    dfs.append(m)\n",
    "    df_errs.append(err)\n",
    "df_final = pd.concat(dfs)\n",
    "df_final_err = pd.concat(df_errs)\n",
    "\n",
    "\n",
    "# Resetting the index to fix any issues with non-unique or unordered indices\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "# Resetting the index to fix any issues with non-unique or unordered indices\n",
    "df_final_err.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if metric == 'final_acc':\n",
    "    df_final.loc[:, ~df_final.columns.isin(['base', 'algorithm'])] *= 100\n",
    "    df_final_err.loc[:, ~df_final_err.columns.isin(['base', 'algorithm'])] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Base</th><th>Algorithm</th><th>cifar100</th><th>combined</th><th>fashionmnist</th><th>kmnist</th><th>mnist</th></tr><tr><td>modular</td><td>vanilla</td><td>70.03531 +/- 0.14</td><td>88.58490 +/- 0.36</td><td>92.80133 +/- 0.31</td><td>80.63172 +/- 0.31</td><td>93.46685 +/- 0.20</td></tr><tr><td>monolithic</td><td>vanilla</td><td>63.10844 +/- 0.32</td><td>86.58945 +/- 0.37</td><td>92.46734 +/- 0.33</td><td>78.22727 +/- 0.31</td><td>91.95880 +/- 0.27</td></tr><tr><td>modular</td><td>data</td><td>71.86266 +/- 0.16</td><td>89.03221 +/- 0.33</td><td>93.55734 +/- 0.28</td><td>82.59461 +/- 0.26</td><td><b>94.59515 +/- 0.12</b></td></tr><tr><td>monolithic</td><td>data</td><td>65.18141 +/- 0.17</td><td>87.81542 +/- 0.36</td><td>94.01612 +/- 0.35</td><td>80.70161 +/- 0.32</td><td>94.20244 +/- 0.17</td></tr><tr><td>modular</td><td>fedavg</td><td>70.98984 +/- 0.14</td><td>88.45254 +/- 0.37</td><td>92.45719 +/- 0.45</td><td>80.03750 +/- 0.35</td><td>93.56893 +/- 0.18</td></tr><tr><td>monolithic</td><td>fedavg</td><td>67.04531 +/- 0.16</td><td>86.56614 +/- 0.40</td><td>93.67609 +/- 0.39</td><td>80.55297 +/- 0.33</td><td>93.86382 +/- 0.20</td></tr><tr><td>modular</td><td>fedcurv</td><td>71.10688 +/- 0.13</td><td>88.45416 +/- 0.37</td><td>93.05695 +/- 0.40</td><td>80.33977 +/- 0.36</td><td>93.78444 +/- 0.19</td></tr><tr><td>modular</td><td>fedprox</td><td>71.81547 +/- 0.14</td><td>88.46861 +/- 0.37</td><td>92.92711 +/- 0.41</td><td>80.48461 +/- 0.35</td><td>93.92683 +/- 0.17</td></tr><tr><td>monolithic</td><td>fedcurv</td><td>66.79344 +/- 0.15</td><td>86.61881 +/- 0.41</td><td>93.74039 +/- 0.37</td><td>80.39203 +/- 0.34</td><td>93.66086 +/- 0.24</td></tr><tr><td>monolithic</td><td>fedprox</td><td>67.17703 +/- 0.17</td><td>86.85734 +/- 0.40</td><td>93.89984 +/- 0.35</td><td>80.25969 +/- 0.33</td><td>93.73559 +/- 0.23</td></tr><tr><td>modular</td><td>modmod</td><td>76.76578 +/- 0.08</td><td>89.64960 +/- 0.30</td><td>93.28117 +/- 0.40</td><td>81.83375 +/- 0.27</td><td>94.07937 +/- 0.18</td></tr><tr><td>modular</td><td>modmod + data + fed</td><td><b>77.04828 +/- 0.10</b></td><td><b>90.31476 +/- 0.28</b></td><td><b>94.10467 +/- 0.31</b></td><td><b>82.93362 +/- 0.23</b></td><td>94.56647 +/- 0.12</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_table_v3(df_final, df_final_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def make_latex_table(df_final, df_final_err, df_auc, df_auc_err, remap_name=None):\n",
    "#     if not remap_name:\n",
    "#         remap_name = {}\n",
    "\n",
    "#     # Define columns for the table display\n",
    "#     columns = ['base', 'algorithm'] + [col for col in df_final.columns if col not in ('base', 'algorithm')]\n",
    "#     max_final = df_final.max(numeric_only=True)  # Calculate max values for final accuracy columns to highlight best results\n",
    "#     min_final = df_final.min(numeric_only=True)  # Calculate min values for final accuracy columns\n",
    "#     max_auc = df_auc.max(numeric_only=True)  # Calculate max values for AUC columns to highlight best results\n",
    "#     min_auc = df_auc.min(numeric_only=True)  # Calculate min values for AUC columns\n",
    "\n",
    "#     # Start building the LaTeX table\n",
    "#     latex = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{Performance Metrics across Datasets and Algorithms}\\n\"\n",
    "#     latex += \"\\\\label{tab:performance_metrics}\\n\\\\begin{adjustbox}{width=1.25\\\\textwidth}\\n\\\\begin{tabular}{ll\" + \"c\" * (len(columns) - 2) + \"}\\n\\\\toprule\\n\"\n",
    "#     latex += \" & \".join([\"\\\\textbf{\" + col.capitalize() + \"}\" for col in columns]) + \" \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    \n",
    "#     # Organize data by 'base' first, then iterate\n",
    "#     df_grouped = df_final.groupby('base')\n",
    "#     for base, group in df_grouped:\n",
    "#         first = True\n",
    "#         for index, row in group.iterrows():\n",
    "#             algorithm = remap_name.get(row['algorithm'], row['algorithm'])\n",
    "#             row_items = [base if first else \"\", algorithm]  # Only show the base for the first entry\n",
    "            \n",
    "#             for dataset in columns[2:]:  # Start from 2 to skip 'base' and 'algorithm'\n",
    "#                 final_value = df_final.loc[index, dataset]\n",
    "#                 final_error = df_final_err.loc[index, dataset]\n",
    "#                 auc_value = df_auc.loc[index, dataset]\n",
    "#                 auc_error = df_auc_err.loc[index, dataset]\n",
    "\n",
    "#                 # Determine if the values should be bold and colored\n",
    "#                 final_str = f\"{final_value:.2f} $\\\\pm$ {final_error:.2f}\"\n",
    "#                 auc_str = f\"{auc_value:.2f} $\\\\pm$ {auc_error:.2f}\"\n",
    "\n",
    "#                 if final_value == max_final[dataset]:\n",
    "#                     final_str = f\"\\\\textbf{{\\\\textcolor{{Green}}{{{final_str}}}}}\"\n",
    "#                 elif final_value == min_final[dataset]:\n",
    "#                     final_str = f\"\\\\textbf{{\\\\textcolor{{red}}{{{final_str}}}}}\"\n",
    "\n",
    "#                 if auc_value == max_auc[dataset]:\n",
    "#                     auc_str = f\"\\\\textbf{{\\\\textcolor{{Green}}{{{auc_str}}}}}\"\n",
    "#                 elif auc_value == min_auc[dataset]:\n",
    "#                     auc_str = f\"\\\\textbf{{\\\\textcolor{{red}}{{{auc_str}}}}}\"\n",
    "                \n",
    "#                 row_items.append(f\"{final_str}/{auc_str}\")  # Append the formatted string for this dataset\n",
    "            \n",
    "#             latex += \" & \".join(row_items) + \" \\\\\\\\\\n\"\n",
    "#             first = False  # Subsequent rows won't show the 'base' again\n",
    "    \n",
    "#     latex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{adjustbox}\\n\\\\end{table}\\n\"\n",
    "#     return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_latex_table(df_final, df_final_err, df_auc, df_auc_err, remap_name=None):\n",
    "    if not remap_name:\n",
    "        remap_name = {}\n",
    "\n",
    "    # Define columns for the table display\n",
    "    columns = ['base', 'algorithm'] + [col for col in df_final.columns if col not in ('base', 'algorithm')]\n",
    "    max_final = df_final.max(numeric_only=True)  # Calculate max values for final accuracy columns to highlight best results\n",
    "    max_auc = df_auc.max(numeric_only=True)  # Calculate max values for AUC columns to highlight best results\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    latex = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{Performance Metrics across Datasets and Algorithms}\\n\"\n",
    "    latex += \"\\\\label{tab:performance_metrics}\\n\\\\begin{adjustbox}{width=1.25\\\\textwidth}\\n\\\\begin{tabular}{ll\" + \"c\" * (len(columns) - 2) + \"}\\n\\\\toprule\\n\"\n",
    "    latex += \" & \".join([\"\\\\textbf{\" + col.capitalize() + \"}\" for col in columns]) + \" \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    \n",
    "    # Organize data by 'base' first, then iterate\n",
    "    df_grouped = df_final.groupby('base')\n",
    "    for base, group in df_grouped:\n",
    "        first = True\n",
    "        for index, row in group.iterrows():\n",
    "            algorithm = remap_name.get(row['algorithm'], row['algorithm'])\n",
    "            row_items = [base if first else \"\", algorithm]  # Only show the base for the first entry\n",
    "            \n",
    "            for dataset in columns[2:]:  # Start from 2 to skip 'base' and 'algorithm'\n",
    "                final_value = df_final.loc[index, dataset]\n",
    "                final_error = df_final_err.loc[index, dataset]\n",
    "                auc_value = df_auc.loc[index, dataset]\n",
    "                auc_error = df_auc_err.loc[index, dataset]\n",
    "                \n",
    "                # Determine if the values should be bold\n",
    "                final_str = f\"{final_value:.2f} $\\\\pm$ {final_error:.2f}\"\n",
    "                auc_str = f\"{auc_value:.2f} $\\\\pm$ {auc_error:.2f}\"\n",
    "                if final_value == max_final[dataset]:\n",
    "                    final_str = f\"\\\\textbf{{{final_str}}}\"\n",
    "                if auc_value == max_auc[dataset]:\n",
    "                    auc_str = f\"\\\\textbf{{{auc_str}}}\"\n",
    "                \n",
    "                row_items.append(f\"{final_str}/{auc_str}\")  # Append the formatted string for this dataset\n",
    "            \n",
    "            latex += \" & \".join(row_items) + \" \\\\\\\\\\n\"\n",
    "            first = False  # Subsequent rows won't show the 'base' again\n",
    "    \n",
    "    latex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{adjustbox}\\n\\\\end{table}\\n\"\n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{Performance Metrics across Datasets and Algorithms}\n",
      "\\label{tab:performance_metrics}\n",
      "\\begin{adjustbox}{width=1.25\\textwidth}\n",
      "\\begin{tabular}{llccccc}\n",
      "\\toprule\n",
      "\\textbf{Base} & \\textbf{Algorithm} & \\textbf{Cifar100} & \\textbf{Combined} & \\textbf{Fashionmnist} & \\textbf{Kmnist} & \\textbf{Mnist} \\\\\n",
      "\\midrule\n",
      "modular & vanilla & 70.04 $\\pm$ 0.14/71.83 $\\pm$ 0.13 & 88.58 $\\pm$ 0.36/88.05 $\\pm$ 0.28 & 92.80 $\\pm$ 0.31/92.03 $\\pm$ 0.32 & 80.63 $\\pm$ 0.31/80.62 $\\pm$ 0.31 & 93.47 $\\pm$ 0.20/92.68 $\\pm$ 0.22 \\\\\n",
      " & data & 71.86 $\\pm$ 0.16/73.42 $\\pm$ 0.14 & 89.03 $\\pm$ 0.33/89.48 $\\pm$ 0.25 & 93.56 $\\pm$ 0.28/92.97 $\\pm$ 0.30 & 82.59 $\\pm$ 0.26/82.04 $\\pm$ 0.29 & \\textbf{94.60 $\\pm$ 0.12}/93.89 $\\pm$ 0.14 \\\\\n",
      " & fedavg & 70.99 $\\pm$ 0.14/73.96 $\\pm$ 0.14 & 88.45 $\\pm$ 0.37/87.99 $\\pm$ 0.31 & 92.46 $\\pm$ 0.45/91.96 $\\pm$ 0.45 & 80.04 $\\pm$ 0.35/80.10 $\\pm$ 0.34 & 93.57 $\\pm$ 0.18/92.82 $\\pm$ 0.23 \\\\\n",
      " & fedcurv & 71.11 $\\pm$ 0.13/73.94 $\\pm$ 0.14 & 88.45 $\\pm$ 0.37/87.99 $\\pm$ 0.29 & 93.06 $\\pm$ 0.40/92.32 $\\pm$ 0.44 & 80.34 $\\pm$ 0.36/80.14 $\\pm$ 0.38 & 93.78 $\\pm$ 0.19/92.76 $\\pm$ 0.26 \\\\\n",
      " & fedprox & 71.82 $\\pm$ 0.14/73.85 $\\pm$ 0.13 & 88.47 $\\pm$ 0.37/88.02 $\\pm$ 0.29 & 92.93 $\\pm$ 0.41/92.07 $\\pm$ 0.46 & 80.48 $\\pm$ 0.35/80.20 $\\pm$ 0.35 & 93.93 $\\pm$ 0.17/93.05 $\\pm$ 0.21 \\\\\n",
      " & modmod & 76.77 $\\pm$ 0.08/76.80 $\\pm$ 0.13 & 89.65 $\\pm$ 0.30/89.62 $\\pm$ 0.26 & 93.28 $\\pm$ 0.40/93.26 $\\pm$ 0.41 & 81.83 $\\pm$ 0.27/81.78 $\\pm$ 0.29 & 94.08 $\\pm$ 0.18/93.94 $\\pm$ 0.19 \\\\\n",
      " & modmod + data + fed & \\textbf{77.05 $\\pm$ 0.10}/\\textbf{77.07 $\\pm$ 0.14} & \\textbf{90.31 $\\pm$ 0.28}/\\textbf{90.41 $\\pm$ 0.24} & \\textbf{94.10 $\\pm$ 0.31}/94.43 $\\pm$ 0.35 & \\textbf{82.93 $\\pm$ 0.23}/\\textbf{82.90 $\\pm$ 0.25} & 94.57 $\\pm$ 0.12/\\textbf{94.75 $\\pm$ 0.14} \\\\\n",
      "monolithic & vanilla & 63.11 $\\pm$ 0.32/65.60 $\\pm$ 0.32 & 86.59 $\\pm$ 0.37/87.69 $\\pm$ 0.28 & 92.47 $\\pm$ 0.33/93.27 $\\pm$ 0.36 & 78.23 $\\pm$ 0.31/79.42 $\\pm$ 0.31 & 91.96 $\\pm$ 0.27/93.10 $\\pm$ 0.22 \\\\\n",
      " & data & 65.18 $\\pm$ 0.17/67.23 $\\pm$ 0.21 & 87.82 $\\pm$ 0.36/88.59 $\\pm$ 0.28 & 94.02 $\\pm$ 0.35/\\textbf{94.72 $\\pm$ 0.38} & 80.70 $\\pm$ 0.32/81.01 $\\pm$ 0.29 & 94.20 $\\pm$ 0.17/94.54 $\\pm$ 0.21 \\\\\n",
      " & fedavg & 67.05 $\\pm$ 0.16/69.11 $\\pm$ 0.18 & 86.57 $\\pm$ 0.40/86.76 $\\pm$ 0.31 & 93.68 $\\pm$ 0.39/93.60 $\\pm$ 0.39 & 80.55 $\\pm$ 0.33/80.49 $\\pm$ 0.35 & 93.86 $\\pm$ 0.20/93.76 $\\pm$ 0.26 \\\\\n",
      " & fedcurv & 66.79 $\\pm$ 0.15/68.93 $\\pm$ 0.17 & 86.62 $\\pm$ 0.41/86.87 $\\pm$ 0.31 & 93.74 $\\pm$ 0.37/93.85 $\\pm$ 0.40 & 80.39 $\\pm$ 0.34/80.40 $\\pm$ 0.35 & 93.66 $\\pm$ 0.24/93.37 $\\pm$ 0.31 \\\\\n",
      " & fedprox & 67.18 $\\pm$ 0.17/69.09 $\\pm$ 0.16 & 86.86 $\\pm$ 0.40/87.16 $\\pm$ 0.31 & 93.90 $\\pm$ 0.35/93.99 $\\pm$ 0.39 & 80.26 $\\pm$ 0.33/80.47 $\\pm$ 0.35 & 93.74 $\\pm$ 0.23/93.65 $\\pm$ 0.30 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex = make_latex_table(df_final, df_final_err, df_auc, df_auc_err)\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_auc_latex_table(df_auc, df_auc_err, remap_name=None):\n",
    "    if not remap_name:\n",
    "        remap_name = {}\n",
    "\n",
    "    # Define columns for the table display\n",
    "    columns = ['base', 'algorithm'] + [col for col in df_auc.columns if col not in ('base', 'algorithm')]\n",
    "    max_auc = df_auc.max(numeric_only=True)  # Calculate max values for AUC columns to highlight best results\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    latex = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{AUC Metrics across Datasets and Algorithms}\\n\"\n",
    "    latex += \"\\\\label{tab:auc_metrics}\\n\\\\begin{adjustbox}{width=1.25\\\\textwidth}\\n\\\\begin{tabular}{ll\" + \"c\" * (len(columns) - 2) + \"}\\n\\\\toprule\\n\"\n",
    "    latex += \" & \".join([\"\\\\textbf{\" + col.capitalize() + \"}\" for col in columns]) + \" \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    \n",
    "    # Organize data by 'base' first, then iterate\n",
    "    df_grouped = df_auc.groupby('base')\n",
    "    for base, group in df_grouped:\n",
    "        first = True\n",
    "        for index, row in group.iterrows():\n",
    "            algorithm = remap_name.get(row['algorithm'], row['algorithm'])\n",
    "            row_items = [base if first else \"\", algorithm]  # Only show the base for the first entry\n",
    "            \n",
    "            for dataset in columns[2:]:  # Start from 2 to skip 'base' and 'algorithm'\n",
    "                auc_value = df_auc.loc[index, dataset]\n",
    "                auc_error = df_auc_err.loc[index, dataset]\n",
    "                \n",
    "                # Determine if the values should be bold\n",
    "                auc_str = f\"{auc_value:.2f} $\\\\pm$ {auc_error:.2f}\"\n",
    "                if auc_value == max_auc[dataset]:\n",
    "                    auc_str = f\"\\\\textbf{{{auc_str}}}\"\n",
    "                \n",
    "                row_items.append(auc_str)  # Append the formatted string for this dataset\n",
    "            \n",
    "            latex += \" & \".join(row_items) + \" \\\\\\\\\\n\"\n",
    "            first = False  # Subsequent rows won't show the 'base' again\n",
    "    \n",
    "    latex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{adjustbox}\\n\\\\end{table}\\n\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{AUC Metrics across Datasets and Algorithms}\n",
      "\\label{tab:auc_metrics}\n",
      "\\begin{adjustbox}{width=1.25\\textwidth}\n",
      "\\begin{tabular}{llccccc}\n",
      "\\toprule\n",
      "\\textbf{Base} & \\textbf{Algorithm} & \\textbf{Cifar100} & \\textbf{Combined} & \\textbf{Fashionmnist} & \\textbf{Kmnist} & \\textbf{Mnist} \\\\\n",
      "\\midrule\n",
      "modular & vanilla & 71.83 $\\pm$ 0.13 & 88.05 $\\pm$ 0.28 & 92.03 $\\pm$ 0.32 & 80.62 $\\pm$ 0.31 & 92.68 $\\pm$ 0.22 \\\\\n",
      " & data & 73.42 $\\pm$ 0.14 & 89.48 $\\pm$ 0.25 & 92.97 $\\pm$ 0.30 & 82.04 $\\pm$ 0.29 & 93.89 $\\pm$ 0.14 \\\\\n",
      " & fedavg & 73.96 $\\pm$ 0.14 & 87.99 $\\pm$ 0.31 & 91.96 $\\pm$ 0.45 & 80.10 $\\pm$ 0.34 & 92.82 $\\pm$ 0.23 \\\\\n",
      " & fedcurv & 73.94 $\\pm$ 0.14 & 87.99 $\\pm$ 0.29 & 92.32 $\\pm$ 0.44 & 80.14 $\\pm$ 0.38 & 92.76 $\\pm$ 0.26 \\\\\n",
      " & fedprox & 73.85 $\\pm$ 0.13 & 88.02 $\\pm$ 0.29 & 92.07 $\\pm$ 0.46 & 80.20 $\\pm$ 0.35 & 93.05 $\\pm$ 0.21 \\\\\n",
      " & modmod & 76.80 $\\pm$ 0.13 & 89.62 $\\pm$ 0.26 & 93.26 $\\pm$ 0.41 & 81.78 $\\pm$ 0.29 & 93.94 $\\pm$ 0.19 \\\\\n",
      " & modmod + data + fed & \\textbf{77.07 $\\pm$ 0.14} & \\textbf{90.41 $\\pm$ 0.24} & 94.43 $\\pm$ 0.35 & \\textbf{82.90 $\\pm$ 0.25} & \\textbf{94.75 $\\pm$ 0.14} \\\\\n",
      "monolithic & vanilla & 65.60 $\\pm$ 0.32 & 87.69 $\\pm$ 0.28 & 93.27 $\\pm$ 0.36 & 79.42 $\\pm$ 0.31 & 93.10 $\\pm$ 0.22 \\\\\n",
      " & data & 67.23 $\\pm$ 0.21 & 88.59 $\\pm$ 0.28 & \\textbf{94.72 $\\pm$ 0.38} & 81.01 $\\pm$ 0.29 & 94.54 $\\pm$ 0.21 \\\\\n",
      " & fedavg & 69.11 $\\pm$ 0.18 & 86.76 $\\pm$ 0.31 & 93.60 $\\pm$ 0.39 & 80.49 $\\pm$ 0.35 & 93.76 $\\pm$ 0.26 \\\\\n",
      " & fedcurv & 68.93 $\\pm$ 0.17 & 86.87 $\\pm$ 0.31 & 93.85 $\\pm$ 0.40 & 80.40 $\\pm$ 0.35 & 93.37 $\\pm$ 0.31 \\\\\n",
      " & fedprox & 69.09 $\\pm$ 0.16 & 87.16 $\\pm$ 0.31 & 93.99 $\\pm$ 0.39 & 80.47 $\\pm$ 0.35 & 93.65 $\\pm$ 0.30 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex = make_auc_latex_table(df_auc, df_auc_err)\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_gap_table(df_final, df_final_err, df_auc, df_auc_err):\n",
    "    # Define columns for the gap computation\n",
    "    columns = [col for col in df_final.columns if col not in ('base', 'algorithm')]\n",
    "    gaps_final = {}\n",
    "    gaps_auc = {}\n",
    "\n",
    "    # Calculate the gaps for each dataset\n",
    "    for col in columns:\n",
    "        max_final = df_final[col].max()\n",
    "        min_final = df_final[col].min()\n",
    "        max_auc = df_auc[col].max()\n",
    "        min_auc = df_auc[col].min()\n",
    "\n",
    "        # Compute relative gaps in percentage ((highest - lowest) / lowest) * 100\n",
    "        gaps_final[col] = ((max_final - min_final) / min_final * 100) if min_final != 0 else float('inf')\n",
    "        gaps_auc[col] = ((max_auc - min_auc) / min_auc * 100) if min_auc != 0 else float('inf')\n",
    "\n",
    "    # Start building the LaTeX table\n",
    "    latex = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{Relative Gaps in Percentage for Final and AUC Scores across Datasets}\\n\"\n",
    "    latex += \"\\\\label{tab:relative_gaps_percentage}\\n\\\\begin{tabular}{lcc}\\n\\\\toprule\\n\"\n",
    "    latex += \"\\\\textbf{Dataset} & \\\\textbf{Final Gap (\\%) } & \\\\textbf{AUC Gap (\\%) } \\\\\\\\\\n\\\\midrule\\n\"\n",
    "\n",
    "    # Add data rows to the LaTeX table\n",
    "    for col in columns:\n",
    "        final_gap = f\"{gaps_final[col]:.2f}\\%\" if gaps_final[col] != float('inf') else \"Infinity\"\n",
    "        auc_gap = f\"{gaps_auc[col]:.2f}\\%\" if gaps_auc[col] != float('inf') else \"Infinity\"\n",
    "        latex += f\"{col} & {final_gap} & {auc_gap} \\\\\\\\\\n\"\n",
    "    \n",
    "    latex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{Relative Gaps in Percentage for Final and AUC Scores across Datasets}\n",
      "\\label{tab:relative_gaps_percentage}\n",
      "\\begin{tabular}{lcc}\n",
      "\\toprule\n",
      "\\textbf{Dataset} & \\textbf{Final Gap (\\%) } & \\textbf{AUC Gap (\\%) } \\\\\n",
      "\\midrule\n",
      "cifar100 & 22.09\\% & 17.50\\% \\\\\n",
      "combined & 4.33\\% & 4.20\\% \\\\\n",
      "fashionmnist & 1.78\\% & 3.00\\% \\\\\n",
      "kmnist & 6.02\\% & 4.38\\% \\\\\n",
      "mnist & 2.87\\% & 2.23\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex = make_gap_table(df_final, df_final_err, df_auc, df_auc_err)\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
