{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5413/4256843647.py:4: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-whitegrid')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd\n",
    "from plot import *\n",
    "from analyze import *\n",
    "from analyze_budget import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_df(series, exclude_keys=None):\n",
    "    \"\"\"\n",
    "    Takes a pandas Series with a MultiIndex and folds over all keys except for those specified\n",
    "    in `exclude_keys` by concatenating the key name and its value into the 'algo' column values.\n",
    "\n",
    "    Parameters:\n",
    "    - series: pandas.Series with a MultiIndex.\n",
    "    - exclude_keys: list of strings representing keys to exclude from the folding process.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with 'algo' and 'dataset' columns, where 'algo' has been modified to include\n",
    "      information from other keys.\n",
    "    \"\"\"\n",
    "\n",
    "    if exclude_keys is None:\n",
    "      exclude_keys=['algo', 'dataset', 'final_acc']\n",
    "    # Convert the Series into a DataFrame\n",
    "    df = series.reset_index()\n",
    "    \n",
    "    # # Initialize a column to store the modified algo values\n",
    "    df['modified_algo'] = df['algo']\n",
    "    exclude_keys += ['modified_algo']\n",
    "    \n",
    "    # # Iterate over each level of the original MultiIndex (now columns in df)\n",
    "    for key in df.columns:\n",
    "        if key not in exclude_keys:\n",
    "            # Append the key name and its value to the 'modified_algo' entries\n",
    "            df['modified_algo'] = df['modified_algo'] + '_' + key + ':' + df[key].astype(str)\n",
    "    \n",
    "    # # Select and rename the relevant columns for the final DataFrame\n",
    "    final_df = df[['modified_algo', 'dataset', series.name]].copy()\n",
    "    final_df.rename(columns={'modified_algo': 'algo', series.name: 'value'}, inplace=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def aggregate_results(df, keys=None, metric=None, post_process=True,\n",
    "                      error_type=\"sem\"):\n",
    "   if keys is None:\n",
    "      keys = [\"algo\", \"use_contrastive\"]\n",
    "   if metric is None:\n",
    "      metric = \"final_acc\"\n",
    "   keys += [\"dataset\"]\n",
    "   m = df.groupby(keys)[\n",
    "         metric].mean()\n",
    "   if error_type == \"sem\":\n",
    "      stderr = df.groupby(keys)[metric].sem()\n",
    "   else:\n",
    "      stderr = df.groupby(keys)[metric].std()\n",
    "   if post_process:\n",
    "      exclude_keys=[\"algo\", \"dataset\", metric]\n",
    "      m = postprocess_df(m, exclude_keys)\n",
    "      stderr = postprocess_df(stderr, exclude_keys)\n",
    "   return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=None\n",
    "error_type=\"sem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_for_table(m):\n",
    "    res = m.copy()\n",
    "    # Remove the \"_use_contrastive:False\" part for cleaner extraction\n",
    "    res['algo_clean'] = res['algo'].str.replace('_use_contrastive:False', '')\n",
    "\n",
    "    # Now, extract 'base' and 'algorithm' accurately\n",
    "    res['base'] = res['algo_clean'].str.extract(r'^([^_]+)')[0]\n",
    "    res['algorithm'] = res['algo_clean'].str.extract(r'_(.+)$')[0]\n",
    "\n",
    "    # Fill NaN in 'algorithm' with 'vanilla'\n",
    "    res['algorithm'].fillna('vanilla', inplace=True)\n",
    "\n",
    "    # Drop the columns we don't need anymore\n",
    "    res.drop(['algo', 'algo_clean'], axis=1, inplace=True)\n",
    "\n",
    "    res = res.pivot_table(index=['base', 'algorithm'], columns='dataset', values='value', aggfunc='first').reset_index()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickbest(m, stderr, algo_part):\n",
    "    # Create empty DataFrames to hold the best configurations and their corresponding standard errors\n",
    "    best_configs = pd.DataFrame()\n",
    "    best_errors = pd.DataFrame()\n",
    "    \n",
    "    # Filter both DataFrames to include only the rows where the 'algo' column contains the algorithm part\n",
    "    filtered_m = m[m['algo'].str.contains(algo_part)]\n",
    "    filtered_stderr = stderr[stderr['algo'].str.contains(algo_part)]\n",
    "    \n",
    "    # Loop over each unique dataset\n",
    "    for dataset in filtered_m['dataset'].unique():\n",
    "        # Filter to only include rows for this dataset\n",
    "        dataset_m = filtered_m[filtered_m['dataset'] == dataset]\n",
    "        dataset_stderr = filtered_stderr[filtered_stderr['dataset'] == dataset]\n",
    "        \n",
    "        # Find the index of the row with the highest 'mean' value in this subset\n",
    "        best_index = dataset_m['value'].idxmax()\n",
    "        \n",
    "        # Append the row at best_index to the best_configs DataFrame and the corresponding errors\n",
    "        best_configs = best_configs.append(dataset_m.loc[best_index])\n",
    "        best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
    "    \n",
    "    # Reset index of the resulting DataFrames for cleanliness\n",
    "    best_configs.reset_index(drop=True, inplace=True)\n",
    "    best_errors.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return best_configs, best_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_sparse = True\n",
    "add_data_backward = True\n",
    "make_new_opt = False\n",
    "\n",
    "remap = {\n",
    "\n",
    "# f'modmod_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod',\n",
    "# f'recv_data_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'data',\n",
    "# f'grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'fed',\n",
    "\n",
    "# f'modmod+recv_data_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod+data',\n",
    "# f'modmod+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod+fed',\n",
    "# f'recv_data+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'data + fed',\n",
    "\n",
    "# f'modmod+heuristic_data_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod+data',\n",
    "# f'modmod+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod+fed',\n",
    "# f'heuristic_data+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'data+fed',\n",
    "\n",
    "f'recv_data+modmod+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod + data + fed',\n",
    "f'heuristic_data+modmod+grad_sharing_no_sparse_{no_sparse}_recv_mod_add_data_backward_{add_data_backward}_make_new_opt_{make_new_opt}': 'modmod + data + fed',\n",
    "\n",
    "# 'heuristic_data': 'data',\n",
    "# 'heuristic_data+grad_sharing': 'data + fed',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_modular_combine(metric, only_all=False):\n",
    "    df = pd.read_csv('combine_modes_results.csv')\n",
    "    cifar_df = pd.read_csv('cifar_combine_modes_results.csv')\n",
    "    df = pd.concat([cifar_df, df])\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = m['algorithm'].map(remap)\n",
    "    stderr['algorithm'] = stderr['algorithm'].map(remap)\n",
    "    m = m[m['base'] == 'modular']\n",
    "    # hack\n",
    "    if only_all:\n",
    "        m = m[m['algorithm'] == 'modmod + data + fed']\n",
    "    stderr = stderr[stderr['base'] == 'modular']\n",
    "    # hack\n",
    "    if only_all:\n",
    "        stderr = stderr[stderr['algorithm'] == 'modmod + data + fed']\n",
    "    m = m[~pd.isna(m['algorithm'])]\n",
    "    stderr = stderr[~pd.isna(stderr['algorithm'])]\n",
    "    m = m.groupby(['base', 'algorithm']).mean().reset_index()\n",
    "    stderr = stderr.groupby(['base', 'algorithm']).mean().reset_index()\n",
    "    return m, stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_monolithic_combine(metric):\n",
    "    df = pd.read_csv('monolithic_combine_modes_results.csv')\n",
    "    cifar_df = pd.read_csv('cifar100_monolithic_combine_modes_results.csv')\n",
    "    df = pd.concat([cifar_df, df])\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = m['algorithm'].map(remap)\n",
    "    stderr['algorithm'] = stderr['algorithm'].map(remap)\n",
    "    m = m[m['base'] == 'monolithic']\n",
    "    stderr = stderr[stderr['base'] == 'monolithic']\n",
    "    m = m[~pd.isna(m['algorithm'])]\n",
    "    stderr = stderr[~pd.isna(stderr['algorithm'])]\n",
    "    m = m.groupby(['base', 'algorithm']).mean().reset_index()\n",
    "    stderr = stderr.groupby(['base', 'algorithm']).mean().reset_index()\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_baseline(metric):\n",
    "    df = pd.read_csv('experiment_results/vanilla_jorge_setting_basis_no_sparse.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric,\n",
    "                                    error_type=error_type)\n",
    "\n",
    "\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recv(metric):\n",
    "    # analyze('experiment_results/jorge_setting_recv')\n",
    "    df = pd.read_csv('experiment_results/jorge_setting_recv.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric,\n",
    "                                    error_type=error_type)\n",
    "\n",
    "\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = 'data'\n",
    "    stderr['algorithm'] = 'data'\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_modmod(metric):\n",
    "    df = pd.read_csv('experiment_results/jorge_setting_lowest_task_id_wins_modmod_test_sync_base_True_opt_with_random_False_frozen_False_transfer_decoder_True_transfer_structure_True_no_sparse_basis_True.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "\n",
    "    leep_df = pd.read_csv('experiment_results/leep_jorge_setting_lowest_task_id_wins_modmod_test_sync_base_True_opt_with_random_False_frozen_False_transfer_decoder_True_transfer_structure_True_no_sparse_basis_True.csv')\n",
    "    leep_df = leep_df[leep_df['use_contrastive'] == False]\n",
    "    leep_df = leep_df[leep_df['dataset'] == 'combined']\n",
    "\n",
    "    df = pd.concat([df, leep_df])\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = 'modmod'\n",
    "    stderr['algorithm'] = 'modmod'\n",
    "    return m, stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fedavg(metric):\n",
    "    df = pd.read_csv('experiment_results/jorge_setting_fedavg.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = 'fedavg'\n",
    "    stderr['algorithm'] = 'fedavg'\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fl(metric):\n",
    "    df = pd.read_csv('best_fl_results.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "\n",
    "    bases = ['modular', 'monolithic']\n",
    "    fed_algos = ['fedcurv', 'fedprox']\n",
    "    best_fls = []\n",
    "    best_errs = []\n",
    "    for base in bases:\n",
    "        for fed_algo in fed_algos:\n",
    "            best_fl, best_err = pickbest(m, stderr, f\"{base}_{fed_algo}\")\n",
    "            best_fl['algo'] = f\"{base}_{fed_algo}\"\n",
    "            best_err['algo'] = f\"{base}_{fed_algo}\"\n",
    "\n",
    "            best_fls.append(best_fl)\n",
    "            best_errs.append(best_err)\n",
    "\n",
    "    best_fl = pd.concat(best_fls)\n",
    "    best_err = pd.concat(best_errs)\n",
    "    best_fl = format_df_for_table(best_fl)\n",
    "    best_err = format_df_for_table(best_err)\n",
    "    return best_fl, best_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fedfish(metric):\n",
    "    # analyze('fedfish_results')\n",
    "    df = pd.read_csv('fedfish_results.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m = format_df_for_table(m)\n",
    "    stderr = format_df_for_table(stderr)\n",
    "    m['algorithm'] = 'fedfish'\n",
    "    stderr['algorithm'] = 'fedfish'\n",
    "    return m, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fedfish_best(metric):\n",
    "    df = pd.read_csv('tune_temp_fedfish_results.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m, stderr = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "\n",
    "    df = pd.read_csv('fedfish_results.csv')\n",
    "    df = df[df['use_contrastive'] == False]\n",
    "    m_default, stderr_default = aggregate_results(df, keys=keys, metric=metric, error_type=error_type)\n",
    "    m_default['algo'] = m_default['algo'].str.replace('_use_contrastive:False', '_fedfish_default')\n",
    "    stderr_default['algo'] = stderr_default['algo'].str.replace('_use_contrastive:False', '_fedfish_default')\n",
    "\n",
    "    m = pd.concat([m, m_default])\n",
    "    stderr = pd.concat([stderr, stderr_default])\n",
    "\n",
    "    bases = ['modular', 'monolithic']\n",
    "    fed_algos = ['fedfish'] \n",
    "    best_fls = []\n",
    "    best_errs = []\n",
    "\n",
    "    default_m, default_err = load_fedfish(metric)\n",
    "\n",
    "    for base in bases:\n",
    "        for fed_algo in fed_algos:\n",
    "            best_fl, best_err = pickbest(m, stderr, f\"{base}_{fed_algo}\")\n",
    "            best_fl['algo'] = f\"{base}_{fed_algo}\"\n",
    "            best_err['algo'] = f\"{base}_{fed_algo}\"\n",
    "\n",
    "            best_fls.append(best_fl)\n",
    "            best_errs.append(best_err)\n",
    "\n",
    "    best_fl = pd.concat(best_fls)\n",
    "    best_err = pd.concat(best_errs)\n",
    "    best_fl = format_df_for_table(best_fl)\n",
    "    best_err = format_df_for_table(best_err)\n",
    "    \n",
    "    # replace best_fl with m if it's better\n",
    "    return best_fl, best_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n"
     ]
    }
   ],
   "source": [
    "metric = 'auc'\n",
    "funcs = [load_baseline, load_recv, load_fedavg, load_fedfish_best, load_fl, load_modmod, load_modular_combine, load_monolithic_combine]\n",
    "dfs = []\n",
    "df_errs = []\n",
    "for func in funcs:\n",
    "    m, err = func(metric=metric)\n",
    "    dfs.append(m)\n",
    "    df_errs.append(err)\n",
    "df_auc = pd.concat(dfs)\n",
    "df_auc_err = pd.concat(df_errs)\n",
    "\n",
    "\n",
    "# Resetting the index to fix any issues with non-unique or unordered indices\n",
    "df_auc.reset_index(drop=True, inplace=True)\n",
    "# Resetting the index to fix any issues with non-unique or unordered indices\n",
    "df_auc_err.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if metric == 'final_acc':\n",
    "    df_auc.loc[:, ~df_auc.columns.isin(['base', 'algorithm'])] *= 100\n",
    "    df_auc_err.loc[:, ~df_auc_err.columns.isin(['base', 'algorithm'])] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_configs = best_configs.append(dataset_m.loc[best_index])\n",
      "/tmp/ipykernel_5413/4106921490.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_errors = best_errors.append(dataset_stderr.loc[best_index])\n"
     ]
    }
   ],
   "source": [
    "metric = 'final_acc'\n",
    "funcs = [load_baseline, load_recv, load_fedavg, load_fedfish_best, load_fl, load_modmod, load_modular_combine, load_monolithic_combine]\n",
    "dfs = []\n",
    "df_errs = []\n",
    "for func in funcs:\n",
    "    m, err = func(metric=metric)\n",
    "    dfs.append(m)\n",
    "    df_errs.append(err)\n",
    "df_final = pd.concat(dfs)\n",
    "df_final_err = pd.concat(df_errs)\n",
    "\n",
    "\n",
    "# Resetting the index to fix any issues with non-unique or unordered indices\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "# Resetting the index to fix any issues with non-unique or unordered indices\n",
    "df_final_err.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if metric == 'final_acc':\n",
    "    df_final.loc[:, ~df_final.columns.isin(['base', 'algorithm'])] *= 100\n",
    "    df_final_err.loc[:, ~df_final_err.columns.isin(['base', 'algorithm'])] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_table_v3(df_final, df_final_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def make_latex_table(df_final, df_final_err, df_auc, df_auc_err, remap_name=None):\n",
    "#     if not remap_name:\n",
    "#         remap_name = {}\n",
    "\n",
    "#     # Define columns for the table display\n",
    "#     columns = ['base', 'algorithm'] + [col for col in df_final.columns if col not in ('base', 'algorithm')]\n",
    "#     max_final = df_final.max(numeric_only=True)  # Calculate max values for final accuracy columns to highlight best results\n",
    "#     min_final = df_final.min(numeric_only=True)  # Calculate min values for final accuracy columns\n",
    "#     max_auc = df_auc.max(numeric_only=True)  # Calculate max values for AUC columns to highlight best results\n",
    "#     min_auc = df_auc.min(numeric_only=True)  # Calculate min values for AUC columns\n",
    "\n",
    "#     # Start building the LaTeX table\n",
    "#     latex = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{Performance Metrics across Datasets and Algorithms}\\n\"\n",
    "#     latex += \"\\\\label{tab:performance_metrics}\\n\\\\begin{adjustbox}{width=1.25\\\\textwidth}\\n\\\\begin{tabular}{ll\" + \"c\" * (len(columns) - 2) + \"}\\n\\\\toprule\\n\"\n",
    "#     latex += \" & \".join([\"\\\\textbf{\" + col.capitalize() + \"}\" for col in columns]) + \" \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    \n",
    "#     # Organize data by 'base' first, then iterate\n",
    "#     df_grouped = df_final.groupby('base')\n",
    "#     for base, group in df_grouped:\n",
    "#         first = True\n",
    "#         for index, row in group.iterrows():\n",
    "#             algorithm = remap_name.get(row['algorithm'], row['algorithm'])\n",
    "#             row_items = [base if first else \"\", algorithm]  # Only show the base for the first entry\n",
    "            \n",
    "#             for dataset in columns[2:]:  # Start from 2 to skip 'base' and 'algorithm'\n",
    "#                 final_value = df_final.loc[index, dataset]\n",
    "#                 final_error = df_final_err.loc[index, dataset]\n",
    "#                 auc_value = df_auc.loc[index, dataset]\n",
    "#                 auc_error = df_auc_err.loc[index, dataset]\n",
    "\n",
    "#                 # Determine if the values should be bold and colored\n",
    "#                 final_str = f\"{final_value:.2f} $\\\\pm$ {final_error:.2f}\"\n",
    "#                 auc_str = f\"{auc_value:.2f} $\\\\pm$ {auc_error:.2f}\"\n",
    "\n",
    "#                 if final_value == max_final[dataset]:\n",
    "#                     final_str = f\"\\\\textbf{{\\\\textcolor{{Green}}{{{final_str}}}}}\"\n",
    "#                 elif final_value == min_final[dataset]:\n",
    "#                     final_str = f\"\\\\textbf{{\\\\textcolor{{red}}{{{final_str}}}}}\"\n",
    "\n",
    "#                 if auc_value == max_auc[dataset]:\n",
    "#                     auc_str = f\"\\\\textbf{{\\\\textcolor{{Green}}{{{auc_str}}}}}\"\n",
    "#                 elif auc_value == min_auc[dataset]:\n",
    "#                     auc_str = f\"\\\\textbf{{\\\\textcolor{{red}}{{{auc_str}}}}}\"\n",
    "                \n",
    "#                 row_items.append(f\"{final_str}/{auc_str}\")  # Append the formatted string for this dataset\n",
    "            \n",
    "#             latex += \" & \".join(row_items) + \" \\\\\\\\\\n\"\n",
    "#             first = False  # Subsequent rows won't show the 'base' again\n",
    "    \n",
    "#     latex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{adjustbox}\\n\\\\end{table}\\n\"\n",
    "#     return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_latex_table(df_final, df_final_err, df_auc, df_auc_err, remap_name=None):\n",
    "    if not remap_name:\n",
    "        remap_name = {}\n",
    "\n",
    "    # Define columns for the table display\n",
    "    columns = ['base', 'algorithm'] + [col for col in df_final.columns if col not in ('base', 'algorithm')]\n",
    "    max_final = df_final.max(numeric_only=True)  # Calculate max values for final accuracy columns to highlight best results\n",
    "    max_auc = df_auc.max(numeric_only=True)  # Calculate max values for AUC columns to highlight best results\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    latex = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{Performance Metrics across Datasets and Algorithms. The first number is the average AUC and the second is the final average accuracy. Standard error is included.}\\n\"\n",
    "    latex += \"\\\\label{tab:all}\\n\\\\begin{adjustbox}{width=1.25\\\\textwidth}\\n\\\\begin{tabular}{ll\" + \"c\" * (len(columns) - 2) + \"}\\n\\\\toprule\\n\"\n",
    "    latex += \" & \".join([\"\\\\textbf{\" + col.capitalize() + \"}\" for col in columns]) + \" \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    \n",
    "    # Organize data by 'base' first, then iterate\n",
    "    df_grouped = df_final.groupby('base')\n",
    "    for base, group in df_grouped:\n",
    "        first = True\n",
    "        for index, row in group.iterrows():\n",
    "            algorithm = remap_name.get(row['algorithm'], row['algorithm'])\n",
    "            row_items = [base if first else \"\", algorithm]  # Only show the base for the first entry\n",
    "            \n",
    "            for dataset in columns[2:]:  # Start from 2 to skip 'base' and 'algorithm'\n",
    "                final_value = df_final.loc[index, dataset]\n",
    "                final_error = df_final_err.loc[index, dataset]\n",
    "                auc_value = df_auc.loc[index, dataset]\n",
    "                auc_error = df_auc_err.loc[index, dataset]\n",
    "                \n",
    "                # Format the values using the \\meanstd command\n",
    "                final_str = f\"\\\\meanstd{{{final_value:.2f}}}{{{final_error:.2f}}}\"\n",
    "                auc_str = f\"\\\\meanstd{{{auc_value:.2f}}}{{{auc_error:.2f}}}\"\n",
    "                if final_value == max_final[dataset]:\n",
    "                    final_str = f\"\\\\textbf{{{final_str}}}\"\n",
    "                if auc_value == max_auc[dataset]:\n",
    "                    auc_str = f\"\\\\textbf{{{auc_str}}}\"\n",
    "                \n",
    "                row_items.append(f\"{final_str}/{auc_str}\")  # Append the formatted string for this dataset\n",
    "            \n",
    "            latex += \" & \".join(row_items) + \" \\\\\\\\\\n\"\n",
    "            first = False  # Subsequent rows won't show the 'base' again\n",
    "    \n",
    "    latex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{adjustbox}\\n\\\\end{table}\\n\"\n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{Performance Metrics across Datasets and Algorithms. The first number is the average AUC and the second is the final average accuracy. Standard error is included.}\n",
      "\\label{tab:all}\n",
      "\\begin{adjustbox}{width=1.25\\textwidth}\n",
      "\\begin{tabular}{llccccc}\n",
      "\\toprule\n",
      "\\textbf{Base} & \\textbf{Algorithm} & \\textbf{Cifar100} & \\textbf{Combined} & \\textbf{Fashionmnist} & \\textbf{Kmnist} & \\textbf{Mnist} \\\\\n",
      "\\midrule\n",
      "modular & vanilla & \\meanstd{70.04}{0.14}/\\meanstd{71.83}{0.13} & \\meanstd{88.58}{0.36}/\\meanstd{88.05}{0.28} & \\meanstd{92.80}{0.31}/\\meanstd{92.03}{0.32} & \\meanstd{80.63}{0.31}/\\meanstd{80.62}{0.31} & \\meanstd{93.47}{0.20}/\\meanstd{92.68}{0.22} \\\\\n",
      " & data & \\meanstd{71.86}{0.16}/\\meanstd{73.42}{0.14} & \\meanstd{89.03}{0.33}/\\meanstd{89.48}{0.25} & \\meanstd{93.56}{0.28}/\\meanstd{92.97}{0.30} & \\meanstd{82.59}{0.26}/\\meanstd{82.04}{0.29} & \\textbf{\\meanstd{94.60}{0.12}}/\\meanstd{93.89}{0.14} \\\\\n",
      " & fedavg & \\meanstd{70.99}{0.14}/\\meanstd{73.96}{0.14} & \\meanstd{88.45}{0.37}/\\meanstd{87.99}{0.31} & \\meanstd{92.46}{0.45}/\\meanstd{91.96}{0.45} & \\meanstd{80.04}{0.35}/\\meanstd{80.10}{0.34} & \\meanstd{93.57}{0.18}/\\meanstd{92.82}{0.23} \\\\\n",
      " & fedfish & \\meanstd{71.10}{0.13}/\\meanstd{73.97}{0.15} & \\meanstd{88.46}{0.37}/\\meanstd{87.99}{0.29} & \\meanstd{93.08}{0.39}/\\meanstd{92.33}{0.44} & \\meanstd{80.32}{0.36}/\\meanstd{80.13}{0.38} & \\meanstd{93.77}{0.19}/\\meanstd{92.76}{0.26} \\\\\n",
      " & fedcurv & \\meanstd{71.11}{0.13}/\\meanstd{73.94}{0.14} & \\meanstd{88.45}{0.37}/\\meanstd{87.99}{0.29} & \\meanstd{93.06}{0.40}/\\meanstd{92.32}{0.44} & \\meanstd{80.34}{0.36}/\\meanstd{80.14}{0.38} & \\meanstd{93.78}{0.19}/\\meanstd{92.76}{0.26} \\\\\n",
      " & fedprox & \\meanstd{71.82}{0.14}/\\meanstd{73.85}{0.13} & \\meanstd{88.47}{0.37}/\\meanstd{88.02}{0.29} & \\meanstd{92.93}{0.41}/\\meanstd{92.07}{0.46} & \\meanstd{80.48}{0.35}/\\meanstd{80.20}{0.35} & \\meanstd{93.93}{0.17}/\\meanstd{93.05}{0.21} \\\\\n",
      " & modmod & \\meanstd{76.77}{0.08}/\\meanstd{76.80}{0.13} & \\meanstd{89.65}{0.30}/\\meanstd{89.62}{0.26} & \\meanstd{93.28}{0.40}/\\meanstd{93.26}{0.41} & \\meanstd{81.83}{0.27}/\\meanstd{81.78}{0.29} & \\meanstd{94.08}{0.18}/\\meanstd{93.94}{0.19} \\\\\n",
      " & modmod + data + fed & \\textbf{\\meanstd{77.05}{0.10}}/\\textbf{\\meanstd{77.07}{0.14}} & \\textbf{\\meanstd{90.31}{0.28}}/\\textbf{\\meanstd{90.41}{0.24}} & \\textbf{\\meanstd{94.10}{0.31}}/\\meanstd{94.43}{0.35} & \\textbf{\\meanstd{82.93}{0.23}}/\\textbf{\\meanstd{82.90}{0.25}} & \\meanstd{94.57}{0.12}/\\textbf{\\meanstd{94.75}{0.14}} \\\\\n",
      "monolithic & vanilla & \\meanstd{63.11}{0.32}/\\meanstd{65.60}{0.32} & \\meanstd{86.59}{0.37}/\\meanstd{87.69}{0.28} & \\meanstd{92.47}{0.33}/\\meanstd{93.27}{0.36} & \\meanstd{78.23}{0.31}/\\meanstd{79.42}{0.31} & \\meanstd{91.96}{0.27}/\\meanstd{93.10}{0.22} \\\\\n",
      " & data & \\meanstd{65.18}{0.17}/\\meanstd{67.23}{0.21} & \\meanstd{87.82}{0.36}/\\meanstd{88.59}{0.28} & \\meanstd{94.02}{0.35}/\\textbf{\\meanstd{94.72}{0.38}} & \\meanstd{80.70}{0.32}/\\meanstd{81.01}{0.29} & \\meanstd{94.20}{0.17}/\\meanstd{94.54}{0.21} \\\\\n",
      " & fedavg & \\meanstd{67.05}{0.16}/\\meanstd{69.11}{0.18} & \\meanstd{86.57}{0.40}/\\meanstd{86.76}{0.31} & \\meanstd{93.68}{0.39}/\\meanstd{93.60}{0.39} & \\meanstd{80.55}{0.33}/\\meanstd{80.49}{0.35} & \\meanstd{93.86}{0.20}/\\meanstd{93.76}{0.26} \\\\\n",
      " & fedfish & \\meanstd{66.85}{0.17}/\\meanstd{68.91}{0.17} & \\meanstd{86.55}{0.41}/\\meanstd{86.82}{0.31} & \\meanstd{93.64}{0.38}/\\meanstd{93.84}{0.40} & \\meanstd{80.39}{0.34}/\\meanstd{80.38}{0.36} & \\meanstd{93.65}{0.24}/\\meanstd{93.37}{0.31} \\\\\n",
      " & fedcurv & \\meanstd{66.79}{0.15}/\\meanstd{68.93}{0.17} & \\meanstd{86.62}{0.41}/\\meanstd{86.87}{0.31} & \\meanstd{93.74}{0.37}/\\meanstd{93.85}{0.40} & \\meanstd{80.39}{0.34}/\\meanstd{80.40}{0.35} & \\meanstd{93.66}{0.24}/\\meanstd{93.37}{0.31} \\\\\n",
      " & fedprox & \\meanstd{67.18}{0.17}/\\meanstd{69.09}{0.16} & \\meanstd{86.86}{0.40}/\\meanstd{87.16}{0.31} & \\meanstd{93.90}{0.35}/\\meanstd{93.99}{0.39} & \\meanstd{80.26}{0.33}/\\meanstd{80.47}{0.35} & \\meanstd{93.74}{0.23}/\\meanstd{93.65}{0.30} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex = make_latex_table(df_final, df_final_err, df_auc, df_auc_err)\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_auc_latex_table(df_auc, df_auc_err, remap_name=None):\n",
    "    if not remap_name:\n",
    "        remap_name = {}\n",
    "\n",
    "    # Define columns for the table display\n",
    "    columns = ['base', 'algorithm'] + [col for col in df_auc.columns if col not in ('base', 'algorithm')]\n",
    "    max_auc = df_auc.max(numeric_only=True)  # Calculate max values for AUC columns to highlight best results\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    latex = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{AUC Metrics across Datasets and Algorithms}\\n\"\n",
    "    latex += \"\\\\label{tab:auc_metrics}\\n\\\\begin{adjustbox}{width=1.25\\\\textwidth}\\n\\\\begin{tabular}{ll\" + \"c\" * (len(columns) - 2) + \"}\\n\\\\toprule\\n\"\n",
    "    latex += \" & \".join([\"\\\\textbf{\" + col.capitalize() + \"}\" for col in columns]) + \" \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    \n",
    "    # Organize data by 'base' first, then iterate\n",
    "    df_grouped = df_auc.groupby('base')\n",
    "    for base, group in df_grouped:\n",
    "        first = True\n",
    "        for index, row in group.iterrows():\n",
    "            algorithm = remap_name.get(row['algorithm'], row['algorithm'])\n",
    "            row_items = [base if first else \"\", algorithm]  # Only show the base for the first entry\n",
    "            \n",
    "            for dataset in columns[2:]:  # Start from 2 to skip 'base' and 'algorithm'\n",
    "                auc_value = df_auc.loc[index, dataset]\n",
    "                auc_error = df_auc_err.loc[index, dataset]\n",
    "                \n",
    "                # Determine if the values should be bold\n",
    "                auc_str = f\"{auc_value:.2f} $\\\\pm$ {auc_error:.2f}\"\n",
    "                if auc_value == max_auc[dataset]:\n",
    "                    auc_str = f\"\\\\textbf{{{auc_str}}}\"\n",
    "                \n",
    "                row_items.append(auc_str)  # Append the formatted string for this dataset\n",
    "            \n",
    "            latex += \" & \".join(row_items) + \" \\\\\\\\\\n\"\n",
    "            first = False  # Subsequent rows won't show the 'base' again\n",
    "    \n",
    "    latex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{adjustbox}\\n\\\\end{table}\\n\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{AUC Metrics across Datasets and Algorithms}\n",
      "\\label{tab:auc_metrics}\n",
      "\\begin{adjustbox}{width=1.25\\textwidth}\n",
      "\\begin{tabular}{llccccc}\n",
      "\\toprule\n",
      "\\textbf{Base} & \\textbf{Algorithm} & \\textbf{Cifar100} & \\textbf{Combined} & \\textbf{Fashionmnist} & \\textbf{Kmnist} & \\textbf{Mnist} \\\\\n",
      "\\midrule\n",
      "modular & vanilla & 71.83 $\\pm$ 0.13 & 88.05 $\\pm$ 0.28 & 92.03 $\\pm$ 0.32 & 80.62 $\\pm$ 0.31 & 92.68 $\\pm$ 0.22 \\\\\n",
      " & data & 73.42 $\\pm$ 0.14 & 89.48 $\\pm$ 0.25 & 92.97 $\\pm$ 0.30 & 82.04 $\\pm$ 0.29 & 93.89 $\\pm$ 0.14 \\\\\n",
      " & fedavg & 73.96 $\\pm$ 0.14 & 87.99 $\\pm$ 0.31 & 91.96 $\\pm$ 0.45 & 80.10 $\\pm$ 0.34 & 92.82 $\\pm$ 0.23 \\\\\n",
      " & fedfish & 73.97 $\\pm$ 0.15 & 87.99 $\\pm$ 0.29 & 92.33 $\\pm$ 0.44 & 80.13 $\\pm$ 0.38 & 92.76 $\\pm$ 0.26 \\\\\n",
      " & fedcurv & 73.94 $\\pm$ 0.14 & 87.99 $\\pm$ 0.29 & 92.32 $\\pm$ 0.44 & 80.14 $\\pm$ 0.38 & 92.76 $\\pm$ 0.26 \\\\\n",
      " & fedprox & 73.85 $\\pm$ 0.13 & 88.02 $\\pm$ 0.29 & 92.07 $\\pm$ 0.46 & 80.20 $\\pm$ 0.35 & 93.05 $\\pm$ 0.21 \\\\\n",
      " & modmod & 76.80 $\\pm$ 0.13 & 89.62 $\\pm$ 0.26 & 93.26 $\\pm$ 0.41 & 81.78 $\\pm$ 0.29 & 93.94 $\\pm$ 0.19 \\\\\n",
      " & modmod + data + fed & \\textbf{77.07 $\\pm$ 0.14} & \\textbf{90.41 $\\pm$ 0.24} & 94.43 $\\pm$ 0.35 & \\textbf{82.90 $\\pm$ 0.25} & \\textbf{94.75 $\\pm$ 0.14} \\\\\n",
      "monolithic & vanilla & 65.60 $\\pm$ 0.32 & 87.69 $\\pm$ 0.28 & 93.27 $\\pm$ 0.36 & 79.42 $\\pm$ 0.31 & 93.10 $\\pm$ 0.22 \\\\\n",
      " & data & 67.23 $\\pm$ 0.21 & 88.59 $\\pm$ 0.28 & \\textbf{94.72 $\\pm$ 0.38} & 81.01 $\\pm$ 0.29 & 94.54 $\\pm$ 0.21 \\\\\n",
      " & fedavg & 69.11 $\\pm$ 0.18 & 86.76 $\\pm$ 0.31 & 93.60 $\\pm$ 0.39 & 80.49 $\\pm$ 0.35 & 93.76 $\\pm$ 0.26 \\\\\n",
      " & fedfish & 68.91 $\\pm$ 0.17 & 86.82 $\\pm$ 0.31 & 93.84 $\\pm$ 0.40 & 80.38 $\\pm$ 0.36 & 93.37 $\\pm$ 0.31 \\\\\n",
      " & fedcurv & 68.93 $\\pm$ 0.17 & 86.87 $\\pm$ 0.31 & 93.85 $\\pm$ 0.40 & 80.40 $\\pm$ 0.35 & 93.37 $\\pm$ 0.31 \\\\\n",
      " & fedprox & 69.09 $\\pm$ 0.16 & 87.16 $\\pm$ 0.31 & 93.99 $\\pm$ 0.39 & 80.47 $\\pm$ 0.35 & 93.65 $\\pm$ 0.30 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex = make_auc_latex_table(df_auc, df_auc_err)\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_gap_table(df_final, df_final_err, df_auc, df_auc_err):\n",
    "    # Define columns for the gap computation\n",
    "    columns = [col for col in df_final.columns if col not in ('base', 'algorithm')]\n",
    "    gaps_final = {}\n",
    "    gaps_auc = {}\n",
    "\n",
    "    # Calculate the gaps for each dataset\n",
    "    for col in columns:\n",
    "        max_final = df_final[col].max()\n",
    "        min_final = df_final[col].min()\n",
    "        max_auc = df_auc[col].max()\n",
    "        min_auc = df_auc[col].min()\n",
    "\n",
    "        # Compute relative gaps in percentage ((highest - lowest) / lowest) * 100\n",
    "        gaps_final[col] = ((max_final - min_final) / min_final * 100) if min_final != 0 else float('inf')\n",
    "        gaps_auc[col] = ((max_auc - min_auc) / min_auc * 100) if min_auc != 0 else float('inf')\n",
    "\n",
    "    # Start building the LaTeX table\n",
    "    latex = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\caption{Relative Gaps in Percentage for Final and AUC Scores across Datasets}\\n\"\n",
    "    latex += \"\\\\label{tab:relative_gaps_percentage}\\n\\\\begin{tabular}{lcc}\\n\\\\toprule\\n\"\n",
    "    latex += \"\\\\textbf{Dataset} & \\\\textbf{Final Gap (\\%) } & \\\\textbf{AUC Gap (\\%) } \\\\\\\\\\n\\\\midrule\\n\"\n",
    "\n",
    "    # Add data rows to the LaTeX table\n",
    "    for col in columns:\n",
    "        final_gap = f\"{gaps_final[col]:.2f}\\%\" if gaps_final[col] != float('inf') else \"Infinity\"\n",
    "        auc_gap = f\"{gaps_auc[col]:.2f}\\%\" if gaps_auc[col] != float('inf') else \"Infinity\"\n",
    "        latex += f\"{col} & {final_gap} & {auc_gap} \\\\\\\\\\n\"\n",
    "    \n",
    "    latex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{Relative Gaps in Percentage for Final and AUC Scores across Datasets}\n",
      "\\label{tab:relative_gaps_percentage}\n",
      "\\begin{tabular}{lcc}\n",
      "\\toprule\n",
      "\\textbf{Dataset} & \\textbf{Final Gap (\\%) } & \\textbf{AUC Gap (\\%) } \\\\\n",
      "\\midrule\n",
      "cifar100 & 22.09\\% & 17.50\\% \\\\\n",
      "combined & 4.35\\% & 4.20\\% \\\\\n",
      "fashionmnist & 1.78\\% & 3.00\\% \\\\\n",
      "kmnist & 6.02\\% & 4.38\\% \\\\\n",
      "mnist & 2.87\\% & 2.23\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex = make_gap_table(df_final, df_final_err, df_auc, df_auc_err)\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
