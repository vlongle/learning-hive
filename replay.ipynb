{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 0, 4, 3, 4, 6, 4, 3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a = [5, 0, 4, 3, 4, 6, 4, 3, 8, 0, 1, 0, 5, 9, 6, 4, 9, 0, 3, 0]\n",
    "a[:2 * 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import omegaconf\n",
    "from shell.utils.experiment_utils import *\n",
    "from shell.utils.metric import *\n",
    "import matplotlib.pyplot as plt\n",
    "from shell.fleet.network import TopologyGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_root_dir = \"testing_contrastive_results\"\n",
    "# save_root_dir = \"testing_contrastive_distinct_init_train_long_results\"\n",
    "# save_root_dir = \"testing_contrastive_distinct_init_adapt_results\"\n",
    "# save_root_dir = \"testing_contrastive_refactor_freezing_results\"\n",
    "# save_root_dir = \"testing_contrastive_results_20epochs\"\n",
    "save_root_dir = \"vanilla_init_big_mod_nocontrast_results\"\n",
    "# save_root_dir = \"finding_hyper_for_mod_contrastive_large_results\"\n",
    "# save_root_dir = \"vanilla_results\"\n",
    "dataset = \"cifar100\"\n",
    "# dataset = \"mnist\"\n",
    "# algo = \"monolithic\"\n",
    "algo = \"modular\"\n",
    "num_train = 256\n",
    "# num_train = 64\n",
    "# seed = 0\n",
    "seed = 1\n",
    "# use_contrastive = True\n",
    "use_contrastive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f\"{dataset}_{algo}_numtrain_{num_train}\"\n",
    "if use_contrastive:\n",
    "    job_name += \"_contrastive\"\n",
    "experiment = os.path.join(save_root_dir, job_name, dataset,algo, f\"seed_{seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'component_update_freq': 100, 'num_epochs': 100, 'init_component_update_freq': 500, 'init_num_epochs': 500, 'save_freq': 20}, 'dataset': {'dataset_name': 'cifar100', 'num_tasks': 20, 'num_classes_per_task': 5, 'with_replacement': False, 'num_trains_per_class': 256, 'num_vals_per_class': -1, 'remap_labels': True}, 'net': {'name': 'cnn', 'depth': 4, 'channels': 50, 'conv_kernel': 3, 'maxpool_kernel': 2, 'padding': 1, 'dropout': 0.5}, 'sharing_strategy': {'name': 'no_sharing', 'num_coms_per_round': 0}, 'seed': 1, 'algo': 'modular', 'job_name': 'cifar100_modular_numtrain_256', 'num_agents': 4, 'root_save_dir': 'vanilla_init_big_mod_nocontrast_results', 'parallel': True, 'num_init_tasks': 4, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': False}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = os.path.join(experiment, \"hydra_out\", \".hydra\", \"config.yaml\")\n",
    "# read the config file\n",
    "cfg = omegaconf.OmegaConf.load(config_path)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'component_update_freq': 100, 'num_epochs': 100, 'init_component_update_freq': 500, 'init_num_epochs': 500, 'save_freq': 20}, 'dataset': {'dataset_name': 'cifar100', 'num_tasks': 20, 'num_classes_per_task': 5, 'with_replacement': False, 'num_trains_per_class': 256, 'num_vals_per_class': -1, 'remap_labels': True}, 'net': {'name': 'cnn', 'depth': 4, 'channels': 50, 'conv_kernel': 3, 'maxpool_kernel': 2, 'padding': 1, 'dropout': 0.5}, 'sharing_strategy': {'name': 'no_sharing', 'num_coms_per_round': 0}, 'seed': 1, 'algo': 'modular', 'job_name': 'cifar100_modular_numtrain_256', 'num_agents': 4, 'root_save_dir': 'vanilla_init_big_mod_nocontrast_results', 'parallel': True, 'num_init_tasks': 4, 'agent': {'save_dir': '${root_save_dir}/${job_name}/${dataset.dataset_name}/${algo}/seed_${seed}', 'batch_size': 64, 'memory_size': 32, 'improvement_threshold': 0.05, 'use_contrastive': False}}\n",
      "i_size 32\n",
      "num_classes 5\n",
      "net_cfg {'name': 'cnn', 'depth': 4, 'channels': 50, 'conv_kernel': 3, 'maxpool_kernel': 2, 'padding': 1, 'dropout': 0.5, 'i_size': 32, 'num_classes': 5, 'num_tasks': 20, 'num_init_tasks': 4}\n",
      "<class 'shell.learners.er_dynamic.CompositionalDynamicER'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph, datasets, NetCls, LearnerCls, net_cfg, agent_cfg, train_cfg = setup_experiment(cfg)\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([68, 60, 90, 97, 15, 26, 40, 87, 73,  0,  2, 21, 92, 76, 64, 35, 83,\n",
       "        28, 46, 45, 71, 70, 55,  3,  8, 47, 74, 94, 86, 31, 11, 34, 32, 96,\n",
       "        69, 22, 82, 95, 18, 52, 13, 33, 16, 84, 53, 75, 57, 36, 30, 12,  5,\n",
       "        93,  9, 51, 72, 56, 78, 65, 88, 24, 44,  4, 27, 37, 48, 62, 14, 50,\n",
       "        43, 42, 29, 63, 81, 91, 67, 23, 39, 85, 10, 41, 25, 59, 38, 80, 54,\n",
       "        17, 20,  6, 79, 98,  7, 61, 19, 58, 89, 66, 49,  1, 99, 77]),\n",
       " array([63, 93, 97, 51, 96, 92, 82,  6, 32, 20, 70, 54, 17, 84, 77, 62, 86,\n",
       "        75,  1, 31, 45, 27, 25, 33, 76, 11, 56, 13, 36, 87, 37, 24, 28, 65,\n",
       "        44, 48, 81, 42, 12, 74, 40, 16, 55, 72, 88, 90, 43, 66, 47,  9, 99,\n",
       "        19, 67,  8, 50, 38, 39, 69, 73, 52, 18, 60, 22,  3, 15, 57, 68, 91,\n",
       "        71, 85,  4, 61, 94, 26, 23, 83, 10, 30, 46, 53, 29, 79,  5, 58,  7,\n",
       "        21, 59, 98, 64, 14, 80, 89, 35, 95, 78,  2,  0, 41, 49, 34]),\n",
       " array([13,  0, 10, 22,  2, 93, 80,  5,  7, 99, 94, 76, 54, 12, 83,  9, 39,\n",
       "         8, 87, 98, 32, 46, 61, 69, 70, 92, 71, 29, 27, 75, 21, 17, 85,  1,\n",
       "        74, 97, 43, 91, 51, 59, 14, 20, 63,  6, 41, 25, 81, 65, 53, 57, 67,\n",
       "        35, 31, 45, 64, 44, 68, 30, 84, 73, 86, 26, 95, 37, 48, 56, 15, 78,\n",
       "        38, 19, 90, 58, 34, 77, 89, 88, 36, 42, 23, 52, 33,  3, 62, 55, 40,\n",
       "        60, 50, 72, 24, 16, 82, 28, 18, 49, 47, 66, 96, 79, 11,  4]),\n",
       " array([ 5, 81, 60, 19, 41, 97, 98, 51, 26, 84, 80, 17, 82,  2, 44, 83, 75,\n",
       "         8, 45, 93,  9,  0, 94, 52, 10, 99, 16, 24, 11, 27, 34, 65, 30, 12,\n",
       "        92, 56, 42, 55, 87, 88,  7, 33, 32, 91, 29, 40, 20, 86, 96, 48, 31,\n",
       "        71, 79, 72, 46, 61, 36,  4, 18, 43,  1, 28, 53, 54, 25, 78, 90, 74,\n",
       "        37, 38, 95, 69, 14, 58, 23, 62, 64, 76, 68, 13, 22, 63, 47,  6, 21,\n",
       "        35,  3, 89, 77, 39, 67, 70, 66, 15, 73, 85, 50, 59, 57, 49])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_sequence_list = [dataset.class_sequence for dataset in datasets]\n",
    "classes_sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNSoftLLDynamic(\n",
       "  (structure): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (1): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (2): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (3): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (4): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (5): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (6): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (7): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (8): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (9): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (10): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (11): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (12): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (13): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (14): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (15): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (16): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (17): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (18): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "      (19): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "  )\n",
       "  (softmax): Softmax(dim=0)\n",
       "  (components): ModuleList(\n",
       "    (0-5): 6 x Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (decoder): ModuleList(\n",
       "    (0-19): 20 x Linear(in_features=200, out_features=5, bias=True)\n",
       "  )\n",
       "  (transform): Normalize(mean=(0.5079, 0.4872, 0.4415), std=(0.2676, 0.2567, 0.2765))\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=200, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_id = 5\n",
    "num_added_components = 2\n",
    "agent_id = 0\n",
    "net = load_net(cfg, NetCls, net_cfg, agent_id=agent_id, task_id=task_id, num_added_components=num_added_components)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (1): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (2): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (3): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (4): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (5): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (6): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (7): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (8): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (9): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (10): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (11): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (12): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (13): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (14): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (15): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (16): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (17): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (18): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       "    (19): Parameter containing: [torch.float32 of size 6x4 (GPU 0)]\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1.],\n",
       "        [-inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.structure[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[agent_id]\n",
    "testloaders = {task: torch.utils.data.DataLoader(testset,\n",
    "                                                         batch_size=128,\n",
    "                                                         shuffle=False,\n",
    "                                                         num_workers=0,\n",
    "                                                         pin_memory=True,\n",
    "                                                         ) for task, testset in enumerate(dataset.testset[:(task_id+1)])}\n",
    "# testloaders = {task: torch.utils.data.DataLoader(testset,\n",
    "#                                                          batch_size=128,\n",
    "#                                                          shuffle=False,\n",
    "#                                                          num_workers=0,\n",
    "#                                                          pin_memory=True,\n",
    "#                                                          ) for task, testset in enumerate(dataset.valset[:(task_id+1)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.79,\n",
       " 1: 0.802,\n",
       " 2: 0.81,\n",
       " 3: 0.684,\n",
       " 4: 0.724,\n",
       " 5: 0.77,\n",
       " 'avg': 0.7633333333333333}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = {}\n",
    "with torch.no_grad():\n",
    "    for task_id, testloader in testloaders.items():\n",
    "        correct = 0.\n",
    "        n = 0.\n",
    "        for X, y in testloader:\n",
    "            X = X.to(net.device)\n",
    "            y = y.to(net.device)\n",
    "            Y_hat = net(X, task_id)\n",
    "            correct += (Y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += len(y)\n",
    "            acc[task_id] = correct/n\n",
    "\n",
    "acc[\"avg\"] = sum(acc.values())/len(acc)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_task</th>\n",
       "      <th>test_task</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.611221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.611221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.611221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.611221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.611221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_task test_task  test_acc  test_loss  epoch\n",
       "0           0         0       0.2   1.611221      0\n",
       "1           0       avg       0.2   1.611221      0\n",
       "2           0         0       0.2   1.611221      0\n",
       "3           0       avg       0.2   1.611221      0\n",
       "4           1         0       0.2   1.611221      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_path = os.path.join(experiment, f\"agent_{agent_id}\",\"record.csv\")\n",
    "df = pd.read_csv(record_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_task</th>\n",
       "      <th>test_task</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.564209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.831394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.563911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.610230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>5</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.748982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.564209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.831394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.563911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>1.595624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>5</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.713667</td>\n",
       "      <td>0.746547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.564209</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.831394</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.563911</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>1.292949</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>5</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.779333</td>\n",
       "      <td>0.696101</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.564209</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.831394</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.563911</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>1.220540</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>5</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.788667</td>\n",
       "      <td>0.684033</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.564209</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.831394</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.563911</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>1.195170</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>5</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.789667</td>\n",
       "      <td>0.679805</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.564209</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.831394</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.563911</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>1.180639</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>5</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.794333</td>\n",
       "      <td>0.677383</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.438658</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.547158</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.473930</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.829068</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.566504</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>1.075250</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>5</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.655095</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.438658</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.547158</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.473930</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.829068</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.566504</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>1.075250</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>5</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.655095</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_task test_task  test_acc  test_loss  epoch\n",
       "206           5         0  0.842000   0.439963      0\n",
       "207           5         1  0.800000   0.564209      0\n",
       "208           5         2  0.854000   0.484183      0\n",
       "209           5         3  0.714000   0.831394      0\n",
       "210           5         4  0.750000   0.563911      0\n",
       "211           5         5  0.200000   1.610230      0\n",
       "212           5       avg  0.693333   0.748982      0\n",
       "213           5         0  0.842000   0.439963      1\n",
       "214           5         1  0.800000   0.564209      1\n",
       "215           5         2  0.854000   0.484183      1\n",
       "216           5         3  0.714000   0.831394      1\n",
       "217           5         4  0.750000   0.563911      1\n",
       "218           5         5  0.322000   1.595624      1\n",
       "219           5       avg  0.713667   0.746547      1\n",
       "220           5         0  0.842000   0.439963     21\n",
       "221           5         1  0.800000   0.564209     21\n",
       "222           5         2  0.854000   0.484183     21\n",
       "223           5         3  0.714000   0.831394     21\n",
       "224           5         4  0.750000   0.563911     21\n",
       "225           5         5  0.716000   1.292949     21\n",
       "226           5       avg  0.779333   0.696101     21\n",
       "227           5         0  0.842000   0.439963     41\n",
       "228           5         1  0.800000   0.564209     41\n",
       "229           5         2  0.854000   0.484183     41\n",
       "230           5         3  0.714000   0.831394     41\n",
       "231           5         4  0.750000   0.563911     41\n",
       "232           5         5  0.772000   1.220540     41\n",
       "233           5       avg  0.788667   0.684033     41\n",
       "234           5         0  0.842000   0.439963     61\n",
       "235           5         1  0.800000   0.564209     61\n",
       "236           5         2  0.854000   0.484183     61\n",
       "237           5         3  0.714000   0.831394     61\n",
       "238           5         4  0.750000   0.563911     61\n",
       "239           5         5  0.778000   1.195170     61\n",
       "240           5       avg  0.789667   0.679805     61\n",
       "241           5         0  0.842000   0.439963     81\n",
       "242           5         1  0.800000   0.564209     81\n",
       "243           5         2  0.854000   0.484183     81\n",
       "244           5         3  0.714000   0.831394     81\n",
       "245           5         4  0.750000   0.563911     81\n",
       "246           5         5  0.806000   1.180639     81\n",
       "247           5       avg  0.794333   0.677383     81\n",
       "248           5         0  0.850000   0.438658    100\n",
       "249           5         1  0.814000   0.547158    100\n",
       "250           5         2  0.856000   0.473930    100\n",
       "251           5         3  0.714000   0.829068    100\n",
       "252           5         4  0.760000   0.566504    100\n",
       "253           5         5  0.826000   1.075250    100\n",
       "254           5       avg  0.803333   0.655095    100\n",
       "255           5         0  0.850000   0.438658    101\n",
       "256           5         1  0.814000   0.547158    101\n",
       "257           5         2  0.856000   0.473930    101\n",
       "258           5         3  0.714000   0.829068    101\n",
       "259           5         4  0.760000   0.566504    101\n",
       "260           5         5  0.826000   1.075250    101\n",
       "261           5       avg  0.803333   0.655095    101"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"train_task\"] == task_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_out = [] # features\n",
    "y_out = [] # global labels\n",
    "y_task = [] # globallabel_task_id\n",
    "with torch.no_grad():\n",
    "    for task_id, testloader in testloaders.items():\n",
    "        for X, y in testloader:\n",
    "            X = X.to(net.device)\n",
    "            X_encode = net.contrastive_embedding(X, task_id)\n",
    "            X_out.append(X_encode.cpu())\n",
    "            y_out.append(y.cpu())\n",
    "            y_task.append(np.ones_like(y) * task_id)\n",
    "X_encode = np.concatenate(X_out, axis=0)\n",
    "Y = np.concatenate(y_out, axis=0)\n",
    "y_task = np.concatenate(y_task, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.class_sequence)\n",
    "print(np.unique(Y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2, random_state=0, init=\"pca\", n_jobs=-1).fit_transform(X_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for y_label in np.unique(Y):\n",
    "    plt.scatter(X_embedded[Y == y_label, 0], X_embedded[Y == y_label, 1], label=y_label)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array same size as y and y_task where each element is {y}_{y_task} string\n",
    "y_task_str = np.array([str(Y[i]) + \"_\" + str(y_task[i]) for i in range(len(Y))]) # class_task\n",
    "# plot X_embedded with color corresponding to y_task_str\n",
    "import seaborn as sns\n",
    "# different sns color palette\n",
    "# bigger plot size\n",
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "sns.set_palette(\"tab20\")\n",
    "\n",
    "task = 0\n",
    "X_t = X_embedded[y_task == task]\n",
    "y_t = y_task_str[y_task == task]\n",
    "sns.scatterplot(x=X_t[:, 0], y=X_t[:, 1], hue=y_t);\n",
    "# sns.scatterplot(x=X_embedded[:, 0], y=X_embedded[:, 1], hue=y_task_str);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fc759119c7a949f50d7f999e302b90a14fbc886f397e56263de77303ed14594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
